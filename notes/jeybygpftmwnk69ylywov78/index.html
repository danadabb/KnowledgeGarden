<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/KnowledgeGarden/favicon.ico"/><title>Solutions Architect Associate</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Notes for the SAA certification"/><meta property="og:title" content="Solutions Architect Associate"/><meta property="og:description" content="Notes for the SAA certification"/><meta property="og:url" content="https://danadabb.github.io//KnowledgeGarden/notes/jeybygpftmwnk69ylywov78/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="12/18/2024"/><meta property="article:modified_time" content="10/7/2025"/><link rel="canonical" href="https://danadabb.github.io//KnowledgeGarden/notes/jeybygpftmwnk69ylywov78/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/KnowledgeGarden/_next/static/css/7cc3493d7b9f289d.css" as="style"/><link rel="stylesheet" href="/KnowledgeGarden/_next/static/css/7cc3493d7b9f289d.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/KnowledgeGarden/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/KnowledgeGarden/_next/static/chunks/webpack-2e871d18defb9c0c.js" defer=""></script><script src="/KnowledgeGarden/_next/static/chunks/framework-28c999baf2863c3d.js" defer=""></script><script src="/KnowledgeGarden/_next/static/chunks/main-00d0d583ee74faf4.js" defer=""></script><script src="/KnowledgeGarden/_next/static/chunks/pages/_app-e302c5ec5598b9da.js" defer=""></script><script src="/KnowledgeGarden/_next/static/chunks/935-4dee79e80b8641c6.js" defer=""></script><script src="/KnowledgeGarden/_next/static/chunks/6-50972def09142ee2.js" defer=""></script><script src="/KnowledgeGarden/_next/static/chunks/pages/notes/%5Bid%5D-78d472fa3b924116.js" defer=""></script><script src="/KnowledgeGarden/_next/static/hwGfdcDrSx4cXywVsCQrh/_buildManifest.js" defer=""></script><script src="/KnowledgeGarden/_next/static/hwGfdcDrSx4cXywVsCQrh/_ssgManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout" style="margin-top:64px;display:flex;flex-direction:row"><div class="site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);background-color:transparent;flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></div><main class="ant-layout-content side-layout-main" style="max-width:1200px;min-width:0;display:block"><div style="padding:0 24px"><div class="main-content" role="main"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="solutions-architect-associate">Solutions Architect Associate<a aria-hidden="true" class="anchor-heading icon-link" href="#solutions-architect-associate"></a></h1>
<p>Notes attributed to <a href="https://learn.cantrill.io/courses/enrolled/1820301">this course</a></p>
<h2 id="aws-accounts">AWS Accounts<a aria-hidden="true" class="anchor-heading icon-link" href="#aws-accounts"></a></h2>
<ul>
<li>An AWS account is a container for identities (users) and resources</li>
<li>Every AWS account has a root user</li>
<li>The account root user can't be restricted it has full access to everything within this account.</li>
<li>The credit card used with the root account will be the <strong>Account</strong> Payment method, everything will be billed to that card</li>
<li>AWS is a pay-as-you-go/consume platform</li>
<li>Certain resources have a free-tier</li>
<li>IAM - every AWS account comes with it's own IAM Database</li>
<li>IAM lets you create 3 different IAM profiles - Users, groups and roles
<ul>
<li>Users represent humans or applications that need access to your account - this is for individual purposes</li>
<li>Groups are a collection of related users</li>
<li>Roles can be used for granting external access to your account</li>
</ul>
</li>
<li>IAM policy - used to allow/deny access to AWS services attached to other identities</li>
<li>IAM is an identity provider, which also authenticates and authorizes</li>
<li>IAM Access Keys are long term credentials with up to 2 available per IAM user typically used in CLIs or applications</li>
<li>Access Keys are made up of Access Key ID and the Secret Access Key</li>
</ul>
<h2 id="technical-fundamentals">Technical fundamentals<a aria-hidden="true" class="anchor-heading icon-link" href="#technical-fundamentals"></a></h2>
<p>Pre-cursor to the concepts covered in this course summarized here:
<a href="/KnowledgeGarden/notes/fqi20n3dabq8rhrs04h6tk3">Tech Fundamentals</a></p>
<h2 id="aws-fundamentals">AWS Fundamentals<a aria-hidden="true" class="anchor-heading icon-link" href="#aws-fundamentals"></a></h2>
<h3 id="public-vs-private-services">Public vs Private services<a aria-hidden="true" class="anchor-heading icon-link" href="#public-vs-private-services"></a></h3>
<ul>
<li>Services can be categorized into two types: public and private services</li>
<li>AWS public and private service are separated by network access.</li>
<li>Public service is something which can be accessed using public endpoints e.g. s3</li>
<li>A private aws service runs within a vpc so only what is connected to that vpc can access it</li>
<li>AWS has three zones - the public internet zone, the private network and the AWS public zone which runs in between the public and private zone.</li>
<li>AWS public zone is where public services operate from e.g. s3</li>
</ul>
<h3 id="aws-global-infrastructure">AWS Global Infrastructure<a aria-hidden="true" class="anchor-heading icon-link" href="#aws-global-infrastructure"></a></h3>
<ul>
<li>AWS have created their infrastructure platform consisting of isolated regions connected together.</li>
<li>A region is a creation of AWS which covers an area over the world which contains a full deployment of AWS infrastructure. New regions are added all the time.</li>
<li>When interacting with most AWS services you're doing it at a particular region e.g. elastic compute cloud in North virginia is different to interacting to elastic compute in Sydney.</li>
<li>AWS also provides Edge locations which are smaller than regions and they typically have only content distribution services as well as some types of edge computing. They are useful for companies like Netflix who want to store tv shows and movies as close to their customers as possible to allow low for low latency and high speed distribution</li>
<li>Some services act from a global perspective e.g. IAM</li>
<li>Regions have three main benefits:</li>
</ul>
<ol>
<li>Each reason is separate geographically which isolates any faults</li>
<li>Geopolitical separation - different governance depending the region</li>
<li>Location control - tune architecture performance relative to an area</li>
</ol>
<ul>
<li>Regions also have a code e.g. Sydney is ep-southeast-2, as well as a name - Asia Pacific (Sydney)</li>
</ul>
<p>Inside every region, AWS also provide multiple availability zones. These give isolated infrastructure within a region. If a region experiences an isolated issue but only one availability zone is affected, the others are likely to be still fully functional. A solutions architect may distribute the services across multiple availability zones. This is used to build resilience.</p>
<h3 id="aws-default-virtual-private-cloud-vpc">AWS Default Virtual Private Cloud (VPC)<a aria-hidden="true" class="anchor-heading icon-link" href="#aws-default-virtual-private-cloud-vpc"></a></h3>
<ul>
<li>A VPC is a Virtual Network inside AWS</li>
<li>A VPC is a regional service that operates within that region</li>
<li>A VPC by default is private and isolated. Services deployed into the same vpc can communicate but it's isolated from other vpcs and the AWS zone/public internet.</li>
<li>There are two types of VPCs per account:</li>
</ul>
<ol>
<li>Default VPCs - can only have one per region. Configured by AWS.</li>
<li>Custom VPCs - can have many per region. You use these in almost all serious AWS deployments to configure them how you like.</li>
</ol>
<ul>
<li>VPCs cannot communicate with each other without you configuring them to do so.</li>
<li>VPCs are regionally resilient</li>
<li>The default VPC gets a default CIDR IP range which is always the same - 172.31.0.0/16</li>
<li>A VPC can be subdivided into subnets for resilience. Each subnet inside a VPC can be put into an availability zone. The default VPC has one subnet in every availability zone in that region.</li>
<li>the default VPC assigns a public address to the services by default.</li>
</ul>
<h3 id="elastic-compute-cloud-ec2">Elastic Compute Cloud (EC2)<a aria-hidden="true" class="anchor-heading icon-link" href="#elastic-compute-cloud-ec2"></a></h3>
<ul>
<li>EC2 is a service which allows you to provision virtual machines known as instances with an operating system.</li>
<li>EC2 is IAAS (Infrastructure as a Service) which provides access to virtual machines (instances)</li>
<li>An instance is just an operating system configured in a certain way</li>
<li>EC2 is a private AWS service by default - it uses VPC. You can configure it to have public access</li>
<li>An EC2 is AZ (availability zone) resilient. If the AZ fails then the instance fails</li>
<li>You can choose an instance with various sizes and capabilities</li>
<li>EC2 provides on-demand billing - per second</li>
<li>Instances can use different types of storage e.g. local host storage (ec2 host) or Elastic Block Store (EBS) which is network storage made available</li>
<li>EC2 instances have a state e.g. RUNNING -> STOPPED -> TERMINATED</li>
<li>EC2 can be moved from RUNNING TO STOPPED and back again</li>
<li>TERMINATING an instance is a one way change, you can do that from the RUNNING or STOPPED state. It's a non-reversible action</li>
<li>At a high level, an instance is composed of CPU, memory, disk and networking. You are charged for all four of those instances.</li>
<li>When an instance is STOPPED, it means no CPU, memory or network is being used therefore you won't be charged for any running costs of that instance. Storage however is still being used when it's in the stopped state which means you will be charged for it.</li>
<li>In order to have no costs for an EC2 instance you need to terminate it.</li>
<li>An Amazon Machine Image (AMI) is an image of an EC2 instance.</li>
<li>An AMI can be used to create an EC2 instance or an AMI can be created from an EC2 instance.</li>
<li>An AMI is similar to a server image in a physical server</li>
<li>An AMI contains:
<ul>
<li>Attached permissions - who can use the image e.g only owner vs specific accounts vs public</li>
<li>Root volume - the drive that boots the operating system</li>
<li>Block device mapping - configuration which links the volumes that the AMI has and how they're presented to the operating system e.g boot vs data volume</li>
</ul>
</li>
<li>EC2 can host different OS e.g. linux, windows, macos. You can connect to them via remote desktop (windows) or SSH (linux/macos)</li>
</ul>
<h3 id="simple-storage-service-s3">Simple Storage Service (S3)<a aria-hidden="true" class="anchor-heading icon-link" href="#simple-storage-service-s3"></a></h3>
<ul>
<li>S3 is a global storage platform - it's regionally resilient. The data is replicated across availability zones in that regions. It can tolerate a fault in an AZ</li>
<li>S3 is a public service</li>
<li>It's used to host a large amount of data e.g. movies, audio, photos, text, large data sets</li>
<li>Economical and can be accessed via a variety of methods e.g. UI/CLI/API/HTTP</li>
<li>S3 delivers two main things:</li>
</ul>
<ol>
<li>Objects - the data s3 stores</li>
<li>Buckets - containers for objects</li>
</ol>
<p><strong>Objects</strong> are basically files that are made up of two components:</p>
<ol>
<li>the object key (name) - usually the file name</li>
<li>the object value (data) - the data or contents of the object</li>
</ol>
<ul>
<li>
<p>The bucket name needs to be <strong>globally unique</strong> - this is across all regions and aws accounts. It should be between 3-63 characters, all lower case, no underscores. Must start with a lowercase letter or a number. It can't be formatted like an IP address.</p>
</li>
<li>
<p>A bucket can hold an unlimited number of objects and an unlimited amount of data - it's an infinitely scalable service.</p>
</li>
<li>
<p>A bucket may show on the UI that it has folders but the underlying structure is flat and everything sits in the root. Folders are referred to as prefixes in s3 as they prefix the object names.</p>
</li>
<li>
<p>There is a soft limit of 100 buckets for an s3 account and a hard limit of 1000 buckets using support request.</p>
</li>
<li>
<p>You can have unlimited objects in a bucket, with each object able to range between 0 to 5TB in size.</p>
</li>
<li>
<p>S3 is not a file or block. It is an object store</p>
</li>
<li>
<p>You can't mount an s3 bucket as a drive e.g. K:\ or /images</p>
</li>
<li>
<p>s3 is great for large scale data storage, distribution or upload</p>
</li>
<li>
<p>great for offloading - moving data from a server to the s3</p>
</li>
<li>
<p>Most services can use s3 as an INPUT or OUTPUT. s3 is a good default for data storage.</p>
</li>
</ul>
<h3 id="cloudformation-cfn-basics">CloudFormation (CFN) basics<a aria-hidden="true" class="anchor-heading icon-link" href="#cloudformation-cfn-basics"></a></h3>
<ul>
<li>CloudFormation is Infrastructure as Code (IaC) which allows automation infrastructure creation, update and deletion.</li>
<li>CFN uses templates written in either YAML or JSON</li>
<li>A template:
<ul>
<li>has a list of resources to do the action on (at least one - mandatory)</li>
<li>description - the only restriction with this is if the template has an AWSTemplateFormatVersion, the description must come directly after it (this can be a trick question in the exam)</li>
<li>metadata - controls how the UI presents the template</li>
<li>parameters - adds fields which need to be added with input (default values could be provided)</li>
<li>mappings - allows you to create lookup tables</li>
<li>conditions - decision making in the template</li>
<li>outputs - once the template is finished it can present outputs based on the resource e.g. the instance ID of the ec2</li>
</ul>
</li>
<li>CloudFormation takes a template and creates a stack. A stack contains all the logical resources the template tells it to contain. CFN will create a corresponding physical resource in your AWS account.</li>
<li>You can update or delete the logical resources in the template and the template will do this to the physical resources on your account</li>
<li>CFN exists to automate infrastructure</li>
<li>CFN can be used as part of change management as it can be put in code repositories</li>
</ul>
<h3 id="cloudwatch-cw-basics">CloudWatch (CW) Basics<a aria-hidden="true" class="anchor-heading icon-link" href="#cloudwatch-cw-basics"></a></h3>
<ul>
<li>CloudWatch is a support service which is used by many other AWS services. It collects and manages operational data detailing how it performs, runs or logging data</li>
<li>It performs 3 main jobs:</li>
</ul>
<ol>
<li><strong>Metrics</strong> - collects metrics from AWS products, Apps, on-premises</li>
<li><strong>Logs</strong> - collects logs as above</li>
<li><strong>Events</strong> - Cloudwatch can generate events to do something</li>
</ol>
<ul>
<li>Namespace is a container for monitoring data. It's a way of separating things into different areas e.g. AWS/EC2</li>
<li>A metric is a collection of related data points in a time ordered structure e.g. cpu utilization, network I/O or disk I/O</li>
<li>Data points are measurements of data consisting of a timestamp and value</li>
<li>Dimensions are used to separate data points within the same metric e.g. instance ID (i-xxxxx) and instance type (t3.small)</li>
<li>We can take action on metrics using alarms</li>
</ul>
<h3 id="shared-responsibility-model">Shared Responsibility Model<a aria-hidden="true" class="anchor-heading icon-link" href="#shared-responsibility-model"></a></h3>
<ul>
<li>Shared responsibility in AWS is the principal that some areas you have to manage vs AWS have to manage</li>
<li>At a high level, AWS is responsible for the security of the cloud where as customers are responsible for the security in the cloud</li>
<li>AWS responsibilities include managing security of regions, Availability Zones and Edge locations specifically the hardware/global infrastructure.</li>
<li>AWS also manage the security around compute, storage, database and networking as well as any software that is used to provide those services</li>
<li>Customers need to take care of client side data encryption, server side encryption and network traffic protection.</li>
<li>Customers need to take care of OS, network and firewall configuration</li>
<li>Customers need to take care of platform, applications, identity and access management as well as customer data.</li>
</ul>
<p><img src="/KnowledgeGarden/assets/images/srp-model.png" alt="Shared Responsibility Model"></p>
<h3 id="high-availability-vs-fault-tolerance-vs-disaster-recovery">High-Availability vs Fault-Tolerance vs Disaster Recovery<a aria-hidden="true" class="anchor-heading icon-link" href="#high-availability-vs-fault-tolerance-vs-disaster-recovery"></a></h3>
<ul>
<li>High Availability (HA) aims to ensure an agreed level of operational performance, usually uptime. for a higher than normal period</li>
<li>HA is about maximizing a system's online time</li>
<li>System availability is usually expressed as a percentage of uptime e.g. 99.9% a year means 8.77 hours p/year downtime</li>
<li>Fault tolerance (FA) is the property that enables a system to continue operating properly in the event of the failure of one or more of its components</li>
<li>HA is just about maximizing uptime where as FA is operating through failure e.g. a airplane can't just be highly available it must be fault tolerant</li>
<li>FA is much more complex and more costly to implement as you need to minimize outages but also design a system that will tolerate a failure</li>
<li>Disaster recovery (DR) is a set of policies, tools and procedures to enable the recovery or continuation of vital technology infrastructure and systems following a natural or human-induced disaster</li>
<li>You need to plan what should be done in the event of a failure. An example of DR planning is having off-site backup storage</li>
<li>DR planning should happen in advance so that the process is automated</li>
</ul>
<p><strong>Summary</strong>:</p>
<ul>
<li>HA - minimise outages</li>
<li>FA - operate through faults</li>
<li>DR - used when these don't work</li>
</ul>
<h3 id="route53-r53-fundamentals">Route53 (R53) Fundamentals<a aria-hidden="true" class="anchor-heading icon-link" href="#route53-r53-fundamentals"></a></h3>
<ul>
<li>Route53 provides two main services:</li>
</ul>
<ol>
<li>Allows you to register domains</li>
<li>Hosts zones on managed nameservers it provides</li>
</ol>
<ul>
<li>Route53 is a global service with a single Database. You don't need to pick a region</li>
<li>It is globally resilient so it can tolerate the fault of multiple regions</li>
<li>Route53 provides DNS zones as well as hosting for those zones</li>
<li>Zone files are created and hosted on four managed name servers</li>
<li>Hosted zones can be public or private (VPC)</li>
<li>A hosted zone hosts DNS records (recordsets)</li>
</ul>
<h3 id="dns-record-types">DNS Record Types<a aria-hidden="true" class="anchor-heading icon-link" href="#dns-record-types"></a></h3>
<ul>
<li>
<p>There are different records that can be stored in DNS:</p>
<ul>
<li>
<p>Nameserver (NS) - allow delegation to occur end to end in DNS. e.g example.com → ns1.example.com, ns2.example.com</p>
</li>
<li>
<p>A and AAAA Records - A record will point to a v4 IP address and the AAAA will point to the v6 IP address. For example:</p>
<p><strong> A Record:</strong> example.com → 192.168.1.1</p>
<p><strong> AAAA Record:</strong> example.com → 2001:db8::1</p>
</li>
<li>
<p>CNAME - Canonical Name - lets you create the equivalent of DNS shortcuts by pointing to the same A record. E.g. <a href="http://www.example.com">www.example.com</a> → example.com</p>
</li>
<li>
<p>MX Record - how a server can find a mail server for a specific domain. Includes a priority number</p>
<pre><code>example.com
  Priority: 10 → mail1.example.com
  Priority: 20 → mail2.example.com
</code></pre>
</li>
<li>
<p>TXT - allow you to add arbitrary text to a domain that must be matched to prove domain ownership.</p>
</li>
</ul>
</li>
<li>
<p>TTL (Time To Live) is the time set by the DNS to determine how long a DNS record is cached by a resolver (DNS server o browser) before it must check for an updated record from an authoritative server.</p>
</li>
</ul>
<h2 id="iam-accounts-and-aws-organisations">IAM, Accounts and AWS Organisations<a aria-hidden="true" class="anchor-heading icon-link" href="#iam-accounts-and-aws-organisations"></a></h2>
<h3 id="iam-identity-policies">IAM Identity Policies<a aria-hidden="true" class="anchor-heading icon-link" href="#iam-identity-policies"></a></h3>
<ul>
<li>
<p>IAM policies are a type of policy which get attached to identities in AWS</p>
</li>
<li>
<p>Identities are IAM users, groups and roles</p>
</li>
<li>
<p>IAM Policies:</p>
<ul>
<li>provides and denies access to features in AWS</li>
<li>Policy documents are created using JSON containing one or more statements</li>
<li>the first part of a statement is a Sid (Statement ID) which is an optional field that lets you identify a statement and what it does. Using these is best practice to inform the reader</li>
<li>Every statement will have a resource you're interacting with and the action you're wanting to perform on that resource</li>
<li>The action is in the format "service:operation" where the operation can possibly be a wild card or a list of multiple actions</li>
<li>Resources is the same only it matches AWS resources. Individual resources are referred to using the ARN</li>
<li>Effect is either allow or deny. It is possible to be allowed and denied at the same time</li>
</ul>
<pre class="language-json"><code class="language-json">&#x3C;!-- Policy document example -->
<span class="token punctuation">{</span>
  <span class="token property">"Version"</span><span class="token operator">:</span> <span class="token string">"2012-10-17"</span><span class="token punctuation">,</span>
  <span class="token property">"Statement"</span><span class="token operator">:</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{</span>
      <span class="token property">"Sid"</span><span class="token operator">:</span> <span class="token string">"FullAccess"</span><span class="token punctuation">,</span>
      <span class="token property">"Effect"</span><span class="token operator">:</span> <span class="token string">"Allow"</span><span class="token punctuation">,</span>
      <span class="token property">"Action"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"s3:*"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token property">"Resource"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"*"</span><span class="token punctuation">]</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">]</span>
<span class="token punctuation">}</span>
</code></pre>
<ul>
<li>when there is an overlap in permissions, then both of the statements are processed where the priority begins at explicit denies. Denies overrule everything else. The second priority are explicit allows. Allows take effect unless there are explicit denies. The default if no rules are in place, the default is DENY.</li>
<li>With the exception of the account root user, aws identity start of with NO ACCESS to aws resources.</li>
<li>Remember: explicit DENY > explicit ALLOW > DENY</li>
</ul>
</li>
<li>
<p>There are two types of policies: Inline policies and managed policies</p>
</li>
<li>
<p>Inline policies are when you apply individual JSON policy documents to each individual account. This is good for exceptional or special access rights for an individual as opposed to a group or a number of people</p>
</li>
<li>
<p>Managed policies are another JSON policy that you'd attach to identities in a reusable way. These should be used for the normal default rights in a business as they are low overhead</p>
</li>
<li>
<p>There are two types of managed policies: AWS managed policies and customer managed policies which you can create and manage for exact requirements</p>
</li>
</ul>
<h3 id="iam-users-and-arns">IAM Users and ARNs<a aria-hidden="true" class="anchor-heading icon-link" href="#iam-users-and-arns"></a></h3>
<ul>
<li>IAM users are an identity used for anything required long term AWS access e.g. humans, applications or service accounts</li>
<li>A principal (a person/application) makes a request to IAM to authenticate to a resource</li>
<li>Authentication for IAM users is done using either username and password or access keys. Access keys are usually used by applications or by humans using CLI tools.</li>
<li>Once a principal goes through the access tools, they become an authenticated identity</li>
<li>Once a principal is identified AWS knows which policies apply to an identity. This is the process of authorization.</li>
<li>Authentication is how a principal can prove to IAM it's who they say they are where as Authorization checks the policies attached to the identity to give them permission for a resource</li>
<li>ARN (Amazon Resource Name) uniquely identify resources within any AWS accounts.</li>
<li>ARN is used to allow you to refer to a single or group of resources using wild cards</li>
<li>ARNs are used in IAM policies</li>
<li>The format is:
<code>arn:partition:service:region:account-id:resource-id</code>
<code>arn:partition:service:region:account-id:resource-type/resource-id</code>
<code>arn:partition:service:region:account-id:resource-type:resource-id</code></li>
<li>You can only have 5000 IAM users per account</li>
<li>An IAM User can be a member of 10 groups</li>
<li>If you have more than 5000 identifiable users then IAM users is not the right identity to use for that solution. You can fix this with IAM roles or Identity Federation.</li>
</ul>
<h3 id="iam-groups">IAM Groups<a aria-hidden="true" class="anchor-heading icon-link" href="#iam-groups"></a></h3>
<ul>
<li>IAM groups are containers for IAM users</li>
<li>You can't log into IAM groups nor do they have credentials of their own</li>
<li>They are used solely to manage and organise IAM users</li>
<li>an IAM user can be part of multiple IAM groups</li>
<li>Groups can have policies attached to them, both inline and managed</li>
<li>You can also have individual inline/managed policies at the user level</li>
<li>You should collect all the policies that apply to a user from their groups and individual policies and apply the same deny-allow-deny rule to work out what their permissions are</li>
<li>There is no limit for the amount of users in an IAM group but the IAM user limit of 5000 exists for the whole account</li>
<li>There is no such 'all users' group in IAM built in. You can create this and manage it manually</li>
<li>You cannot have any nesting in groups</li>
<li>There is a limit of 300 groups per account but it can be increased with a support ticket</li>
<li>Policies can be attached to resources as well for example a bucket can have a policy attached to it where it allows and denies identities access to that bucket.</li>
<li>A resource can be refer to a user or role to give permission to itself but it cannot give it to a group. This is because a group is not a true identity and they can't be referenced as a principal in a policy</li>
</ul>
<h3 id="iam-roles">IAM Roles<a aria-hidden="true" class="anchor-heading icon-link" href="#iam-roles"></a></h3>
<ul>
<li>
<p>A role is a type of identity that exists inside an IAM account</p>
</li>
<li>
<p>IAM user is when a single principal wants to use AWS</p>
</li>
<li>
<p>IAM roles are best suited to be used by multiple principals e.g. multiple users in the aws account or users, apps or services inside or outside of the aws account.</p>
</li>
<li>
<p>If you can't identify the number of principals that use an identity or if you have more than 5000 principals you could consider using an IAM role</p>
</li>
<li>
<p>Usually roles are used on a temporary basis to borrow permissions</p>
</li>
<li>
<p>IAM roles have two types of policies that can be attached:</p>
<ol>
<li>Trust policy - which identities can assume that role. This can be entities in AWS accounts, other accounts, anonymous users and SSO providers e.g. facebook, google etc</li>
<li>Permissions policy - temporary credentials are given to identities assuming the role and these credentials are used to check the permissions</li>
</ol>
</li>
<li>
<p>temporary credentials are generated to roles using STS (Secure Token Service).</p>
</li>
</ul>
<h3 id="when-to-use-iam-roles">When to use IAM Roles<a aria-hidden="true" class="anchor-heading icon-link" href="#when-to-use-iam-roles"></a></h3>
<ul>
<li>One of the most common uses of IAM roles is AWS services as they need permission and access rights to perform certain actions</li>
<li>An example is AWS Lambda - it may start/stop ec2 instances, perform backups or other tasks that need permission</li>
<li>Instead of hardcoding the access keys into the Lambda, the IAM role 'Lambda execution role' can grant access to aws product/services. It will use the sts:AssumeRole operation to generate temporary credentials to use AWS services.</li>
<li>This is a better approach than using access keys as it's more secure and it won't need key rotation</li>
<li>Roles are also useful for emergency or unusual situations. A person can assume an emergency role when absolutely required for a short time.</li>
<li>Roles are useful for an existing corporate environment. If a corporate has over 5000 staff you cant assign each of them an IAM user.</li>
<li>You could allow an IAM role inside your AWS account to be used by an external identity e.g. active directory</li>
<li>If you create an app with over 5000 users that needs AWS access, you can use web identity federation which uses IAM roles. Web identities can be providers such as google, facebook or twitter/X</li>
<li>The pro of using web identities is that no AWS credentials are stored on the app and it uses existing accounts that customers have. This can scale to 100 million+ users</li>
<li>If you want to use resources across aws accounts, aws roles can also be used.</li>
</ul>
<h3 id="service-linked-roles-and-passrole">Service-linked Roles and PassRole<a aria-hidden="true" class="anchor-heading icon-link" href="#service-linked-roles-and-passrole"></a></h3>
<ul>
<li>Service-linked roles are a special time of IAM role linked to a specific AWS service</li>
<li>their permissions are pre-defined by an AWS service</li>
<li>The main difference between a regular IAM role and a service-linked role is that you cannot delete a service-linked role until it's no longer required</li>
<li>They are either created by a service or by you during set up</li>
<li>Passrole permissions give the users the ability to use a service linked role without being able to create or edit the role. This is similar to using a pre-created role in a cloud formation stack.</li>
</ul>
<h3 id="aws-organisations">AWS Organisations<a aria-hidden="true" class="anchor-heading icon-link" href="#aws-organisations"></a></h3>
<ul>
<li>AWS organisations take a single AWS account (standard account) to create an organisation. This account becomes the management account (previously called Master account).</li>
<li>The management account invites existing standard AWS accounts into the organisation. Once they join they change from being standard to member accounts.</li>
<li>An AWS organisation has only ONE management account and zero or more member accounts</li>
<li>An organisational root is not the same as an AWS account root user. The root of an AWS organisation is just a container for aws accounts and organisational units. It's the top level of the hierarchical structure of an organisation.</li>
<li>Consolidating billing for organisations changes the billing methods for member accounts by removing them and passing them through to the management account. In the context of consolidated billing this is known as the Payer Account.</li>
<li>Master, management and payment account refer to the same thing - the account that was used to create the organisation.</li>
</ul>
<h3 id="service-control-policies">Service Control Policies<a aria-hidden="true" class="anchor-heading icon-link" href="#service-control-policies"></a></h3>
<ul>
<li>SCPs are a feature of AWS organisations which allow restrictions to be placed on member accounts in the form of boundaries</li>
<li>SCPs are policy documents or JSON that can be attached to the organisation as a whole or organisational units or individual AWS accounts</li>
<li>They inherit down the organisation tree so that nested units will be affected by it and everything below it will be affected too</li>
<li>Management accounts are special as they cannot be restricted and not affected by service control policies.</li>
<li>They can limit what a root user can do though</li>
<li>SCP do not grant permissions. They just control what an account can and cannot grant via identity policies</li>
<li>By default, SCP applies FullAWsAccess which means no restrictions</li>
<li>SCP also has implicit deny if there is an absence of an allow</li>
<li>Only permissions allowed within the intersection of Identity policies and SCPs are allowed</li>
</ul>
<p><img src="/KnowledgeGarden/assets/images/SCP-policies-venn.png" alt="SCP and Identity Policies Venn"></p>
<h3 id="cloudwatch-logs">CloudWatch Logs<a aria-hidden="true" class="anchor-heading icon-link" href="#cloudwatch-logs"></a></h3>
<ul>
<li>A public service that allows you to store, monitor and access logging data</li>
<li>Has built in AWS integration with services eg EC2, VPC, Lambda, CloudTrail, R53</li>
<li>Can generate metrics based on logs (metric filter)</li>
<li>Log events are stored in log streams. Log streams are from one specific source e.g. one ec2 instance</li>
<li>Log groups are containers for multiple log streams for the same type of logging</li>
<li>Log groups are where we define retention and permission policies and metric filters</li>
<li>Metrics can have associated alarms</li>
</ul>
<h3 id="cloudtrail-essentials">CloudTrail Essentials<a aria-hidden="true" class="anchor-heading icon-link" href="#cloudtrail-essentials"></a></h3>
<ul>
<li>A product which logs API calls and account events/activities e.g. creating, deleting s3 bucket, stopping a service etc</li>
<li>A cloudtrail event is a call/activity on an aws account</li>
<li>Stores 90 days of event history - enabled by default for no cost. You don't get any s3 storage unless you configure a trail.</li>
<li>To customise this you must create 1 or more Trails</li>
<li>Management Events and Data Events are the type of trails</li>
<li>Management Events are control plane operations</li>
<li>Data events are resource operations e.g. uploading objects, lambda functions being invoked</li>
<li>By default, cloud trail only logs Management events</li>
<li>A trail logs events for an AWS region it's created in</li>
<li>Cloud trail is a regional service</li>
<li>A trail can be set to all regions or one region</li>
<li>By default, regional trails will log to the region they're in but global services will log to <strong>us-east-1</strong></li>
<li>If you create a trail, it is stored in an s3 bucket as compressed JSON log files</li>
<li>CloudTrail could also be integrated into Cloudwatch logs</li>
<li>You can create an organisational trail which is a single management point for every event across the whole organisation</li>
<li>CloudTrail is NOT real time. There can be a 15+ minute delay</li>
</ul>
<h3 id="aws-control-tower">AWS Control Tower<a aria-hidden="true" class="anchor-heading icon-link" href="#aws-control-tower"></a></h3>
<ul>
<li>AWS Control Tower gives an easy and quick way to set up a multi-account environment</li>
<li>Control Tower orchestrates other services to provide this functionality e.g. Organizations, IAM identity center, cloudformation, config</li>
<li>It's another evolution of AWS Organisation with more capability</li>
</ul>
<p>There are a few different parts of control tower:</p>
<ul>
<li>Landing zone - multi-account environment</li>
<li>Guard Rails - detect/mandates rules and standards across all accounts</li>
<li>Account Factory - automates and standardises new account creation</li>
<li>Dashboard - single page oversight of the entire environment</li>
</ul>
<p><strong>Landing Zone</strong></p>
<ul>
<li>Home region - the region you deploy the region</li>
<li>brings features of multiple AWS products together e.g. Organizations, AWS Config, Cloudformation</li>
<li>Security OU - organisational unit that has log archive and audit accounts</li>
<li>Sandbox OU - which is for testing and less rigid security</li>
<li>You can create other OU's and Accounts</li>
<li>Utilises the IAM Identity Center (AWS SSO) - SSO, multi account, ID Federation</li>
<li>Monitoring and Notifications - cloudwatch and SNS</li>
</ul>
<p><strong>Guard Rails</strong></p>
<ul>
<li>Come in either Mandatory, Strongly Recommended or Elective</li>
<li>Function in two ways</li>
</ul>
<ol>
<li>preventative - stop you from doing things - either enforced or not enabled</li>
<li>detective - compliance check for identifying issues - either clear, in violation or not enabled</li>
</ol>
<p><strong>Account Factory</strong></p>
<ul>
<li>Automate account provisioning</li>
<li>Can be done with cloud admins or end users with appropriate permissions</li>
<li>This provisioning comes with Guardrails which are automatically added</li>
<li>Account admin given to a named user to allow people in the organisation to provision accounts</li>
<li>Accounts are set up with standard configuration</li>
<li>Accounts can be closed or repurposed</li>
<li>Can be fully integrated with a business SDLC</li>
</ul>
<h2 id="simple-storage-service">Simple Storage Service<a aria-hidden="true" class="anchor-heading icon-link" href="#simple-storage-service"></a></h2>
<h3 id="s3-security-resource-policies-and-acls">S3 Security (Resource Policies and ACLs)<a aria-hidden="true" class="anchor-heading icon-link" href="#s3-security-resource-policies-and-acls"></a></h3>
<ul>
<li>S3 is private by default</li>
<li>The only identity which has any access to s3 by default is the account root user</li>
<li>You can grant permission to s3 via S3 <strong>Bucket Policies</strong> which are:
<ul>
<li>A form of resource policies</li>
<li>like identity policies but attached to a bucket</li>
<li>From the perspective of the resource - you control who can access that resource</li>
<li>Identity policies are limited by only being able to give control to the current account, so you cannot give another account access to an s3 bucket. Resource policies allows this for the current or different accounts.</li>
<li>Resource policies can ALLOW/DENY anonymous principals. This can't be done with identity policies since they need to be attached to a valid identity in AWS. Therefore the resource policies can be given to external access.</li>
<li>Resource policies have a 'principal' component which specifies which principals this policy applies to</li>
<li>An identity policy doesn't have a principal because the policy always applies to the account that created it. A good way to identify identity vs resource policy is checking the absence of principal</li>
<li>Identity policy as well as the bucket policy applies to both internal and cross account access. For anonymous only the bucket policy applies.</li>
</ul>
</li>
</ul>
<p>Access Control Lists (ACLs):</p>
<ul>
<li>Another form of s3 security used less frequently these days. They aren't recommended any more by AWS</li>
<li>A sub-resource of an object or bucket.</li>
<li>You cannot use ACLs on a group of objects</li>
</ul>
<p>Block Public Access:</p>
<ul>
<li>Another layer of permission to block all public access as a fail safe</li>
</ul>
<p>Choosing between resource or identity policies depends on the business' requirements and personal preference but sometimes choosing one over the other makes sense in specific situations:</p>
<ul>
<li>If you're granting/denying permissions on lots of different resources across an aws account, then you will need to use identity as not all services support resource policies.</li>
<li>If you prefer to manage resources from one place then identity makes sense because this is done in IAM</li>
<li>If you're managing a specific product then resource makes sense</li>
<li>Cross account or anonymous resources should use resource policies</li>
<li>Do not use ACLs unless you MUST</li>
</ul>
<h3 id="s3-static-hosting">S3 Static Hosting<a aria-hidden="true" class="anchor-heading icon-link" href="#s3-static-hosting"></a></h3>
<ul>
<li>Without static hosting, you access S3 Via AWS APIs</li>
<li>With static hosting, you can access those resources via HTTP e.g. websites, blogs etc</li>
<li>You must set an Index and Error document for s3 hosting. We point the index document to a specific html file object in the bucket as well as Error</li>
<li>A website endpoint is created for hosting</li>
<li>You can use a custom domain via R53 but the bucket name MUST match the domain name</li>
</ul>
<p>There are two scenarios that are perfect for s3</p>
<ol>
<li>Offloading - moving large data from a compute service to s3 is cheaper</li>
<li>Out-of-band pages - if a server is offline for maintenance or has performance bugs we can point users to a static page on s3 that contains something like a status message</li>
</ol>
<p>Pricing:</p>
<ul>
<li>Per GB per month charge</li>
<li>Transfer fee - in is free, out is per gig charge</li>
<li>Request and data retrieval - every operation e.g. GET, POST incurs a cost</li>
</ul>
<h3 id="object-versioning-and-mfa-delete">Object Versioning and MFA Delete<a aria-hidden="true" class="anchor-heading icon-link" href="#object-versioning-and-mfa-delete"></a></h3>
<ul>
<li>
<p>Disabled by default. <strong>Once enabled you cannot disable it</strong></p>
</li>
<li>
<p>You can suspend it and a suspended bucket can be re-enabled
<img src="/KnowledgeGarden/assets/images/s3-versioning-state.png" alt="S3 versioning state"></p>
</li>
<li>
<p>Versioning let's you store multiple version of objects within a bucket where as without it, there is a unique object name and the object gets replaced each time.</p>
</li>
<li>
<p>the 'id' is null if versioning is disabled, if it is enabled then s3 will allocate an id</p>
</li>
<li>
<p>newer versions will have a new ID</p>
</li>
<li>
<p>The newest version is known as Latest or current version</p>
</li>
<li>
<p>If you don't specify to s3 a specific version, you always get the latest. You can access individual versions by specifying the ID</p>
</li>
<li>
<p>If we delete an object, the object is not deleted, it's just hidden and marked with a delete marker. This is when we don't specify an ID/version</p>
</li>
<li>
<p>if we specify a version ID then an object is actually deleted</p>
</li>
<li>
<p>Important: <strong>versioning CANNOT be switched off - only suspended*</strong></p>
</li>
<li>
<p>Space is consumed by ALL versions and you are billed for ALL versions</p>
</li>
<li>
<p>Only way to remove all costs is to delete the bucket. Suspending does not remove the old versions</p>
</li>
<li>
<p>MFA Delete - enabled in versioning configuration which means you need an MFA token to change bucket versioning state or delete version</p>
</li>
<li>
<p>You would need to pass in MFA and the code passed with API calls to do these actions</p>
</li>
</ul>
<h3 id="s3-performance-optimization">S3 Performance Optimization<a aria-hidden="true" class="anchor-heading icon-link" href="#s3-performance-optimization"></a></h3>
<ul>
<li>Default upload in s3 is using single data stream to s3. The issue with this is if the stream fails the entire upload fails and you need a full restart</li>
<li>A single PUT upload in AWS is limited to 5GB as a maximum</li>
<li>A solution to a single stream is using a <strong>multi-part upload</strong></li>
<li>This breaks the original blob into individual parts</li>
<li>The <strong>minimum</strong> data size to use multi part upload is 100MB. It's recommended to use it for anything over 100mb.</li>
<li>An upload can be split into a maximum of 10,000 parts with each part between 5mb -> 5gb</li>
<li>Each individual part is treated as it's own isolated upload and can be restarted in isolation</li>
<li>It also improves transfer rates by uploading in parallel</li>
<li>S3 Accelerated transfer
<ul>
<li>using the public internet is not the most ideal way to get data from source to destination as the route chosen by ISPs is not always optimal. S3 transfer acceleration uses the network of AWS Edge locations located in convenient areas. This feature needs to be switched on.</li>
<li>Edge locations then use AWS Network as an 'express train' to get to the destination</li>
</ul>
</li>
</ul>
<h3 id="key-management-system">Key Management System<a aria-hidden="true" class="anchor-heading icon-link" href="#key-management-system"></a></h3>
<ul>
<li>
<p>A regional and Public service</p>
</li>
<li>
<p>Let's you create, store and manage keys</p>
</li>
<li>
<p>Handles both Symmetric and Asymmetric keys</p>
</li>
<li>
<p>Capable of performing cryptographic operations (encrypt, decrypt)</p>
</li>
<li>
<p><strong>Keys never leave KMS</strong></p>
</li>
<li>
<p>Uses a FIPS 140-2 (L2) - the L2 matters for the exam</p>
</li>
<li>
<p>KMS Keys are the keys that KMS manages</p>
</li>
<li>
<p>These are logical containers which contain ID, date, policy, desc and state.</p>
</li>
<li>
<p>KMS keys are backed by physical key material</p>
</li>
<li>
<p>The material is generated or imported and can be used for up to 4kb of data</p>
</li>
<li>
<p>KMS Keys do not leave the KMS product and the unencrypted form is never stored on disk</p>
</li>
<li>
<p>Data Encryption Keys (DEKs) are another type of key in KMS</p>
</li>
<li>
<p>DEK uses GenerateDataKey which can be used to encrypt and decrypt data more than 4kb in size</p>
</li>
<li>
<p>KMS does NOT store DEK, it provides it to you and discards it.</p>
</li>
<li>
<p>KMS will provide you with the plaintext and ciphertext version of this key</p>
</li>
<li>
<p>KMS does not do the encryption or decryption using DEK - you do or the service using KMS does</p>
</li>
<li>
<p>Services such as s3 use DEK for every object</p>
</li>
<li>
<p>KMS keys are isolated to a region and never leave</p>
</li>
<li>
<p>KMS keys CAN be multi region</p>
</li>
<li>
<p>THey can be AWS owned or customer owned</p>
</li>
<li>
<p>THere are two types of customer owned keys:</p>
<ol>
<li>AWS managed - created automatically by services</li>
<li>Customer managed - created by customers and are more configurable</li>
</ol>
</li>
<li>
<p>Both of these keys support rotation - with AWS managed keys this cannot be disabled but with customer it is optional</p>
</li>
<li>
<p>A KMS key contains a backing key which means previous backing keys can be used</p>
</li>
<li>
<p>Can use alias</p>
</li>
<li>
<p>Every KMS Key has a key policy (resource). For customer managed keys you can change it</p>
</li>
<li>
<p>KMS has to be explicitly be told which AWS account to manage it</p>
</li>
<li>
<p>Usually you use a combination of Key policies and IAM policies to manage KMS</p>
</li>
</ul>
<h3 id="s3-object-encryption-csesse">S3 Object Encryption CSE/SSE<a aria-hidden="true" class="anchor-heading icon-link" href="#s3-object-encryption-csesse"></a></h3>
<ul>
<li>Buckets aren't encrypted - objects are</li>
</ul>
<p>Data can be stored in disk in two different ways:</p>
<ol>
<li>Client side encryption - objects are being encrypted by the client before they ever leave. AWS receives it in a scrambled form and stores it in a scrambled form</li>
<li>Server side encryption - in transit, the data is in it's original form, once it's hitting s3 it's encrypted by the s3 servers</li>
</ol>
<p><img src="/KnowledgeGarden/assets/images/s3-encryption.png" alt="S3 Encryption"></p>
<p>There are 3 types of encryption for server side encryption:</p>
<ol>
<li>SSE-C - Server side encryption with customer provided keys</li>
<li>SSE-S3 - with amazon s3 managed keys (this is the default)</li>
<li>SSE-KMS - with KMS Keys stored in AWS Key management service</li>
</ol>
<p>SSE-C:</p>
<ul>
<li>Customer is responsible for the keys and S3 manages the s3 encryption/decryption processes. When you put an object into s3 you put it through as plaintext alongside the encryption key. When it goes through https it will be encrypted to an external observer. The key is destroyed at s3.</li>
</ul>
<p>SSE-S3:</p>
<ul>
<li>AWS handles both the encryption and the keys. You provide the plaintext data, the s3 encrypts it via a generated key for the object. You don't get to choose the key or customise it.</li>
</ul>
<p>SSE-KMS:</p>
<ul>
<li>You use KMS to create a key. Client sends data via plaintext and it's encrypted by S3 via the KMS key. That key is used by s3 to generate an encryption Key. Using this method, key managers can decide who can see the unencrypted data</li>
</ul>
<p>Summary of encryption types</p>
<p><img src="/KnowledgeGarden/assets/images/s3-encryption-summary.png" alt="summary"></p>
<h3 id="s3-bucket-keys">S3 Bucket Keys<a aria-hidden="true" class="anchor-heading icon-link" href="#s3-bucket-keys"></a></h3>
<ul>
<li>A way to help s3 scale with server side encryption</li>
<li>using SSE-KMS, AWS KMS is called every single time a call is made to s3 to generate a DEK</li>
<li>This starts to cost a lot upon scaling</li>
<li>Instead of generating a new DEK from KMS every time, <strong>bucket keys</strong> will ask KMS to generate a time limited bucket key used to generate DEKs within s3</li>
<li>This significantly reduces KMS API calls, reduces cost and increases scalability</li>
<li>Using bucket keys means cloudtrail kms events now show the bucket not te object</li>
<li>Bucket key works with replication, object encryption is maintained</li>
<li>If you replicate a plain text bucket to a bucket that is encrypted, it will get encrypted at the destination side</li>
</ul>
<h3 id="s3-object-storage-classes">S3 Object Storage Classes<a aria-hidden="true" class="anchor-heading icon-link" href="#s3-object-storage-classes"></a></h3>
<ul>
<li>
<p><strong>S3 standard</strong> is the default storage class. This replicates objects across at least 3 availability zones (AZs) in the AWS region</p>
</li>
<li>
<p>if s3 object is stored, a HTTP 1.1 200 OK response is provided by the s3 API endpoint</p>
</li>
<li>
<p>You're billed a GB/m fee for data stored, a $ per GB charge for transfer OUT (in is free) and a price per 1,000 requests. No specific retrieval fee, no minimum duration, no minimum size</p>
</li>
<li>
<p>S3 standards can be made publicly available</p>
</li>
<li>
<p>S3 standard should be used for frequently accessed data which is important and non-replaceable. This should be used as the default and only investigate moving other classes if you need a specific use case.</p>
</li>
<li>
<p><strong>S3 Standard-IA (infrequent Access)</strong></p>
</li>
<li>
<p>The same as S3 standard in most ways however has a lower GB storage price and a retrieval fee that increases with frequent data access</p>
</li>
<li>
<p>there is a minimum duration charge for using it (30 days)</p>
</li>
<li>
<p>Has a min capacity charge of 128kb per object</p>
</li>
<li>
<p>S3 Standard-ia should be used for long-lived data which is important but where access is infrequent</p>
</li>
<li>
<p><strong>S3 One Zone-IA (infrequent Access)</strong></p>
</li>
<li>
<p>Shares many of the considerations of standard-IA</p>
</li>
<li>
<p>The big difference is that the data is stored in one AZ in the region</p>
</li>
<li>
<p>Should be used for long-lived data which is non-critical and replaceable and where access is infrequent</p>
</li>
<li>
<p>Examples could be intermediate data you can afford to use or for replica copies</p>
</li>
<li>
<p><strong>S3 Glacier - Instant</strong></p>
</li>
<li>
<p>Like s3 standard IA except it has cheaper storage, more expensive retrieval costs, and longer minimums</p>
</li>
<li>
<p>more for when you want to access something once a quarter as opposed to once a month</p>
</li>
<li>
<p><strong>S3 Glacier - Flexible</strong></p>
</li>
<li>
<p>A cheaper storage solution</p>
</li>
<li>
<p>Stored as if 'cold' and therefore cannot be made publicly accessible. Retrieving requires a retrieval process</p>
</li>
<li>
<p>Retrieved to s3 standard-IA temporarily</p>
</li>
<li>
<p>There are 3 different retrieval methods:</p>
</li>
</ul>
<ol>
<li>expedited - 1-5 minutes</li>
<li>standard - 3-5 hours</li>
<li>bulk - 5-12 hours</li>
</ol>
<ul>
<li>
<p>the faster the retrieval the more expensive</p>
</li>
<li>
<p>situations for when you need to store archival data where frequent or realtime access isn't needed (e.g. yearly) and the access takes time.</p>
</li>
<li>
<p><strong>S3 Glacier - Deep Archive</strong></p>
</li>
<li>
<p>If you consider Flexible to be a 'chilled' state, then data in Deep Archive is in a 'frozen' state</p>
</li>
<li>
<p>180 day minimum duration</p>
</li>
<li>
<p>The retrieval methods are:</p>
</li>
</ul>
<ol>
<li>standard (12 hours)</li>
<li>bulk (up to 48 hours)</li>
</ol>
<ul>
<li>best for data that rarely if ever needs to be accessed e.g. legal or regulation data storage</li>
<li>it's a cheaper storage</li>
</ul>
<p><strong>Intelligent Tiering</strong>
Monitors and automatically moves any objects not accessed for 30 days to a low cost infrequent access tier and eventually to archive instant access, archive access or deep archive tiers. If objects start to become more popular and frequently accessed, they will be moved back up the tiers to frequent access at no charge</p>
<ul>
<li>Designed for long lived data with changing or unknown patterns</li>
</ul>
<h3 id="s3-lifecycle-configuration">S3 Lifecycle Configuration<a aria-hidden="true" class="anchor-heading icon-link" href="#s3-lifecycle-configuration"></a></h3>
<ul>
<li>You can create life cycle rules on objects in an s3 bucket</li>
<li>A set of rules that consist of actions based on a criteria</li>
<li>Can be applied on a bucket or group of objects</li>
</ul>
<p>two types of actions can be applied</p>
<ul>
<li>Transition actions - change the storage class of the object(s) e.g. from s3 standard to s3 IA after 30 days
<ul>
<li>all the transitions transition 'downward' in a waterfall fashion, not upward</li>
<li>the only exception of a transition not available downward is one zone-IA into S3 Glacier Instant Retrieval</li>
<li>if you transition objects you need to be aware of the minimum days before transition for example s3 standard to standard IA or one zone IA it would need to have been in s3 standard for at least 30 days</li>
<li>smaller objects can cost more upon transitioning due to minimum sizes</li>
<li>moving from s3 to IA also requires an additional 30 days before you can move them again to glacier classes</li>
</ul>
</li>
<li>Expiration actions - delete object(s) or versions</li>
</ul>
<p>You can't apply these rules based on 'access frequency' in the same way intelligent tiering does</p>
<h3 id="s3-replication">S3 Replication<a aria-hidden="true" class="anchor-heading icon-link" href="#s3-replication"></a></h3>
<p>S3 has two replication features which allow objects to be replicated between source and destination buckets in the same or different AWS accounts:</p>
<ol>
<li>
<p>Cross region replication (CRR) - allows the replication of objects from a source bucket to one or more destination buckets in different AWS regions</p>
</li>
<li>
<p>Same region replication (SSR) - as above but same region</p>
</li>
</ol>
<p>The architecture replication is applied to the source bucket. It specifies:</p>
<ul>
<li>the destination bucket</li>
<li>an IAM role to use for the replication process - s3 assumes that role</li>
<li>For replication across AWS accounts, the role isn't by default trusted by the destination account, therefore there needs to be a bucket policy in the destination account to allow the role to replicate into it</li>
</ul>
<p>Replication Options:</p>
<ul>
<li>What to replicate - all objects or subset</li>
<li>which storage class the destination bucket will use - the default is the destination uses the same class as the source</li>
<li>you can define the ownership of the objects in the destination. Across accounts, the bucket objects will by default be owned by the source bucket account</li>
<li>Replication time control (RTC) - adds a guaranteed 15 minute SLA on to the replication process.</li>
</ul>
<p>Replication consideration:</p>
<ul>
<li>By default, it's not retroactive - only from the point you enable replication will objects in the bucket be replicated. Objects prior to that time will not.</li>
<li>Versioning MUST be enabled for replication</li>
<li>batch replication can be turned on to replicate existing objects</li>
<li>objects are replicated only one way i.e. source to destination - there is a bi-directional setting that can be configured</li>
<li>replication can be unencrypted, SSE-S3, SSE-KMS (with extra config) and SSE-C</li>
<li>Source bucket owner needs permission to the object they replicate</li>
<li>It will not replicate system events that are made by life cycle management. Neither can it replicate glacier or glacier deep archive objects</li>
<li>Delete markers are not replicated - but can be enabled</li>
</ul>
<p>Why use replication?</p>
<ul>
<li>SSR (Same region replication) - Log aggregation - sync logs into a single s3 bucket</li>
<li>SSR - Prod and test sync</li>
<li>SSR - resilience with strict sovereignty</li>
<li>CRR (Cross region replication) - global resilience improvements</li>
<li>CRR - Latency reduction by replicating data to buckets closer to source</li>
</ul>
<h3 id="s3-presigned-urls">S3 PreSigned URLs<a aria-hidden="true" class="anchor-heading icon-link" href="#s3-presigned-urls"></a></h3>
<ul>
<li>Presigned URLS in s3 are a way to generate a URL with access permissions in a safe way.</li>
<li>If a bucket is not public, only an authenticated aws user can access it</li>
<li>AWS offers pre-signed urls for the case where we don't want to give someone short term access to the bucket without making it public or creating an aws identity for them</li>
<li>This can be used for both PUT and GET operations</li>
<li>Pre-signed urls allow someone to access a certain object in a private bucket with the same access rights as the user who generated the url for a certain period of time</li>
<li>You can create a pre-signed url for an object you don't have access to where the url will also not provide access to the object</li>
<li>the url has the same permissions of the identity as of the time the url was made</li>
<li>Don't generate pre-signed urls with a role - URLs will stop working when temporary credentials expire - because assuming an IAM role gives you temporary credentials and the pre-signed url may expire far later than the credentials. It's best to use long term identities i.e. an IAM user</li>
</ul>
<h3 id="s3-select-and-glacier-select">S3 Select and Glacier Select<a aria-hidden="true" class="anchor-heading icon-link" href="#s3-select-and-glacier-select"></a></h3>
<ul>
<li>Ways you can retrieve parts of objects rather than all of an object</li>
<li>S3 can store objects up to 5TB in size</li>
<li>Retrieving a whole object will take time</li>
<li>S3/Glacier select lets you use SQL like statements to select part of an object</li>
<li>Works on many file types such as CSV, JSON, Parquet, BZIP2 compression for CSV and JSON</li>
</ul>
<h3 id="s3-events">S3 Events<a aria-hidden="true" class="anchor-heading icon-link" href="#s3-events"></a></h3>
<ul>
<li>Allows you to create event notifications on a bucket</li>
<li>When enabled, a notification is delivered when something happens on a bucket. It can be delivered to SNS, SQS and lambda functions</li>
<li>Can be generated when objects are created (PUT, POST, COPY and Multi part upload)</li>
<li>Can be generated on Delete (as well as delete markers)</li>
<li>For object restores (start and end)</li>
<li>Replication events</li>
</ul>
<h3 id="s3-access-logs">S3 Access Logs<a aria-hidden="true" class="anchor-heading icon-link" href="#s3-access-logs"></a></h3>
<ul>
<li>Access logging provides detailed records for the requests that are made to a bucket. They are best effort - they are usually logged in target bucket within a few hours</li>
<li>Let you help the access patterns of your customer base</li>
</ul>
<h3 id="s3-object-lock">S3 Object Lock<a aria-hidden="true" class="anchor-heading icon-link" href="#s3-object-lock"></a></h3>
<ul>
<li>Enable on new S3 buckets only otherwise you will need to contact AWS for an existing</li>
<li>You cannot disable object lock or versioning</li>
<li>Write Once Read Many (WORM) - No delete, no overwrite</li>
<li>Requires versioning to be enabled and individual versions are locked</li>
<li>An object version can have one, both or none of <strong>retention period</strong> or <strong>legal hold</strong></li>
</ul>
<p>Retention Locking:</p>
<ul>
<li>Specified in days and years</li>
<li>The two types you can do:
<ol>
<li>Compliance mode - an object version can't be adjusted, deleted or overwritten for that period. The retention period and mode cannot be changed even by the account root user. This is the most strict form of object lock. This could be good for compliance reasons e.g. medical or legal</li>
<li>Governance - can grant special permissions to allow locking settings to be adjusted (s3:ByPassGovernanceRetention). Useful if you want to prevent accidental deletions</li>
</ol>
</li>
</ul>
<p>Legal Hold Locking:</p>
<ul>
<li>Set on object version either on or off, no retention period</li>
<li>You can't delete or change until removed</li>
<li>You need permission to add or remove the legal hold</li>
<li>Good to prevent accidental deletion of critical object versions</li>
</ul>
<h3 id="s3-access-points">S3 Access Points<a aria-hidden="true" class="anchor-heading icon-link" href="#s3-access-points"></a></h3>
<ul>
<li>A feature of S3 which improves the manageability of s3 buckets</li>
<li>Rather than having 1 bucket with 1 bucket policy you can conceptually split it into many access points with different policies</li>
<li>Each access point can be limited in terms of where they can be accessed from with it's own endpoint address</li>
<li>Can be created via the console of via the cli: <code>aws s3control create-access-point --name secretcats --account-id 12355423 --bucket catpics</code></li>
<li>You can think of access points as mini buckets or views. The DNS of each AP is given to a section of users and those mini buckets are individually controlled</li>
<li>Any definitions defined in the access point policy need to be defined in the bucket policy e.g. giving permission to certain users for the access point</li>
</ul>
<h2 id="virtual-private-cloud-vpc-basics">Virtual Private Cloud (VPC) Basics<a aria-hidden="true" class="anchor-heading icon-link" href="#virtual-private-cloud-vpc-basics"></a></h2>
<h3 id="vpc-sizing-and-structure">VPC Sizing and Structure<a aria-hidden="true" class="anchor-heading icon-link" href="#vpc-sizing-and-structure"></a></h3>
<ul>
<li>
<p>A private network inside AWS</p>
</li>
<li>
<p>You need to decide what IP range to use in advance - it's not easy to change later. There are a few things you should keep in mind:</p>
<ul>
<li>What size should the VPC be? This influences how many services can fit into the VPC</li>
<li>Are there any networks we can't use? Duplicate or overlapping ranges complicate things</li>
<li>Be mindful of other VPC ranges, other cloud envs, on premises, partners and vendors and their IP ranges</li>
<li>Try to plan for the future</li>
<li>Consider the VPC structure - tiers and resiliency</li>
</ul>
</li>
<li>
<p>A VPC can be at the smallest a /28 network (16 IP) and at most /16 (65536 IPs)</p>
</li>
<li>
<p>Avoid common ranges</p>
</li>
<li>
<p>Ranges can be determined by the number of regions a business operates in. A suggestion is to reserve 2+ networks per region being used per account
e.g. 3 US, Europe, Australia - 5 regions x 2 - Assume 4 accounts - total 40 ranges ideally</p>
</li>
<li>
<p>Deciding what size VPC to get, you should ask:</p>
<ul>
<li>How many subnets will you need in each VPC?</li>
<li>How many IP Addresses will you need in total ad how many per subnet?</li>
</ul>
</li>
<li>
<p>Services use subnets and subnets operate in 1 availability zone. THerefore you need to consider regions as some regions have more availability zones than others.</p>
<ol>
<li>pick how many AZs yours would use - possibly use 4 as a default. This means you need 4 smaller networks</li>
<li>A suggested default is to start with four tiers - Web, application, database and a spare. If you only used 1 az then you would each tier would need it's own subnet so 4 subnets</li>
</ol>
</li>
</ul>
<p><img src="/KnowledgeGarden/./assets/images/vpc-design.png" alt="VPC Design"></p>
<h3 id="custom-vpcs">Custom VPCs<a aria-hidden="true" class="anchor-heading icon-link" href="#custom-vpcs"></a></h3>
<ul>
<li>VPCs are a regionally isolated and regionally resilient service</li>
<li>Lets you create an isolated network in AWS</li>
<li>Nothing is allowed IN or OUT without explicit configuration</li>
<li>Flexible configuration</li>
<li>Hybrid networking</li>
<li>You have the option of created default or dedicated tenancy - allows you to either put the VPC in shared or dedicated hardware - If you put default you can change this later. If you put dedicated <strong>it's locked in and any resources on this vpc will have to be dedicated too</strong>. Only choose this if you really need it as it comes at a premium cost</li>
<li>Can use IPv4 private and public IPs</li>
<li>Private CIDR block is the main method of communication for the VPC</li>
<li>This primary block at it's smallest can be /28 (16 IP) and max /16 (65,536 IP)</li>
<li>You can create optional secondary IPv4 block</li>
<li>Can be configured to use IPv6 (/56). However, you can't pick a range, AWS chooses them for you unless you own specific IPv6 IPS</li>
</ul>
<p>DNS in a VPC:</p>
<ul>
<li>Provided by R53</li>
<li>Available on the base IP address of the VPC +2</li>
<li>enableDnsHostnames - gives public DNS hostnames to instances</li>
<li>enableDnsSupport - enables DNS resolution in VPC - if not then the dns won't work</li>
</ul>
<h3 id="vpc-subnets">VPC Subnets<a aria-hidden="true" class="anchor-heading icon-link" href="#vpc-subnets"></a></h3>
<ul>
<li>Subnets in VPCs start of entirely private and you need to configure them to be public</li>
<li>A subnet is an AZ resilient feature of the VPC</li>
<li>It's a subnetwork of a VPC within a particular AZ</li>
<li>1 subnet is created a specific AZ in that region. It can never be changed and can never ben in multiple AZs. ONE SUBNET => ONE AZ. Although one AZ can have 0 or more subnets</li>
<li>Allocated an IPv4 CIDR - it has to be within the range of the VPC</li>
<li>The CIDR that a subnet uses can't overlap with other subnets in that VPC</li>
<li>Can optionally be allocated an IPv6 CIDR block. A /64 subset of the /56 is allocated (256)</li>
<li>Subnets can communicate with other subnets in the VPC</li>
<li>Sizes of networks are based on the prefix</li>
<li>Some IPs in every VPC network are reserved</li>
</ul>
<p>Every VPC subnet has five addresses that cannot be used. Assuming the subnet we use is 10.16.16.0/20, the following can't be used:</p>
<ol>
<li>the network address (starting address) e.g. 10.16.16.0</li>
<li>Network + 1 (10.16.16.1) - used by the VPC router</li>
<li>Network + 2 (10.16.16.2) - Reserved by the DNS</li>
<li>Network + 3 (10.16.16.3) - For future use</li>
<li>Broadcast address 10.16.31.255 (Last IP in subnet)</li>
</ol>
<p>A VPC has a configuration object applied to it called a DHCP option set - (dynamic host configuration protocol) - how computing devices receive IP addresses automatically.</p>
<ul>
<li>On every subnet you can define two important allocation options:
<ol>
<li>Auto assign public IPv4 - allocated public addresses as well as their private automatically</li>
<li>Auto assign public IPv6</li>
</ol>
</li>
</ul>
<h3 id="vpc-routing-internet-gateway--bastion-hosts">VPC Routing, Internet Gateway &#x26; Bastion Hosts<a aria-hidden="true" class="anchor-heading icon-link" href="#vpc-routing-internet-gateway--bastion-hosts"></a></h3>
<p>VPC Router:</p>
<ul>
<li>Every VPC has a VPC router - it's highly available</li>
<li>In every subnet, the network+1 address is reserved for the vpc router</li>
<li>It routes traffic between subnets</li>
<li>It's controllable, you create route tables which influences what to do with traffic when it leaves the subnet</li>
<li>A VPC is created with a main route table - if you don't explicitly associate it, then it uses the main route table of the vpc. Otherwise if you create your own, the old one is dissociated. A subnet can only be associated with one route table at a time but a route table can be associated with many subnets</li>
<li>A route table is a list of routes - the vpc looks at the destination address, looks at the route table for the destination address and propagates the data to those destinations. It can be either to a single route or a range. The prefix is used as a priority - the higher the prefix the higher the priority</li>
<li>The target field in a route table is either pointing to a gateway or to local</li>
<li>All route tables have at least 1 route - the local route which matches the VPC CIDR range</li>
<li>If it's also ipv6 enabled it will have another default local route for ipv6</li>
<li>These local routes can never be updated, and those two will ALWAYS take priority</li>
</ul>
<p>Internet Gateway:</p>
<ul>
<li>Regional resilient gateway which can be attached to a VPC</li>
<li>you do not need a gateway per availability zone</li>
<li>a vpc can have no internet gateways or just one</li>
<li>a gateway can have no attachments or 1 at a time</li>
<li>Runs from the border of the VPC and the aws public zone - allows services to be reached from the internet (AWS public zone)</li>
<li>it's a managed gateway, aws handles the performance</li>
<li>Public ipv4 internet addresses never actually touch the services inside the VPC. A record is created which the internet gateway maintains. The instance itself is not configured with a public IP.</li>
</ul>
<p>baston Host / Jump boxes</p>
<ul>
<li>An instance in a public subnet inside a vpc</li>
<li>used to manage incoming connections</li>
<li>this allows you to access internal vpc resource - it's a management or entry point to private vpcs</li>
<li>It used to be the only way in to a vpc</li>
</ul>
<h3 id="stateful-vs-stateless-firewalls">Stateful vs Stateless Firewalls<a aria-hidden="true" class="anchor-heading icon-link" href="#stateful-vs-stateless-firewalls"></a></h3>
<ul>
<li>TCP and IP work together where TCP connection send IP packets</li>
<li>TCP runs on top of IP</li>
<li>A stateless firewall does not understand the state of connections. It needs two rules per inbound connection, an inbound and an outbound and 2 per outbound connection (inbound and outbound).</li>
<li>You will have to allow the full range of ephemeral ports allowed in stateless firewall since responding to a request in a stateless server goes back to a random requester port. This can be a security concern.</li>
<li>A stateful firewall is intelligent enough to identify the request and response components of a connection</li>
<li>you will only have to allow the request meaning the response is automatically allowed</li>
<li>You don't need to allow the full ephemeral port range because a stateful firewall is smart enough to know which port to open up for a request/response</li>
</ul>
<h3 id="network-access-control-lists-nacls">Network Access Control Lists (NACLs)<a aria-hidden="true" class="anchor-heading icon-link" href="#network-access-control-lists-nacls"></a></h3>
<ul>
<li>Can be thought of as a traditional firewall available in AWS vps</li>
<li>Connections within a subnet are not affected by NACLs but inbound/outbound crossing the subnet boundary are filtered by NACLs</li>
<li>NACLs have inbound and outbound rules - data entering and leaving the subnet. Remember a request and a response can be both inbound and outbound.</li>
<li>A VPC is created with a default NACL. Inbound/outbound rules have the implicit deny (*) and an ALLOW ALL rule. The result is all traffic is allowed, the NACL has no effect</li>
<li>Custom NACLs are created for a specific VPC and are initially associated with no subnets. The default rule for inbound and outbound is an implicit deny (*). This means all traffic is denied by default</li>
<li>NACL crossing subnets needs the correct inbound/outbound rules</li>
<li>NACLs can only be assigned to subnets in AWS</li>
<li>They can be used together with security groups to add explicit DENY</li>
<li>Each subnet can have one NACL associated to it (default or custom)</li>
<li>A single NACL can be associated with many subnets</li>
</ul>
<h3 id="security-groups-sg">Security Groups (SG)<a aria-hidden="true" class="anchor-heading icon-link" href="#security-groups-sg"></a></h3>
<ul>
<li>A second type of security filtering feature used in AWS VPC</li>
<li>SG's are stateful - they detect response traffic automatically for a given request</li>
<li>that means any IN or OUT request that is allowed will automatically allow a response - you don't have to worry about configuring ephemeral ports</li>
<li>The major limitation of SG's are that there is no EXPLICIT deny. You cannot block specific bad actors e.g. a range of or a single IP</li>
<li>Usually SGs and NACLs are used in conjunction for this reason</li>
<li>SG support iP/CIDR AND logical resources</li>
<li>This includes other security groups as well as itself</li>
<li>SGs are not attached to instances nor subnets, they are attached to specific elastic network interfaces known as ENIs</li>
<li>SG can use logical references - it can refer to other security groups so that you don't explicitly put IP ranges, any resource in that SG is allowed</li>
</ul>
<h3 id="network-address-translation-nat--nat-gateway">Network Address Translation (NAT) &#x26; NAT Gateway<a aria-hidden="true" class="anchor-heading icon-link" href="#network-address-translation-nat--nat-gateway"></a></h3>
<ul>
<li>A set of different processes by changing their source/destination IP addresses</li>
<li>IP Masquerading is a subset of NAT. IT can hide CIDR IP Blocks behind one IP i.e. many private IP to one public IP</li>
<li>Since IPv4 addresses are running out, giving many private CIDR range <strong>outgoing</strong> internet access</li>
<li>A NAT gateway takes all the incoming packets from all the instances it's managing and it records all the information about the communication. It takes those packets, changes the source address from those instances to it's own IP address (external facing address).</li>
<li>NAT Gateways need to be run from a public subnet so that you can assign an external IPv4 for it</li>
<li>Uses Elastic IPs (static ipv4 public)</li>
<li>AZ resilient service - to make it region resilient, you should but a nat gateway in each AZ and a routing table for each AZ in that NAT gateway as a target</li>
<li>Can get costly if you have a lot of AZs</li>
<li>They are a managed service, you deploy and AWS takes care of them</li>
</ul>
<p><img src="/KnowledgeGarden/./assets/images/natgw-resilience.png" alt="NATGW Full resilience"></p>
<ul>
<li>
<p>A NAT instance is when you make an EC2 instance run as a NAT instance</p>
</li>
<li>
<p>It's much easier and scalable to use a NAT gateway except for when:</p>
<ul>
<li>cost is an issue</li>
<li>for test purposes</li>
<li>need something free tier eligible</li>
<li>you need to connect to them like normal ec2 instances - NAT Gateway cannot be used as a bastion host nor can they do port forwarding</li>
<li>NAT Gateways don't support security groups, they can only use NACLs</li>
</ul>
</li>
<li>
<p>NAT is not required for IPv6</p>
</li>
<li>
<p>In AWS IPv6 addresses are all publicly routable</p>
</li>
<li>
<p><strong>Nat gateways DON'T work with IPV6</strong></p>
</li>
<li>
<p>if you add ::/0 route, that will give an internet gateway bidirectional connectivity for ipv6</p>
</li>
<li>
<p>You can use Egress Only internet gateway if you want outbound only connection for IPv6</p>
</li>
</ul>
<h2 id="elastic-compute-cloud-ec2-basics">Elastic Compute Cloud (EC2) Basics<a aria-hidden="true" class="anchor-heading icon-link" href="#elastic-compute-cloud-ec2-basics"></a></h2>
<h3 id="virtualization-101">Virtualization 101<a aria-hidden="true" class="anchor-heading icon-link" href="#virtualization-101"></a></h3>
<ul>
<li>EC2 provides virtualisation as a service (IaaS)</li>
<li>Virtualization is the process of running more than one operating system on a piece of physical hardware (a server)</li>
<li>Before virtualization, Applications would run on top of an OS in user mode. They cannot directly access hardware resources. If apps try to do that it would cause a system wide error or crash the application</li>
<li>Virtualization fixes this by allowing a single piece of hardware to run multiple OS' where each is separate.</li>
<li>Historically, virtualization was done in two ways:</li>
</ul>
<ol>
<li>Emulated Virtualization (software) - the OS still ran on the hardware on top of a hypervisor. The software ran in privileged mode. Each OS ran inside in a virtual machines. They have emulated hardware provided by the hypervisor. The main issue was that this method was slow.</li>
<li>Para-virtualization - only works on a small subset of OS that can be modified.</li>
</ol>
<p>The major improvement in virtualization came when the physical hardware became virtualization aware. This is known as hardware assisted virtualization. The CPU itself knowns virtualization exists. The hardware redirects privileged calls to the hypervisor.
The process of where the hardware devices themselves become virtualization aware is known as SR-IOV - single route I/O virtualization. Allows a network card or any other I/O card to present itself as not a single card but as several mini cards. These are presented to the guest operating system as real cards and hence the hypervisor doesn't need to be used - the OS can directly use it's card when it wants.</p>
<h3 id="ec2-architecture-and-resilience">EC2 Architecture and Resilience<a aria-hidden="true" class="anchor-heading icon-link" href="#ec2-architecture-and-resilience"></a></h3>
<ul>
<li>EC2 instances are virtual machines (OS + Resources)</li>
<li>Run on EC2 Hosts which are either shared or dedicated</li>
<li>Shared hosts are used by different AWS customers so you don't get ownership of hardware and you pay for usage and resource. There is still no visibility between customers when using shared hosts. Shared host is the default type of hosting</li>
<li>Dedicated hosts is dedicated to your account and you pay for the whole thing. You don't share it with any AWS customers.</li>
<li>EC2 is an <strong>AZ resilient service</strong> - Hosts run in a single AZ. If that AZ fails then hosts will fail and any instances on those hosts will fail or be impacted</li>
<li>EC2 have some local hardware: cpu, memory and storage (instance store). The instance store will be lost if the instance moves to another host. They also have storage and data networking.</li>
<li>EC2 can connect to network storage known as Elastic Block Store (EBS). EBS also rus inside an AZ. You can't access it cross zone.</li>
<li>If an availability zone in AWS has issues, it impacts ec2, subnets, storage and volumes.</li>
<li>An instance runs in a specific host and it will stay on that host when you restart it. It stays there unless it fails or is taken down by AWS. Also if it is stopped and started which is different to restarting. In that instance it will be relocated to another host but it will still be in the same AZ</li>
<li>You can never connect network interfaces or EBS storage in one AZ to an ec2 instance in another AZ</li>
</ul>
<p>EC2 is good when:</p>
<ul>
<li>When you have a traditional OS and compute need</li>
<li>Long running compute needs as it's designed for persistent long running compute requirements</li>
<li>You have server style applications</li>
<li>For burst or steady state load</li>
<li>For monolithic application stacks</li>
<li>For migrating application workloads or disaster recovery</li>
<li>EC2 tends to be the default compute service in AWS unless you have niche requirements.</li>
</ul>
<h3 id="ec2-instance-types">EC2 Instance Types<a aria-hidden="true" class="anchor-heading icon-link" href="#ec2-instance-types"></a></h3>
<p>Factors in choosing instances:</p>
<ul>
<li>CPU, memory, local storage capacity and type will influence which instance type you choose</li>
<li>Resource ratios can give you different ratios of different o resource which will also affect your decision</li>
<li>The amount of storage, data and network bandwidth</li>
<li>The architecture and vendor the instance is run on - x86, ARM, intel, AMD</li>
<li>Additional features and capabilities - GPUs, FPGAs</li>
</ul>
<p>EC2 instances are grouped into 5 main categories:</p>
<ol>
<li>General Purpose - default - should be first choice. even resource ratio, diverse workloads</li>
<li>Compute Optimized - Media Processing, High performance computing, scientific modelling, gaming, machine learning. Ratio is higher towards CPU</li>
<li>Memory Optimized - inverse of compute - ideal for applications for processing large in-memory datasets, database workloads</li>
<li>Accelerated computing - for additional capabilities e.g. hardware GPUs field programmable gate arrays (FPGAs)</li>
<li>Storage Optimized - fast local storage needs - sequential and random IO. Data warehouses, elastic search, data analytics</li>
</ol>
<p>Decoding EC2 Types:
Example: "R5dn.8xlarge"</p>
<ul>
<li>Letter at the start is the instance family - specific type/types of computing</li>
<li>Next (5) is the generation e.g. 5th generation of the family. The latest generation should ideally always be used</li>
<li>the part of the dot - the size "8xlarge" - the instance size</li>
<li>the "dn" - additional capability e.g n could mean network optimized</li>
</ul>
<p><img src="/KnowledgeGarden/./assets/images/ec2-instance-types.png" alt="EC2 Instance Types"></p>
<h3 id="storage-refresher">Storage Refresher<a aria-hidden="true" class="anchor-heading icon-link" href="#storage-refresher"></a></h3>
<p>Storage terms:</p>
<ul>
<li>Direct (local) attached storage - Storage on the EC2 Host. Fast but prone to loss</li>
<li>Network attached storage - volumes delivered over the network (EBS). Resilient but slower</li>
<li>Ephemeral Storage - temporary storage</li>
<li>Persistent Storage - Permanent storage - lives on past the lifetime of the instance</li>
</ul>
<p>Three main categories of storage available in AWS:</p>
<ol>
<li>Block storage - Create a volume that has addressable blocks. No structure provided. The OS usually takes the block storage and creates a file storage on it. Can be HDD or SSD or a logical storage that's backed by physical storage. You can mount and boot off this volume.</li>
<li>File storage - presented as a file server with a structure already there. Mountable but not bootable since the OS doesn't have low level access to it.</li>
<li>Object storage - Flat collection of objects. Not mountable or bootable.</li>
</ol>
<p>Storage Performance terms:</p>
<ul>
<li>I/O (block) size - the size of the blocks of data that you're writing to disk - KB/MB.</li>
<li>IOPS - input output operations per second - how many reads/writes a disk or storage system can accommodate in a second</li>
<li>Throughput - amount of data that can be transferred per second - MB/s. Relies on using the right block size and then maximising the number of IOPS</li>
</ul>
<p>IO X IOPS = THROUGHPUT</p>
<h3 id="elastic-block-store-ebs-service-architecture">Elastic Block Store (EBS) Service Architecture<a aria-hidden="true" class="anchor-heading icon-link" href="#elastic-block-store-ebs-service-architecture"></a></h3>
<ul>
<li>Provides block storage which can be addressed using block IDs. It takes raw physical discs, and presents a raw allocation of those disks known as volumes. These volumes can be written to or read from using a block number. They can be encrypted</li>
<li>When you attach a volume to an EC2 they see a block device and they can use it to create a file system on top of it (ext3/4, xfs). They appear just like any other storage design</li>
<li>Storage is provisioned in ONE AZ. It is separate and isolated within that AZ.</li>
<li>You can attach to one EC2 instance (or other service) over a storage network. There is a multi attach feature which allows to attach to multiple at a time but it needs to be managed so that there aren't multi writes</li>
<li>You can de-attach and reattach the EBS to another volume. EBS are persistent so if an instance moves or stops, restarts, the EBS is maintained</li>
<li>Snapshots can be taken of EBS volumes and they can be regionally resilient by migrating them between AZs and regions</li>
<li>EBS can provision different physical storage types, sizes and performance profiles</li>
<li>You are billed based on GB-month (and sometimes performance)</li>
</ul>
<p>You can't communicate across AZs for EBS</p>
<p><img src="/KnowledgeGarden/assets/images/ebs-sample-architecture.png" alt="EBS sample architecture"></p>
<h3 id="ebs-volume-types---general-purpose">EBS Volume Types - General Purpose<a aria-hidden="true" class="anchor-heading icon-link" href="#ebs-volume-types---general-purpose"></a></h3>
<p>GP2 - SSD:</p>
<ul>
<li>it's high performance storage for a low price.</li>
<li>from 1GB - 16TB</li>
<li>Allocated with IO credit of 16KB. IOPS is 16kb. 1 IOPS is 1 IO in 1 second</li>
<li>IO Credit bucket has a capacity of 5.4 million IO credits</li>
<li>Bucket fills with min 100 IO credits per second regardless of volume size</li>
<li>GP2 can burst up to 3000 IOPS by depleting the bucket</li>
<li>All volumes start with an initial 5.4 million IO credits</li>
<li>Maximum IO per second is 16,000</li>
<li>GP2 is flexible storage for general usage. It can be a default if GP3 isn't there yet</li>
</ul>
<p>GP3 - SSD:</p>
<ul>
<li>Removes the credit architecture of GP2</li>
<li>Starts at 3000 IOPS &#x26; 125 MiB/s</li>
<li>20% cheaper than GP2</li>
<li>You get benefits of GP2 with this</li>
<li>Extra cost for up to 16,000 IOPS or 1,000 MiBs</li>
</ul>
<h3 id="ebs-volume-types---provisioned-iops">EBS Volume Types - Provisioned IOPS<a aria-hidden="true" class="anchor-heading icon-link" href="#ebs-volume-types---provisioned-iops"></a></h3>
<p>io1/2 - SSD:</p>
<ul>
<li>IOPS is configured independently of the volume. Good for consistent low latency and jitter.</li>
<li>4x IOPS of gp2/3 (up to 64,000)</li>
<li>Block express gets you more IOPS and MiBs</li>
<li>There is a maximum performance that can be achieved - a per instance performance</li>
<li>Provisioned io can be good for low latency consistency with high levels of performance e.g. low volumes but high performance</li>
</ul>
<h3 id="ebs-volume-types---hdd-based">EBS Volume Types - HDD-Based<a aria-hidden="true" class="anchor-heading icon-link" href="#ebs-volume-types---hdd-based"></a></h3>
<ul>
<li>These volume types are slower</li>
</ul>
<p>Two types of storage in EBS:</p>
<ol>
<li>st1 - throughput optimised</li>
</ol>
<ul>
<li>cheap</li>
<li>125gb - 16tb</li>
<li>maximum of 500 IOPS - 1mb blocks - max of 500 MB/s</li>
<li>Useful for big data, data warehouses, log processing</li>
</ul>
<ol start="2">
<li>sc1 - cold HDD</li>
</ol>
<ul>
<li>cheaper</li>
<li>125gb - 16tb</li>
<li>designed for infrequent workloads - used for maximum economy where performance isn't as important</li>
<li>max 250 IOPS - max 250 MB/s</li>
<li>lowest cost ebs storage type</li>
<li>cold data with few scans a day</li>
</ul>
<h3 id="instance-store-volumes---architecture">Instance Store Volumes - Architecture<a aria-hidden="true" class="anchor-heading icon-link" href="#instance-store-volumes---architecture"></a></h3>
<ul>
<li>Block storage devices - raw volumes presented to an instance that present TEMPORARY storage</li>
<li>Like EBS except local</li>
<li>physically connected to one EC2 host</li>
<li>Instances on that host can access those volumes</li>
<li>High storage performance</li>
<li>Included in the instance price</li>
<li>Have to be attached at launch time - CANNOT be attached after like EBS</li>
<li>these are temporary volumes</li>
</ul>
<p><img src="/KnowledgeGarden/./assets//images/instance-store-volumes.png" alt="alt text"></p>
<ul>
<li>if you move an instance between hosts, that data is lost. They are given new ephemeral volumes.</li>
<li>if a physical volume fails, then the instance would lose that data</li>
<li>these should only be used for temporary data</li>
<li>some instance types don't support these</li>
<li>performance is a strength of instance store e.g. 4.6 GB/s - 16 GB/s throughput depending on HDD or SSD</li>
<li>More IOPS and Throughput VS EBS</li>
<li>Local to EC2 HOST</li>
<li>if the volume is resized the data is also lost</li>
<li>You pay for it with the instance so there is no advantage to not using them</li>
</ul>
<h3 id="choosing-between-the-ec2-instance-store-and-ebs">Choosing between the EC2 Instance Store and EBS<a aria-hidden="true" class="anchor-heading icon-link" href="#choosing-between-the-ec2-instance-store-and-ebs"></a></h3>
<ul>
<li>Persistence required - default to EBS (avoid Instance store)</li>
<li>Resilience - as above</li>
<li>If you need storage isolated from instance lifecycles then use EBS</li>
<li>If your instance requires resilience but your app supports built-in replication, you could use lots of instances</li>
<li>If you need high performance - both could be good although super high performance, instance store makes more sense</li>
<li>If cost is a concern, instance store makes sense as it comes with the instance</li>
</ul>
<p>REMEMBER these figures:</p>
<ul>
<li>If you need cheap storage but with EBS, use ST1 or SC1 because they are cheaper</li>
<li>Throughput or streaming should default to DT1</li>
<li>if you need a boot volume NEITHER ST1 OR SC1 are suitable</li>
<li>GP/2 - can deliver up to 16,000 IOPS</li>
<li>IO1/2 - up to 64,000 IOPS (*256,000 for block express for large instance types)</li>
<li>RAID0 + EBS can achieve 260,000 IOPS (io1/2-BE/GP2/3 combination)</li>
<li>If you need more than 260,000 and you can deal with less resilience or no persistence, then use Instance Store</li>
</ul>
<p>These figures are important to remember:
<img src="/KnowledgeGarden/./assets/images/instance-store-ebs.png" alt="ec2 instance store vs ebs"></p>
<h3 id="snapshots-restore--fast-snapshot-restore-fsr">Snapshots, Restore &#x26; Fast Snapshot Restore (FSR)<a aria-hidden="true" class="anchor-heading icon-link" href="#snapshots-restore--fast-snapshot-restore-fsr"></a></h3>
<ul>
<li>Backup volumes to s3</li>
<li>Protect against AZ issues, migrate data between AZs</li>
<li>Snapshots become region resilient</li>
<li>Incremental in nature - the first is a full copy of the data on the volume</li>
<li>Future snapshots only store the difference - consume less space and are quicker to perform</li>
<li>If you accidentally delete a snapshot, future snapshots will fix any lost saves</li>
<li>EBS volumes can be blank or based on a restored snapshot</li>
<li>Snapshots can be copied between regions</li>
</ul>
<p><img src="/KnowledgeGarden/./assets/images/EBS-snapshots.png" alt="Ebs Snapshot architecture"></p>
<p>Nuances to Snapshot/volume performance:</p>
<ul>
<li>Snaps restore lazily - fetched gradually</li>
<li>Fast Snapshot Restore (FSR) is an option to immediately restore</li>
<li>Up to 50 FSR snaps per region can be restored. Set on the Snap and AZ.</li>
<li>FSR costs extra and can get expensive</li>
<li>You can achieve the same end result by manually getting the OS to read all the data in s3 which forces the requested blocks to be pulled in</li>
<li>Snapshots are billed at Gigabyte per month</li>
<li>The data stored is the USED not the allocated data e.g if you use 10 of 40gb only 10gb is stored and billed on</li>
</ul>
<h3 id="ebs-encryption">EBS Encryption<a aria-hidden="true" class="anchor-heading icon-link" href="#ebs-encryption"></a></h3>
<ul>
<li>EBS is not encrypted by default</li>
<li>EBS Encryption uses a KMS key using either a default KMS/EBS key or a customer managed key</li>
<li>The key is used to create a data encrypted key (DEK)</li>
<li>What is stored in the EBS is encrypted and what is in the instance's memory is the decrypted version</li>
<li>Any snapshot of the EBS will also be encrypted with the same key</li>
<li>It doesn't cost anything to use so you should use it by default</li>
<li>Accounts can be set up to encrypt EBS by default</li>
<li>Each volume uses a 1 unique DEK</li>
<li>If you create any EBS volumes from a snapshot with an encryption key, it uses that same DEK</li>
<li>You can't change a volume NOT to be encrypted</li>
<li>OS isn't aware of the encryption therefore there is no performance loss</li>
</ul>
<h3 id="network-interfaces-instance-ips-and-dns">Network Interfaces, Instance IPs and DNS<a aria-hidden="true" class="anchor-heading icon-link" href="#network-interfaces-instance-ips-and-dns"></a></h3>
<ul>
<li>
<p>Instances all start of with 1 network interface (a primary ENI - Elastic Network Interface)</p>
</li>
<li>
<p>Network interfaces need to be in the same AZ as an instance</p>
</li>
<li>
<p>Network instances have a MAC address which is the hardware address</p>
</li>
<li>
<p>Network instances have a primary IPv4 Private IP</p>
</li>
<li>
<p>0 or more secondary private IPs - doesn't change for the lifetime of the instance</p>
</li>
<li>
<p>0 or 1 public IPv4 address - dynamic and will change e.g. when you stop and start an instance (not restarts)</p>
</li>
<li>
<p>1 elastic IP per private IPv4 address - assigning this means the instance will remove the dynamic public IPv4</p>
</li>
<li>
<p>0 or more Ipv6 addresses (these are publicly routable)</p>
</li>
<li>
<p>Security groups</p>
</li>
<li>
<p>Per interface you can enable/disable source/destination check</p>
</li>
<li>
<p>Secondary interfaces can be moved to other instances</p>
</li>
<li>
<p>you might use different network interfaces for different security groups</p>
</li>
<li>
<p>OS never sees the public IPv4 - this is performed by the internet gateway - You will NEVER configure an IPv4 public address</p>
</li>
<li>
<p>Public DNS will resolve to the primary private IP in the VPC. Instance to instance communication will not leave the VPC because of this. Everywhere else, it resolves to the public IP address.</p>
</li>
</ul>
<h3 id="amazon-machine-images-ami">Amazon Machine Images (AMI)<a aria-hidden="true" class="anchor-heading icon-link" href="#amazon-machine-images-ami"></a></h3>
<ul>
<li>Images of EC2 - you can create a template of an instance configuration and use that template to create other instances</li>
<li>When you create an instance you're using AWS provided AMIs but you can create your own</li>
<li>AMIs can be AWS or Community provided as well e.g. Redhat, Centos, Ubuntu</li>
<li>Marketplace also provide AMIs which include commercial software</li>
<li>AMIs are regional and they have a unique ID (ami-[letters, numbers])</li>
<li>AMIs can control permissions (public, your account, specific accounts)</li>
<li>You can create an AMI from an existing EC2 instance</li>
</ul>
<p>AMI Lifecycle:</p>
<ol>
<li>Launch - create an instance from AMI</li>
<li>Configure - Customising your instance</li>
<li>Create image - Creating a new AMI from the instance - Snapshots are also taken of EBS volumes and they are references by the AMI as block device mapping</li>
<li>Launch - when the AMI is used to create a new instance, it will have the same EBS volume as the original</li>
</ol>
<ul>
<li>AMI's are in ONE region. Only works in that region but it can be used to deploy into all AZs in that region</li>
<li>AMI Baking - creating an AMI from configured instance</li>
<li>AMI <strong>can't be edited</strong> - you need to launch an instance, update the config and make a new AMI</li>
<li>AMI can be copied between regions but they become SEPARATE AMIs</li>
<li>Permissions of AMI by default is your account - it can be private, public or given to specific accounts</li>
</ul>
<h3 id="ec2-purchase-options">EC2 Purchase Options<a aria-hidden="true" class="anchor-heading icon-link" href="#ec2-purchase-options"></a></h3>
<ul>
<li>Sometimes known as launch types
On demand:
<ul>
<li>default</li>
<li>Instances of different sizes run on the same EC2 hosts with different AWS customers.</li>
<li>On demand uses per second billing while instances are running. Associated storage e.g. storage will charge even when the instances are shut down</li>
<li>For all projects, assume on demand and move only when needed</li>
<li>No interruptions</li>
<li>Will not give you priority access if there are any failures</li>
<li>Predictable pricing, upfront costs but no discounts</li>
<li>Good for short term workloads or unknown workloads</li>
<li>For apps that can't be interrupted</li>
</ul>
</li>
</ul>
<p>Spot pricing:</p>
<ul>
<li>Cheapest</li>
<li>AWS sells spare capacity in an EC2 host at a discounted rate (up to 90% discount)</li>
<li>Will charge up to your maximum price before terminating any of your instances</li>
<li>Never use SPOT for workloads which can't tolerate interruptions</li>
<li>Good fits for SPOT workloads are things that are not time critical or can tolerate interruption/re-run e.g. media processing</li>
</ul>
<p>Reserved instances:</p>
<ul>
<li>For long term consistent usage of EC2</li>
<li>Reduce the per-second cost or remove it entirely</li>
<li>It's possible to reserve and not use and therefore still be built</li>
<li>You can commit for 1 year of 3 years - the longer the more discounted but you need to be careful of wasted resource</li>
<li>You can choose to pay no upfront - per second fee</li>
<li>You can choose upfront means no per second fee so you get the greatest discount here</li>
<li>Partial upfront - pay a smaller lump sum in advance for a lower per-second cost</li>
</ul>
<p>Dedicated host:</p>
<ul>
<li>An EC2 host that is dedicated to you in it's entirety</li>
<li>You pay for the host - the instances on the host you don't pay for so they can be any size up until the capacity</li>
<li>You have a feature called host affinity - stopping and starting instances means that they can stay on the same host</li>
<li>A good use case for dedicated host is you are using software that has licensing based on socket and core</li>
</ul>
<p>Dedicated Instances:</p>
<ul>
<li>A middle ground - instances run on ec2 hosts with other instances of yours and no other customers use the same hardware. You don't pay for the host nor share. You don't to manage the host itself</li>
<li>You have to pay one off hourly fee for any regions where you use them</li>
<li>A fee for the dedicated industry itself</li>
<li>This is where you may be an industry where you cannot use the same underlying hardware as other customers</li>
</ul>
<p>Focus : On-demand, spot and reserved for the exam</p>
<h3 id="reserved-instances---the-rest">Reserved Instances - the rest<a aria-hidden="true" class="anchor-heading icon-link" href="#reserved-instances---the-rest"></a></h3>
<ul>
<li>If you need access to the cheapest ec2 running all the time then you would pick standard reserved</li>
<li>Scheduled reserved:</li>
<li>are great for when you have long term requirements but when it doesn't need to be run constantly e.g. batch processing</li>
<li>If you reserve for that time window that's the only time you can use it</li>
<li>Doesn't support all instance types and regions. 1,200 hours per year and 1 year minimum terms</li>
<li>Capacity reservations
<ul>
<li>have a requirement for some compute that you can guarantee you can launch when you need</li>
<li>You can purchase a reservation and make it a regional one, you get billing discounts on instances in the AZ. They don't reserve capacity within an AZ which is risky during major faults when capacity can be limited</li>
<li>You can pick a zonal reservation - only apply to one AZ providing billing discounts and capacity reservation in that AZ</li>
<li>Regional/AZ are both 1 or 3 year commitment - you can choose on demand capacity reservation - can be booked to ensure you always have access to capacity in an AZ when you need it but at full on demand price. You will pay regardless of whether you consume it</li>
</ul>
</li>
</ul>
<p>Savings plan:</p>
<ul>
<li>an hourly commit for 1-3 years and you get a reduction</li>
<li>You can make a reservation for general compute amounts</li>
<li>Or a specific EC2 savings plan</li>
</ul>
<h3 id="instance-status-checks--auto-recovery">Instance Status Checks &#x26; Auto Recovery<a aria-hidden="true" class="anchor-heading icon-link" href="#instance-status-checks--auto-recovery"></a></h3>
<ul>
<li>Every instance has two high level per instance checks:
<ol>
<li>Systems status - failure could mean loss of system power, loss of network connectivity, host software issues, hardware issues</li>
<li>Instance status - corrupt file system, incorrect instance networking, OS kernel issues</li>
</ol>
</li>
<li>You can manually stop/restart an instance to fix status checks otherwise you can set up auto-recovery</li>
</ul>
<h3 id="horizontal--vertical-scaling">Horizontal &#x26; Vertical Scaling<a aria-hidden="true" class="anchor-heading icon-link" href="#horizontal--vertical-scaling"></a></h3>
<ul>
<li>Two different ways to handle increasing and decreasing load on the system</li>
</ul>
<p>Vertical scaling:</p>
<ul>
<li>Use a bigger server e.g. using a different ec2 instance i.e. go from t3.large to t3.xlarge</li>
<li>There will be downtime when you do this - you should do it during an outage window</li>
<li>Larger instance carry a price premium</li>
<li>there is an upper cap on the performance of an instance</li>
<li>No application modification required</li>
<li>works for all applications even monolithic</li>
</ul>
<p>Horizontal scaling:</p>
<ul>
<li>Instead of increasing the size of an individual instance, you add more instances with load</li>
<li>Instead of one running copy of your application you will have multiple that need to work together</li>
<li>For that reason you will need a load balancer usually so that the load is distributed across the instances</li>
<li>Sessions handling is important - since you may be shifting between instances constantly - you would need application support or <strong>off-host sessions</strong> which means that the session is stored somewhere else e.g. another db</li>
<li>Using off-host sessions would mean the application is stateless - the application doesn't care which instance you connect to</li>
<li>You have no disruption while you're scaling - customer connections remain unaffected and if the sessions are externally hosted it wouldn't matter if you scale down either</li>
<li>There are no real limits to horizontal scaling</li>
<li>Often less expensive - no large instance premium</li>
<li>more granular in terms of resource management</li>
</ul>
<h3 id="instance-metadata">Instance Metadata<a aria-hidden="true" class="anchor-heading icon-link" href="#instance-metadata"></a></h3>
<ul>
<li>A service EC2 provides to instances where you can access data about an instance</li>
<li>Used to configure and manage an instance</li>
<li>Accessible inside all instances - you access it via the IP: <a href="http://169.254.169.254">http://169.254.169.254</a> -> <a href="http://169.254.169.254/latest/meta-data/">http://169.254.169.254/latest/meta-data/</a></li>
<li>Data/information provided:
<ul>
<li>environment</li>
<li>networking</li>
<li>authentication</li>
<li>user-data</li>
<li>NOT AUTHENTICATED or ENCRYPTED - if you connect to an ec2 you can access this. You can restrict it with a firewall for extra money</li>
</ul>
</li>
</ul>
<h2 id="containers--ecs">Containers &#x26; ECS<a aria-hidden="true" class="anchor-heading icon-link" href="#containers--ecs"></a></h2>
<h3 id="introduction-to-containers">Introduction to Containers<a aria-hidden="true" class="anchor-heading icon-link" href="#introduction-to-containers"></a></h3>
<ul>
<li>A container is similar to a VM in that in provides an isolated environment</li>
<li>Where virtual machines run a whole isolated OS, a container runs as a process within the host operating system</li>
<li>The processes are like isolated OS</li>
<li>Containers are much lighter than virtual machines since they don't need to run a full OS</li>
<li>A container is a running copy of a docker image</li>
<li>Docker images are a stack of layers created using a docker file</li>
<li>Docker images are how we create a docker container - a running copy of a docker image</li>
<li>A container registry is a hub of container images - it can be private or public e.g. docker hub</li>
</ul>
<p>Container key concepts:</p>
<ul>
<li>Dockerfiles are used to build images</li>
<li>Containers are portable, self contained and always run as expected</li>
<li>Containers and images are super lightweight</li>
<li>Containers only run the application and environment it needs</li>
<li>Provide much of the isolation VMs do</li>
<li>Ports are 'exposed' to the host and beyond</li>
</ul>
<h3 id="ecs---concepts">ECS - Concepts<a aria-hidden="true" class="anchor-heading icon-link" href="#ecs---concepts"></a></h3>
<ul>
<li>
<p>ECS is a product that allows you to run containers fully or partially managed by AWS - it takes away much of the admin overhead of managing containers</p>
</li>
<li>
<p>ECS to containers is what ec2 is to virtual machines</p>
</li>
<li>
<p>ECS uses clusters which runs in two modes: ec2 mode which uses ec2 instances as container hosts or fargate mode which is a serverless way of running docker containers</p>
</li>
<li>
<p>ECS lets you create a cluster</p>
</li>
<li>
<p>AWS also have a container registry called ECR (elastic container registry)</p>
</li>
<li>
<p>A task in ECS represents the container as a whole</p>
</li>
<li>
<p>A task role is the IAM role a task can assume to interact with AWS resources - a task role is the best way to give permission to containers</p>
</li>
<li>
<p>Tasks and containers are separate things. A task can include one or more containers.</p>
</li>
<li>
<p>A service definition is how we can define a task to scale and how we want it to run</p>
</li>
<li>
<p>A container definition - defines the image and ports that will be used for a container - points to a container image in a registry</p>
</li>
<li>
<p>A task definition applies to the application as a whole. It can be a single container definition or multiple containers and multiple container definitions. It's also where you define a task role and the resources that your task is going to consume</p>
</li>
<li>
<p>A task role is the IAM role which hte task assumes</p>
</li>
<li>
<p>Service - how many copies of a task you want to run, High availability, restarts</p>
</li>
</ul>
<h3 id="ecs---cluster-mode">ECS - Cluster Mode<a aria-hidden="true" class="anchor-heading icon-link" href="#ecs---cluster-mode"></a></h3>
<p>EC2 cluster types defines a number of things but one of them is how much admin overhead surrounding running a set of container hosts that you manage vs how many AWS manage.</p>
<p>EC2 Mode:</p>
<ul>
<li>Start with an ECS management component (also exists in fargate) - handle high level tasks</li>
<li>An ECS cluster is created within VPC in your AWS account - benefits from the multiple AZs</li>
<li>EC2s are used to run containers</li>
<li>Auto scaling groups are used</li>
<li>If you want to use containers in your infrastructure but you want to also manage host capacity and availability then EC2 mode is the appropriate choice</li>
<li>With EC2 mode, even if you're not running any tasks or services in your containers, you will still be paying for them while they're running</li>
</ul>
<p>Fargate mode:</p>
<ul>
<li>removes more overhead</li>
<li>you have no servers to manage - you won't have to pay for EC2 instances</li>
<li>AWS have a shared fargate infrastructure</li>
<li>Fargate still operates in VPC and across AZ</li>
<li>Tasks and services run on the shared infrastructure platform and are then injected into your VPC - they're given network interfaces inside the VPC</li>
<li>You only pay for the containers you are using based on the resources they consume - you don't need to manage or provision hosts</li>
</ul>
<p>EC2 vs ECS (EC2) vs Fargate:</p>
<ul>
<li>if you use containers, use ECS over EC2</li>
<li>Pick EC2 mode when you have a large workload and price conscious organisation - you can use reserved pricing and try to optimise</li>
<li>Large workload but overhead conscious - use fargate</li>
<li>Small or burst style workloads - fargate makes sense as you only use for the resources the container uses</li>
<li>batch/periodic workloads - fargate</li>
</ul>
<h3 id="elastic-container-registry-ecr">Elastic Container Registry (ECR)<a aria-hidden="true" class="anchor-heading icon-link" href="#elastic-container-registry-ecr"></a></h3>
<ul>
<li>ECR is a managed container image registry service - like docker hub but for AWS</li>
<li>We have public and private registries - each aws is provided with one of each.</li>
<li>Each registry can have many repositories (think of github)</li>
<li>Inside each repo you can have many container images and these can have several tags.</li>
<li>The tags need to be unique within your repository</li>
<li>public registry means that anyone can have read only access to anything within that repo (read write needs permission)</li>
<li>private registry means permission required for read only OR read write</li>
<li>ECR is integrated with IAM for permission</li>
<li>Image scanning is either in basic or enhanced (using inspector product)</li>
<li>ECR provides near real time metrics - delivered into cloud watch (auth, push, pull)</li>
<li>ECR logs all api actions into cloud trail</li>
<li>Generates events that are pushed to eventbridge</li>
<li>offers replication cross region and cross-account</li>
</ul>
<h3 id="kubernetes-101">Kubernetes 101<a aria-hidden="true" class="anchor-heading icon-link" href="#kubernetes-101"></a></h3>
<ul>
<li>Open source container orchestration system - use it to automate the deployment, scaling and management of containerised applications</li>
<li>A cloud agnostic product so you can use it on many cloud platforms</li>
<li>A kubernetes cluster is a highly available cluster of compute resources which are organised to work as one unit</li>
<li>The cluster starts with a cluster control plane - it manages the cluster, scheduling, applications, deploying</li>
<li>Cluster nodes are VM or Physical servers which function as a worker in the cluster - they run the containerized applications</li>
<li>containerd or docker is the software for handling container operations</li>
<li>kubelet is the agent to interact with the cluster control plane</li>
<li>kubelet interacts with the control plane using kubernetes API</li>
<li>Pods are the smallest unit of computing in kubernetes. It's common to see one container one pod architecture</li>
<li>You could run multiple containers in a pod but it's usually when they're tightly coupled and are in close proximity</li>
<li>You will rarely manage pods directly - they are temporary</li>
<li>kube-api server is the front end for kubernetes control plane</li>
<li>etcd provides a highly available key-value store - main backing store</li>
<li>kube-scheduler - responsible for checking pods that don't have a node assigned - will assign based on constraints</li>
<li>optional component - cloud-controlled-manager - provides cloud specific control logic i.e. AWS/azure/GCP</li>
<li>kube controller manager - cluster controller processing - node controller, job controller, endpoint controller, service account &#x26; token controllers</li>
<li>on every node - kube proxy is a network proxy - it coordinates networking with the control plane</li>
</ul>
<p>summary terms:</p>
<ul>
<li><strong>cluster</strong> deployment of kubernetes</li>
<li><strong>node</strong> - resources: pods are placed on nodes</li>
<li><strong>pods</strong> - smallest unit in kubernetes - often 1 container 1 pod</li>
<li><strong>services</strong> - an abstraction from pods - service running on 1 or more pods</li>
<li><strong>job</strong> - ad-hoc, creates one or more pods until completion</li>
<li><strong>ingress</strong> - exposes a way into a service</li>
<li><strong>ingress controller</strong> - used to provide ingress e.g. AWS LB controller</li>
<li><strong>Persistent storage (PV)</strong> - provision long running storage to your applications</li>
</ul>
<h3 id="elastic-kubernetes-service-eks-101">Elastic Kubernetes Service (EKS) 101<a aria-hidden="true" class="anchor-heading icon-link" href="#elastic-kubernetes-service-eks-101"></a></h3>
<ul>
<li>A fully-managed kubernetes implementation that simplifies the process of building, securing, operating and maintaining kubernetes clusters</li>
<li>Can run on AWS, outposts, EKS anywhere, EKS distro - open source</li>
<li>Control plane is managed by AWS and scales based on load across multiple AZs</li>
<li>Integrates with other AWS services - ECR, ELB, IAM, VPC</li>
<li>EKS Cluster = EKS Control Plane &#x26; EKS Nodes</li>
<li>etcd is distributed across multiple AZs</li>
<li>Nodes can be self managed, or managed groups or fargate pods - deciding between these is checking the node type and what it needs</li>
<li>For persistent storage - can use EBS, EFS, FSx</li>
</ul>
<h2 id="advanced-ec2">Advanced EC2<a aria-hidden="true" class="anchor-heading icon-link" href="#advanced-ec2"></a></h2>
<h3 id="bootstrapping-ec2-using-user-data">Bootstrapping EC2 using User Data<a aria-hidden="true" class="anchor-heading icon-link" href="#bootstrapping-ec2-using-user-data"></a></h3>
<ul>
<li>
<p>Bootstrapping is the process of bringing an instance with a certain pre-configured state</p>
</li>
<li>
<p>Bootstrapping is a general term outside of AWS</p>
</li>
<li>
<p>Within EC2 it can allow build automation</p>
</li>
<li>
<p>Bootstrapping in EC2 is enabled using ec2 User Data - accessed via the meta-data IP (169.254.196.254/latest/user-data)</p>
</li>
<li>
<p>Anything in the user data is executed by the instance OS</p>
</li>
<li>
<p>Executed ONLY on the FIRST initial launch</p>
</li>
<li>
<p>EC2 doesn't interpret, the OS needs to understand the User Data</p>
</li>
<li>
<p>EC2 on launch checks User Data and executes it or errors on a bad config</p>
</li>
<li>
<p>User data:</p>
<ul>
<li>is opaque to EC2 - it is just a block of data</li>
<li>not secure - don't use it for passwords or long term credentials</li>
<li>limited to 16kb in size</li>
<li>can be modified but the contents are only executed ONCE on launch</li>
</ul>
</li>
</ul>
<p>Boot time to service time - how quickly after you launch an instance is it ready to use</p>
<ul>
<li>For an aws managed AMI it's usually in minutes</li>
<li>You can do the work in advance by AMI baking</li>
<li>the optimal way is to combine bootstrapping and baking - use AMI baking for any part of the process that is time intensive</li>
</ul>
<h3 id="enhanced-bootstrapping-with-cfn-init">Enhanced Bootstrapping with CFN-INIT<a aria-hidden="true" class="anchor-heading icon-link" href="#enhanced-bootstrapping-with-cfn-init"></a></h3>
<ul>
<li>A way you can pass complex bootstrapping instructions to EC2 instances</li>
<li>cfn-init is a helper script which is installed on EC2 OS</li>
<li>User data is procedural where as cfn-init is the desired state (declarative)</li>
<li>can work with packages, groups, users, sources, files, commands and services</li>
<li>Provided with directives via Metadata and AWS::CLoudFormation:Init on a CFN resource</li>
<li>Unlike with user-data that only works on first launch, cfn-init can work with stack updates so that it can execute again and update the configuration of that instance</li>
</ul>
<p>Cloudformation creation policies and signals:</p>
<ul>
<li>Creation policies is something that is added to a logical resource with a timeout value. It waits for a signal from the resource as either a success or error. The resource in cloud formation will show that there is an error if there is one</li>
</ul>
<h3 id="ec2-instance-roles--profile">EC2 Instance Roles &#x26; Profile<a aria-hidden="true" class="anchor-heading icon-link" href="#ec2-instance-roles--profile"></a></h3>
<ul>
<li>EC2 instance roles are roles that an instance can assume and anything running in that instance has those permissions</li>
<li>An instance profile is a wrapper around an IAM role, it's a way to put the credentials into an instance. This is what gets attached to an ec2 instance.</li>
<li>The credentials are delivered by tbe instance meta-data. The credentials are always renewed before they expired. It will never be in a position where they expire. (automatically rotated)</li>
<li>Credentials are in /iam/security-credentials/role-name</li>
<li>Always use roles where possible - they are always preferable to use as opposed to long term credentials</li>
<li>CLI tools use ROLE credentials automatically</li>
</ul>
<h3 id="ssm-parameter-store">SSM Parameter Store<a aria-hidden="true" class="anchor-heading icon-link" href="#ssm-parameter-store"></a></h3>
<ul>
<li>Parameter store is a storage for configuration and secrets</li>
<li>Many AWS services integrate with Parameter store natively</li>
<li>Allows you to store 3 different types of parameters: String, StringList, SecureString</li>
<li>You can store License codes, database strings, full configs and passwords</li>
<li>Allows you to store in hierarchies and use versioning</li>
<li>Can store plaintext and ciphertext (can integrate with KMS)</li>
<li>Public parameters available e.g latest AMIs per region</li>
<li>anything using it needs to be an AWS service or have access to the public endpoints</li>
</ul>
<h3 id="system-and-application-logging-on-ec2">System and Application Logging on EC2<a aria-hidden="true" class="anchor-heading icon-link" href="#system-and-application-logging-on-ec2"></a></h3>
<ul>
<li>Cloudwatch is for metrics and cloudwatch logs is for logging</li>
<li>Neither of those products natively capture data inside an instance</li>
<li>A cloudwatch agent is required - it runs in the ec2 instance and captures OS visible data and sends it to cloudwatch or cloudwatch logs</li>
<li>It needs the configuration and permissions to be able to access and send that data</li>
</ul>
<h3 id="ec2-placement-groups">EC2 Placement Groups<a aria-hidden="true" class="anchor-heading icon-link" href="#ec2-placement-groups"></a></h3>
<ul>
<li>EC2 usually selects an AZ for you when you launch an instance</li>
<li>Placement groups ensure that instances are physically close together or not</li>
<li>There are three types of placement groups:</li>
</ul>
<ol>
<li>Cluster - any instances in a single cluster placement group are physically close together</li>
<li>Spread - the inverse where instances are kept separate</li>
<li>Partition - for distributed and replicated applications where each group is on different hardware</li>
</ol>
<p>Best practice with cluster group is to launch all the instances at the same time.
Typically instances in the same group are usually on the same rack, sometimes the same host. They have a direct connection to each other which ensures there is speedy communication between them. Lowest latency and max PPS possible in AWS.</p>
<p><strong>Cluster placement groups</strong> are used when you really need performance. The con is that there are little resilience because if the AZ goes down the whole cluster goes down.</p>
<ul>
<li>You can't span cluster placement groups across AZs - they must be on ONE AZ only and this is locked when launching first instance</li>
<li>You can span VPC peers but it will signifcantly impact performance</li>
<li>Not supported on every instance type</li>
<li>You should use the same type of instance (although it's not mandatory)</li>
<li>You should launch them at the same time (this is again not mandatory but <strong>very recommended</strong>).</li>
<li>Offer 10gbps single stream performance</li>
<li>Use cases: Performance, fast speeds, low latency e.g. high compute</li>
</ul>
<p><strong>Spread placement groups</strong>:</p>
<ul>
<li>designed to ensure the maximum amount of availability and resilience</li>
<li>Can be across availability zones</li>
<li>Instances are on separate racks so if a rack fails, it won't affect the other instances</li>
<li>There is a limit to 7 instances per AZ</li>
<li>Provides infrastructure isolation - every instance will be entirely separate from every other instance in that spread placement group</li>
<li>each instance runs from a different rack with its own network and power source</li>
<li>You can't use dedicated instances or hosts</li>
<li>Use case: small number of critical instances that need to be kept separate from each other</li>
</ul>
<p><strong>Partition placement groups</strong>:</p>
<ul>
<li>Similar to spread groups</li>
<li>Designed for when you have infrastructure where you have more than 7 instances per AZ but you still have a requirement to separate them</li>
<li>Can be created across multiple AZs and you must specify the number of partitions per AZ with a maximum of 7 partitions per AZ.</li>
<li>Each partition has it's own rack and power</li>
<li>You can launch as many instances as you need per partition and you can either select the partition explicitly or have AWS make that decision on your behalf</li>
<li>Great for topology aware applications such as HDFS, HBase and Cassandra</li>
<li>Can help topology aware applications contain the impact of a failure to part of an application</li>
</ul>
<h3 id="dedicated-hosts">Dedicated Hosts<a aria-hidden="true" class="anchor-heading icon-link" href="#dedicated-hosts"></a></h3>
<ul>
<li>A dedicated host is an EC2 host that is dedicated to you in it's entirety</li>
<li>the host is designed for a specific family of instances e.g. a1, c5, m5 etc</li>
<li>No instance charges - you pay for the host</li>
<li>Can either pay on demand or reserve options</li>
<li>Host hardware comes with a certain number of physical sockets and cores - this dictates how many instances can be run and some software is licensed on the number of sockets and cores of the hardware</li>
<li>Older hosts required all the instances to be the same size but newer ones allow you to mix sizes</li>
</ul>
<p>Limitations and features:</p>
<ul>
<li>AMI Limits - you can't use RHEL, SUSE linux, Windows AMIs</li>
<li>Can't use Amazon RDS instances</li>
<li>Can't use placement groups</li>
<li>Hosts can be shared with other accounts in the org using RAM (resource access manager) and those other accounts can create instances on that host. They can only see the instances they created only. You as the owner of the host cannot control the ones that are created by other accounts</li>
<li>Dedicated hosts are generally used for software licensing / licensing issues. It's not typically the approach you would take just for running EC2 instances</li>
</ul>
<h3 id="enhanced-networking--ebs-optimized">Enhanced Networking &#x26; EBS Optimized<a aria-hidden="true" class="anchor-heading icon-link" href="#enhanced-networking--ebs-optimized"></a></h3>
<ul>
<li>Enhanced network is a feature which is designed to improve the overall performance of EC2 networking</li>
<li>Required for any high end performance features such as cluster placement groups</li>
<li>Uses SR-IOV - Makes it so a physical network interface in an EC2 instance is aware of virtualization</li>
<li>Offers logical cards per physical card - gives each instance exclusive access to each logical card. Handles the process end to end without consuming the host process' CPU</li>
<li>Higher I/O and lower host CPU usage as a result</li>
<li>more bandwidth</li>
<li>higher packets per second (PPS)</li>
<li>Consistent lower latency</li>
<li>Available at no charge for EC2 and available on most EC2 types but needs to be configured</li>
</ul>
<p>EBS Optimized</p>
<ul>
<li>Historically, network used to be shared by data and EBS</li>
<li>EBS Optimisation means a dedicated capacity is provided for EBS usage</li>
<li>This means faster speeds for EBS and it doesn't impact the data side</li>
<li>Most instances support and have enabled by default</li>
<li>Some older instances its supported but enabling costs extra</li>
</ul>
<h2 id="route-53---global-dns">Route 53 - Global DNS<a aria-hidden="true" class="anchor-heading icon-link" href="#route-53---global-dns"></a></h2>
<h3 id="r53-public-hosted-zones">R53 Public Hosted Zones<a aria-hidden="true" class="anchor-heading icon-link" href="#r53-public-hosted-zones"></a></h3>
<ul>
<li>
<p>There are two types of DNZ Zones in Route 53 - public and private.</p>
</li>
<li>
<p>A hosted zone is a DNS database for a given section of the global DNS database e.g. animals4life.org</p>
</li>
<li>
<p>A globally resilient service</p>
</li>
<li>
<p>Hosted zones are created automatically via R53 - or separately and R53 will host it</p>
</li>
<li>
<p>A zone hosts DNS records e.g. A, AAAA, MX, NS, TXT</p>
</li>
<li>
<p>A hosted zone is what the dns system references and it's authoritative for that domain</p>
</li>
<li>
<p>A public hosted zone is a DNS database hosted by R53 on public name servers</p>
</li>
<li>
<p>Accessible from public internet and VPC</p>
</li>
<li>
<p>Hosted on 4 x r53 name servers (NS) specific for the zone</p>
</li>
<li>
<p>Use the ns records to point at those 4 x route</p>
</li>
<li>
<p>To integrate it with the public DNS system, you change the NS records to point at the 4 name servers</p>
</li>
<li>
<p>Inside a public hosted zone, you create resource records which DNS uses</p>
</li>
<li>
<p>You can use route 53 to host zone files for externally registered domains</p>
</li>
</ul>
<h3 id="r53-private-hosted-zones">R53 Private Hosted Zones<a aria-hidden="true" class="anchor-heading icon-link" href="#r53-private-hosted-zones"></a></h3>
<ul>
<li>Operates the same way as a public zone except it's not public</li>
<li>It's associated with VPCs within AWS and it's only accessible there</li>
<li>Can also associate it to different accounts</li>
<li>Can use a split-view technique where you can have overlapping public and private for public and internal use with the same zone name e.g. private intranet websites</li>
<li>Private zone is inaccessible from the internet - but it can be made accessible with VPCs.</li>
<li>VPC can access the private zone via route53 resolver</li>
<li>If you create a public hosted zone with the same name that is how a split view could work. You have specific records in each.</li>
</ul>
<h3 id="cname-vs-r53-alias">CNAME vs R53 Alias<a aria-hidden="true" class="anchor-heading icon-link" href="#cname-vs-r53-alias"></a></h3>
<p>If we only use CNAMES:</p>
<ul>
<li>In DNS an A record maps a name to an IP address i.e. catagram.io => 1.3.3.7</li>
<li>CNAME maps a NAME to another NAME e.g. <a href="http://www.catagram.io">www.catagram.io</a> => catagram.io</li>
<li>You can't use CNAME for the APEX of the domain i.e. you can't have catagram.io pointing at something else</li>
<li>Many AWS services use a DNS Name (ELB)</li>
<li>Therefore if you only use CNAME - catagram.io => ELB would be invalid</li>
<li>Alias record fixes this</li>
</ul>
<p>An ALIAS record:</p>
<ul>
<li>Maps a NAME onto an AWS resource</li>
<li>Can be used for naked/apex and normal records</li>
<li>For non apex/naked it functions like CNAME</li>
<li>There is no charge for ALIAS requests pointing to AWS resources</li>
<li>For AWS services e.g. cloudfront, gateway, s3 buckets - you should default to picking ALIAS</li>
<li>An ALIAS is a subtype - you need to manage the record type with the type youre pointing to e.g. elastic balancer is A record therefore you need to create an A record ALIAS</li>
<li>Can only use ALIAS if you're using route 53</li>
</ul>
<h3 id="simple-routing">Simple Routing<a aria-hidden="true" class="anchor-heading icon-link" href="#simple-routing"></a></h3>
<ul>
<li>Simple routing supports 1 record per name</li>
<li>Each record can have multiple values</li>
<li>Simple routing should be used when you want to route request to one single service e.g a web server</li>
<li>It doesn't support health checks</li>
<li>simple to implement and manage</li>
</ul>
<h3 id="r53-health-checks">R53 Health Checks<a aria-hidden="true" class="anchor-heading icon-link" href="#r53-health-checks"></a></h3>
<ul>
<li>Separate from but are used by records in route 53</li>
<li>Performed by a fleet of health checkers distributed globally</li>
<li>Not limited to just AWS targets - can check anything that is accessible by IP</li>
<li>Check every 30s but can be every 10s (cost extra)</li>
<li>Test TCP, HTTP/HTTPS, HTTP/HTTPS with string matching</li>
<li>An endpoint is either healthy or unhealthy</li>
<li>Types of checks: Endpoint, Cloudwatch Alarm, checks of checks</li>
<li>if 18%+ of distributed checkers report a healthy then the health check is healthy</li>
<li>Commonly uses s3 as a back up</li>
</ul>
<h3 id="failover-routing">Failover Routing<a aria-hidden="true" class="anchor-heading icon-link" href="#failover-routing"></a></h3>
<ul>
<li>You can add a backup/failure resource with the inclusion of a health check on the primary record</li>
<li>Use this when you want to configure active-passive failover</li>
</ul>
<h3 id="multi-value-routing">Multi value routing<a aria-hidden="true" class="anchor-heading icon-link" href="#multi-value-routing"></a></h3>
<ul>
<li>A mix of simple and failover</li>
<li>Can create many records with the same name</li>
<li>Each record can have an associated health check</li>
<li>Up to 8 healthy records are randomly selected</li>
<li>Client chooses and uses 1 value</li>
<li>Any failed health check records won't be returned</li>
<li>More of an active-active method</li>
<li>Not a replacement for a load balancer</li>
<li>Improves availability of an application</li>
</ul>
<h3 id="weighted-routing">Weighted Routing<a aria-hidden="true" class="anchor-heading icon-link" href="#weighted-routing"></a></h3>
<ul>
<li>A simple form of load balancing</li>
<li>You're able to specify a weight for each record</li>
<li>The total weight is calculated for a given name</li>
<li>A record with the weight of 0 never gets returned</li>
<li>Each record is returned based on it's record weight vs total weight</li>
<li>If a record returned is unhealthy, it repeats until a healthy record is chosen</li>
<li>Useful for when you have records with the same name and want to test the distribution</li>
</ul>
<h3 id="latency-routing">Latency Routing<a aria-hidden="true" class="anchor-heading icon-link" href="#latency-routing"></a></h3>
<ul>
<li>When you want to optimise for performance and user experience</li>
<li>For each of the records with the same name, you can use different regions</li>
<li>In the background, aws maintains a latency between different regions</li>
<li>A record that has the lowest latency based on region is chosen for a user</li>
<li>If a record is unhealthy then the second lowest latency is returned</li>
<li>The database AWS maintains is not real time</li>
</ul>
<h3 id="geolocation-routing">Geolocation Routing<a aria-hidden="true" class="anchor-heading icon-link" href="#geolocation-routing"></a></h3>
<ul>
<li>Similar to latency except the location of customers and resources is the influencing factor</li>
<li>With geolocation routing, records are tagged with a location e.g. country, continent or default</li>
<li>When a user is making a request, the IP check verifies the location of the user. Then the relevant record is returned (not the closest) - it checks the state first, the country next and then the continent. Optionally it returns the default you defined. If there is no default then a NO ANSWER is returned.</li>
<li>This is ideal for restricting content e.g. to the usa only</li>
<li>For language specific content or balancing across regional locations</li>
<li>This is about location not proximity. E.G. if you're not based in a specific state the record is defined for in the state, then you wont get that record</li>
</ul>
<h3 id="geoproximity">Geoproximity<a aria-hidden="true" class="anchor-heading icon-link" href="#geoproximity"></a></h3>
<ul>
<li>Aims to return records as close to your users as possible</li>
<li>Records can be tagged by AWS region or lat and long coordinates</li>
<li>Allows us to define a bias - how route 53 handles a calculation .e.g + - bias where "+" increases the region size and "-" decreases neighbouring regions</li>
<li>Bias expands/shrinks the region to direct traffic to</li>
</ul>
<h3 id="r53-interoperability">R53 Interoperability<a aria-hidden="true" class="anchor-heading icon-link" href="#r53-interoperability"></a></h3>
<ul>
<li>
<p>Using route 53 to register domain or host domain files when the other part of that is not with route 53</p>
</li>
<li>
<p>Usually these things are done together with Route 53 but it can do one or the other</p>
</li>
<li>
<p>When you register a domain with route 53 it does two jobs: <em>domain registrar</em> and <em>domain hosting</em></p>
</li>
<li>
<p>It can do BOTH or either</p>
</li>
<li>
<p>If you register a domain using route 53</p>
<ul>
<li>it accepts your money (domain registration fee)</li>
<li>allocates 4 x Name Servers (domain hosting)</li>
<li>Creates a zone file (domain hosting) on the NS servers</li>
</ul>
</li>
<li>
<p>Domain registration:</p>
<ul>
<li>R53 communicates with the registry of TLD (domain registrar)</li>
</ul>
</li>
<li>
<p>typically r53 doesn't isn't just used as a domain registar but sometimes used purely for hosting where the domain is registered via a 3rd party</p>
</li>
</ul>
<h3 id="implementing-dnssec-using-route53">Implementing DNSSEC using Route53<a aria-hidden="true" class="anchor-heading icon-link" href="#implementing-dnssec-using-route53"></a></h3>
<ul>
<li>DNSSEC strengthens authentication in DNS using digital signatures based on public key cryptography.</li>
<li>Asymmetric keys are created in the us-east-1 region (Using KMS)</li>
<li>Route53 creates the zone signing keys internally (KMS isn't involved)</li>
<li>Adds the key signing key and zone signing key public parts within a DNS record</li>
<li>Cloudwatch alarms should be enabled for DNSECInternalFailure or KeySigningKeysNeedingAttention</li>
</ul>
<h2 id="relational-database-service-rds">Relational Database Service (RDS)<a aria-hidden="true" class="anchor-heading icon-link" href="#relational-database-service-rds"></a></h2>
<h3 id="database-refresher--models---part1">Database Refresher &#x26; MODELS - PART1<a aria-hidden="true" class="anchor-heading icon-link" href="#database-refresher--models---part1"></a></h3>
<p>Relational (SQL) vs Non-Relational (NoSQL)</p>
<ul>
<li>SQL - Structured Query Language</li>
<li>Relational - structure in and between tables of data - Rigid Schema</li>
<li>Fixed relationship between tables and defined in advance</li>
<li>NoSQL - is not one single thing - it covers alternative database models</li>
<li>They have a more relaxed schema and relationships between tables is handled differently</li>
</ul>
<h3 id="database-refresher--models---part2">Database Refresher &#x26; MODELS - PART2<a aria-hidden="true" class="anchor-heading icon-link" href="#database-refresher--models---part2"></a></h3>
<p>Examples of nosql/non-relational DB models:</p>
<ul>
<li>Key Value databases consist of sets of keys and values.</li>
<li>unstructured and are key/value pairs</li>
<li>good for simple data, no structure, name/value pairs</li>
<li>Good for in-memory caching</li>
</ul>
<p>Wide Column Store</p>
<ul>
<li>A variation on key value</li>
<li>you can have additional keys as well as a partition key</li>
<li>DynamoDB uses this</li>
<li>Has tables which are groupings of data</li>
<li>tables containing attributes but they don't have to be the same. It can have all of the same attributes or a mixture or none</li>
<li>No fixed structure on the attribute side</li>
<li>Every item has to use the same key structure and needs to include a key that is unique</li>
<li>DynamoDB is a wide column store</li>
</ul>
<p>Document</p>
<ul>
<li>Store and query data as documents</li>
<li>Formatted using json or XML and can have different structure within the same DB</li>
<li>Interacted with via it's ID</li>
<li>Work best for order or collections or contact style DB</li>
<li>Good for deep attributes within a nested structure i.e. orders or contacts</li>
<li>Have flexible indexing for deep nested data</li>
</ul>
<p>Column</p>
<ul>
<li>Row based DBs are when you interact with data based on rows</li>
<li>Rows are ideal when you operate on rows</li>
<li>Column stores data in columns i.e. a grouping column for orderID, Product, Color Size</li>
<li>Good for reporting where you need a particular column</li>
<li>An AWS column db is RedShift</li>
<li>Column db is great for reporting and analytics</li>
</ul>
<p>Graph</p>
<ul>
<li>Good for social media or HR systems</li>
<li>Can store complex relationships between data</li>
<li>Quicker for running queries on relationships</li>
<li>Relationships are fluid and dynamic and are stored along the data</li>
</ul>
<h3 id="acid-vs-base">ACID vs BASE<a aria-hidden="true" class="anchor-heading icon-link" href="#acid-vs-base"></a></h3>
<ul>
<li>Database transaction models</li>
<li>CAP Theorem - consistency, availability and partition tolerance - choose 2
<ul>
<li>Consistency means it will receive the most recent write otherwise an error</li>
<li>Availability - every request will receive a response but it may not be the most recent write</li>
<li>Partition tolerance - can be made of multiple network partitions and continues to operates even if there is a drop of packets</li>
</ul>
</li>
</ul>
<p>ACID</p>
<ul>
<li>Atomic - all of the transaction parts must be successful otherwise none are</li>
<li>Consistent - transactions move the db from one valid state to another - no in between state is allowed</li>
<li>Isolated - concurrent executions leave the db in the same state as if they were executed sequentially</li>
<li>Durable - once a transaction has been committed, it will remain so even in the event of a system failure</li>
<li>Generally refers to RDS DB and it limits a database to scale</li>
</ul>
<p>BASE</p>
<ul>
<li>Basically available - R/W operations are available as much as possible but without any consistency guarantees</li>
<li>Soft state - the DB doesn't enforce consistency, it's offloaded to the developer</li>
<li>Eventually consistent - if we wait long enough, reads from a system will be consistent</li>
<li>highly scalable and performant</li>
<li>Dynamo DB usually works in a BASE like way but does offer consistent reads and other ACID functionality</li>
<li>typically no-sql and acid mentioned together would be referring to a dynamo db database</li>
</ul>
<h3 id="databases-on-ec2">Databases on EC2<a aria-hidden="true" class="anchor-heading icon-link" href="#databases-on-ec2"></a></h3>
<ul>
<li>Running databases directly on EC2 is considered bad practice</li>
<li>There may be some small scenarios where it may benefit</li>
<li>There needs to be reliable communication between your app and DB
Why you might do it:</li>
<li>Access to the DB Instance OS</li>
<li>Advanced DB Option tuning - you don't have these with managed DBs but AWS does allow you to control them without root access in managed DBs</li>
<li>The app vendor might require it</li>
<li>DB or DB version which AWS doesn't provide</li>
<li>specific OS/DB combination that AWS doesn't provide</li>
<li>Architecture AWS don't provide</li>
<li>Decision makers just want it</li>
</ul>
<p>Why you shouldn't:</p>
<ul>
<li>admin overhead - managing EC2 and DBHost/server</li>
<li>Backup / DR management adds additional complexity</li>
<li>EC2 is single AZ - access to DB can fail</li>
<li>Features - AWS DB products have a extensive features which achieve more than what can be done in an ec2 instance</li>
<li>EC2 is on or off - no serverless so you can't scale up or down easily</li>
<li>Replication - admin overhead</li>
<li>performance - aws has advanced performance features for managed DBs</li>
</ul>
<h3 id="relational-database-service-rds-architecture">Relational Database Service (RDS) Architecture<a aria-hidden="true" class="anchor-heading icon-link" href="#relational-database-service-rds-architecture"></a></h3>
<ul>
<li>RDS is a 'Database server as a service' product</li>
<li>On this database server/instance you can have multiple databases</li>
<li>You don't have to run installation or maintenance</li>
<li>Choice of mysql, mariaDB, postgresSQL, oracle, Microsoft SQL server</li>
<li>Amazon aurora is a different product</li>
<li>Managed service - you do not have access to OS or SSH access - there is an RDS custom where you could do this</li>
<li>Runs within a VPC - it's not a global service</li>
<li>Every RDS instance has it's own dedicated storage (EBS)</li>
<li>Data is replicated to the standby DB instances in different AZs</li>
<li>Backups occur to S3 but you don't see it within your account</li>
</ul>
<p>Costs:</p>
<ul>
<li>billed based on instance size and type</li>
<li>Multi az or not</li>
<li>per gig monthly fee for storage - storage type and amount</li>
<li>data transferred I/O</li>
<li>backups &#x26; snapshots - the same amount as storage is free but any more comes with a cost</li>
<li>any extra costs based on licensing if applicable</li>
</ul>
<h3 id="relational-database-service-rds-multiaz---instance-and-cluster">Relational Database Service (RDS) MultiAZ - Instance and Cluster<a aria-hidden="true" class="anchor-heading icon-link" href="#relational-database-service-rds-multiaz---instance-and-cluster"></a></h3>
<ul>
<li>
<p>Historically, the only way to provide high availability to RDS is via multi az. This meant the primary rds instance replicates across AZs:</p>
<ul>
<li>all access to DB is via the CNAME - with multi az you still only access the primary instance</li>
<li>data is written to primary and immediately replicated to standby</li>
<li>not included in free tier</li>
<li>you get one standby replica only - it cannot be used for reads or writes, it's used for failover</li>
<li>60-120 seconds for failover</li>
<li>can only be within the same region</li>
<li>backups can be taken from standby replica to improve performance</li>
<li>failures can occur for various different reasons - AZ outage, primary failure, manual failover, instance type change and software patching</li>
</ul>
</li>
</ul>
<p>Multi az cluster architecture:</p>
<ul>
<li>one writer can replicate to two reader instances (different AZs) - in RDS you can only have 2 and in aurora you can have more</li>
<li>the primary instance can be used for reads and writes and the replicas can be used for reads</li>
<li>runs on much faster hardware</li>
<li>fast writes to local storage and flushed to EBS</li>
<li>readers can be used to scale reading</li>
<li>replication is done via transaction logs which is more efficient</li>
<li>failover is fast = ~35 seconds + transaction log apply</li>
<li>writes are viewed as committed when 1 reader has confirmed that it's written</li>
</ul>
<h3 id="rds-automatic-backup-rds-snapshots-and-restore">RDS Automatic Backup, RDS Snapshots and Restore<a aria-hidden="true" class="anchor-heading icon-link" href="#rds-automatic-backup-rds-snapshots-and-restore"></a></h3>
<p>Two types of backup functionality:</p>
<ol>
<li>Automated backups</li>
<li>snapshots</li>
</ol>
<ul>
<li>both stored in AWS managed s3 buckets - you won't be able to see them in s3</li>
<li>because it's in s3, it's regionally resilient</li>
<li>RDS can replicate backups to another region</li>
<li>charges apply for cross-region data copy and storage in the destination region - this is not the default you have to explicitly enable it</li>
</ul>
<p>Snapshots:</p>
<ul>
<li>snapshots must be run explicitly, they're not automatic</li>
<li>taken of the instance so all the DBs within it</li>
<li>snapshots are incremental i.e. they only store the difference between previous</li>
<li>snapshots don't expire and live beyond the instance</li>
<li>if you use a single AZ there will be an IO pause, with multiple it will happen with the standby</li>
<li>transaction logs will also be stored in the s3 every 5 minutes</li>
</ul>
<p>automated backup</p>
<ul>
<li>automatically cleaned up - min 0 days to 35 days</li>
<li>you can choose to retain automated backups - but they still expire based on retention period</li>
</ul>
<p>Restores:</p>
<ul>
<li>Creates a new RDS instance - it will use a new endpoint address</li>
<li>restoring snapshots aren't fast</li>
</ul>
<h3 id="rds-read-replicas">RDS Read-Replicas<a aria-hidden="true" class="anchor-heading icon-link" href="#rds-read-replicas"></a></h3>
<ul>
<li>Read only replicas of an RDS instance. They can be in the same or cross-region</li>
<li>Read replicas are not part of the main database instance in any way - applications need to be adjusted to use them - Without app support, they don't do anything</li>
<li>Kept in sync using asynchronous synchronisation</li>
<li>can create 5x direct read replicas per DB instance</li>
<li>each providing an additional instance of read performance</li>
<li>read replicas can have read replicas but lag starts to be a problem</li>
<li>can help with global performance improvements</li>
<li>benefit in recover point objectives (RPOS) with frequent snapshot and backups - limits the amount of data lost</li>
<li>rtos are a problem as it takes a long time</li>
<li>RR offer a near 0 RPO - very little potential for data loss</li>
<li>Can be promoted quickly - low RTO</li>
<li>read replicas should only be used on failure only - not for data corruption</li>
<li>read only until they're promoted</li>
<li>great for global availability improvements due to global resilience</li>
</ul>
<h3 id="rds-data-security">RDS Data Security<a aria-hidden="true" class="anchor-heading icon-link" href="#rds-data-security"></a></h3>
<ul>
<li>SSL/TLS (in transit) is available for RDS and can be mandatory</li>
<li>RDS supports EBS volume encryption - KMS encryption</li>
<li>This is handled by Host or DBS</li>
<li>AWS or customer managed CMK generates data encryption keys (DEKs) used for encryption operations</li>
<li>storage, logs, snapshots &#x26; replicas are all encrypted by the same master key</li>
<li>encryption cannot be removed once it's added</li>
<li>RDS MSSQL and RDS Oracle support TDE - transparent data encryption - it's handled by the DB engine</li>
<li>RDS oracle supports integration with cloud HSM - managed by you with no key exposure with AWS</li>
</ul>
<p>IAM Authentication:</p>
<ul>
<li>RDS can be configured to use IAM user authentication to a DB</li>
<li>You have IAM users and roles with attached policies - tokens are generated with a 15 minute validity - you won't need a password</li>
<li>this is only authentication NOT authorization - authorization is controlled by the DB engine</li>
</ul>
<h3 id="rds-custom">RDS Custom<a aria-hidden="true" class="anchor-heading icon-link" href="#rds-custom"></a></h3>
<ul>
<li>Fills the gap between RDS and EC2 running a DB engine</li>
<li>Works for MSSQL and oracle</li>
<li>can connect using SSH, RDP, Session Manager</li>
<li>RDS Custom gives you the benefits of using the RDS product combined with the ability to customise instances</li>
</ul>
<h3 id="aurora-architecture">Aurora Architecture<a aria-hidden="true" class="anchor-heading icon-link" href="#aurora-architecture"></a></h3>
<ul>
<li>
<p>Aurora is very different from RDS</p>
</li>
<li>
<p>Uses a cluster</p>
</li>
<li>
<p>Made up of a single primary instance and 0 or more replicas</p>
</li>
<li>
<p>Replicas are used for reads for normal operations - you don;t have to choose between read scaling and availability</p>
</li>
<li>
<p>Does not use local storage, uses shared cluster volume</p>
</li>
<li>
<p>This provides faster provisioning, improved availability and better performance</p>
</li>
<li>
<p>Has a max cluster volume of 128 TiB</p>
</li>
<li>
<p>Replication happens at the storage level so no extra resources are consumed from the instances</p>
</li>
<li>
<p>Because storage is across 3 AZs, availability of storage is much higher</p>
</li>
<li>
<p>Aurora avoids data lost and reduces any point in time restores - more resilient than RDS</p>
</li>
<li>
<p>AUrora can have up to 15 replicas and any of them can be failover</p>
</li>
<li>
<p>Failover is quicker because there are no storage modifications</p>
</li>
<li>
<p>Cluster shared volume is SSD by default - high IOPS/low latency</p>
</li>
<li>
<p>Billing - based on what storage you consume</p>
</li>
<li>
<p>high water mark billing - e.g. billed for the most used storage in a cluster - this is being changed by AWS but for now this is the architecture</p>
</li>
<li>
<p>replicas can be added and removed without requiring storage provisioning</p>
</li>
<li>
<p>Aurora has a cluster endpoint (points at primary) and reader endpoint (at any replica or primary) - you can also create custom endpoints and there are unique end points per replica</p>
</li>
<li>
<p>Cost - there is no free tier option - it doesn't support micro instances</p>
</li>
<li>
<p>Anything beyond RDS Single AZ (micro) aurora offers a better value</p>
</li>
<li>
<p>compute is charged hourly and you're billed per second at a 10 minute minimum</p>
</li>
<li>
<p>storage is GB month consumed at a high watermark. Theres also an IO cost per request</p>
</li>
<li>
<p>100% DB Size in backups are included in your cost</p>
</li>
<li>
<p>Backups in aurora work the same way as RDS</p>
</li>
<li>
<p>Restores create a brand new cluster</p>
</li>
<li>
<p>Backtrack can be used to rollback DB to a previous point in time - as opposed to a full restore</p>
</li>
<li>
<p>You can create a fast clone to create a new database - it references the original storage and stores differences between the two</p>
</li>
</ul>
<h3 id="aurora-serverless">Aurora Serverless<a aria-hidden="true" class="anchor-heading icon-link" href="#aurora-serverless"></a></h3>
<ul>
<li>Provides a version of the aurora product where you don't have to worry about provisioning a server or DB instances</li>
<li>The non-serverless version of aurora is often known as 'aurora provisioned'</li>
<li>You don't need to provision resources the same way as auroro provisioned</li>
<li>Uses ACU - aurora capacity units</li>
<li>Have a min and max ACU</li>
<li>Cluster adjusts based on load</li>
<li>Can go to 0 and be paused</li>
<li>Billed on consumption per-second</li>
<li>same resilience as aurora (6 copies across azs)</li>
<li>Much simpler, removes complexity, easy to scale</li>
</ul>
<p>Differences:</p>
<ul>
<li>Same cluster volume architecture</li>
<li>Instead of provisioned servers - ACUs - provided from a warm pool of capacity units</li>
<li>They have no local storage</li>
<li>Once allocated, they have access to the cluster storage</li>
<li>interacting with the aurora cluster happens through a 'proxy fleet' - it doesn't connect directly to the units</li>
</ul>
<p>Use cases:</p>
<ul>
<li>Infrequently used - eg low volume blog site.</li>
<li>New applications - where you're unsure of the levels of load</li>
<li>Variable workloads - an application that has peaks and troughs</li>
<li>Unpredictable workloads</li>
<li>Development and test databases</li>
<li>multi-tenant applications</li>
</ul>
<h3 id="aurora-global-database">Aurora Global Database<a aria-hidden="true" class="anchor-heading icon-link" href="#aurora-global-database"></a></h3>
<ul>
<li>A feature of aurora provisioned clusters which allow data to be replicated globally</li>
<li>Introduce the concept of secondary regions which can have up to 16 replicas. They are all read only.</li>
<li>Replica occurs at the storage layer and its typically a 1s replication between regions - it's one way between primary and secondary</li>
<li>You would use these for:
<ul>
<li>cross region disaster recovery and business continuity</li>
<li>Global read scaling - low latency</li>
<li>replication has no impact on DB performance</li>
<li>Secondary can be promoted to read write</li>
<li>currently max 5 secondary regions</li>
</ul>
</li>
</ul>
<h3 id="multi-master-writes">Multi-master writes<a aria-hidden="true" class="anchor-heading icon-link" href="#multi-master-writes"></a></h3>
<ul>
<li>A write mode of aurora provisioned clusters which allows multiple instances to perform reads and writes at the same time rather than only one primary instance having write capability</li>
<li>Default aurora mode is a Single-Master - one R/W and 0+ read only replicas</li>
<li>Failover takes time to replicate to promote</li>
<li>In multi-master all clusters are R/W</li>
<li>There is no load-balancing cluster endpoint to use, the app is responsible to connecting to instances</li>
<li>When a r/w node receives data, it commits to all storage in cluster. It either rejects or accepts the change depending on the in-flight data - it must agree with the other nodes</li>
<li>With multi-master cluster - the change is also replicated to other nodes in the cluster (replication in in-memory caches)</li>
<li>The application logic needs to manually load balance across the cluster instances</li>
</ul>
<h3 id="relational-database-service-rds---rds-proxy">Relational Database Service (RDS) - RDS Proxy<a aria-hidden="true" class="anchor-heading icon-link" href="#relational-database-service-rds---rds-proxy"></a></h3>
<ul>
<li>Why use:
<ul>
<li>Opening/closing connections to DB takes time</li>
<li>handling failure of DB instances is hard</li>
<li>DB proxies change your architecture, you connect to the proxy and it maintains open connections for you in the long term</li>
<li>Applications => Proxy (connection pooling) => Database</li>
<li>Reduces too many connection errors</li>
<li>Smaller/burst instances</li>
<li>AWS Lambda - time saved connecting</li>
<li>Long running connections (SAAS Apps)</li>
<li>Resilience to DB failure is a priority - can reduce the time for failover and make it transparent to the application as it's going through the proxy</li>
</ul>
</li>
</ul>
<p>Key facts:</p>
<ul>
<li>Fully managed DB Proxy for RDS/Aurora</li>
<li>Auto scaling, highly available by default</li>
<li>provides connection pooling reducing DB load</li>
<li>only accessible within a VPC</li>
<li>accessed via a proxy endpoint - no app changes</li>
<li>can enforce SSL/TLS</li>
<li>reduce failover time by over 60% for aurora</li>
<li>abstracts failure of DB away from the application</li>
</ul>
<h3 id="database-migration-service-dms">Database Migration Service (DMS)<a aria-hidden="true" class="anchor-heading icon-link" href="#database-migration-service-dms"></a></h3>
<ul>
<li>A managed service which allows for 0 data loss, low or 0 downtime migration between 2 database endpoints</li>
<li>Runs a replication instance</li>
<li>Source and destination endpoints where one must be on AWS</li>
</ul>
<p>SCT (Schema Conversion Tool):</p>
<ul>
<li>A standalone tool when converting one database engine to another including DB -> S3</li>
<li>Not used for movements of data between compatible engines</li>
<li>different engines e.g. on premiss MSQL - RDS MYSQL</li>
</ul>
<p>DMS + Snowball:</p>
<ul>
<li>Larger migrations (multi TB)</li>
<li>DMS Can use snowball products (Uses schema conversion tool). You move data to a snowball device and ship it back to AWS to perform the migration</li>
</ul>
<h2 id="network-storage--data-lifecycle">Network Storage &#x26; Data Lifecycle<a aria-hidden="true" class="anchor-heading icon-link" href="#network-storage--data-lifecycle"></a></h2>
<h3 id="efs-architecture">EFS Architecture<a aria-hidden="true" class="anchor-heading icon-link" href="#efs-architecture"></a></h3>
<ul>
<li>Elastic File System (EFS)</li>
<li>Provides network based file systems which can be mounted and used by multiple instances at once</li>
<li>Implementation of NFSv4</li>
<li>Can be mounted on Linux instances (Linux only)</li>
<li>Shared between many EC2 instances</li>
<li>Exists separately from the EC2 instance</li>
<li>Private service and accessed via mount targets inside a VPC</li>
<li>Can be accessed on premiss via VPN or DX</li>
<li>Offers general purpose and Max I/O performance mode</li>
<li>General purpose is default and good for 99.9% of uses</li>
<li>Bursting and provisioned throughput modes (pick bursting generally)</li>
<li>Standard (default) and Infrequent Access (IA) classes</li>
<li>Lifecycle policies can be used with classes</li>
</ul>
<h3 id="aws-backup">AWS Backup<a aria-hidden="true" class="anchor-heading icon-link" href="#aws-backup"></a></h3>
<ul>
<li>fully managed data protection service (backup/restore)</li>
<li>Consolidate management of data into one place - across accounts and across regions</li>
<li>Supports a wide range of AWS products - Compute, block storage, file storage, databases, object storage</li>
</ul>
<p>Key concepts:</p>
<ul>
<li>Backup plans - frequency, window, lifecycle, vault, region copy</li>
<li>Backup resources - what resources are backed up</li>
<li>Vaults - destination (container) - assign a KMS key for encryption</li>
<li>Vault lock - write once read many (WORM) - No one, including AWS can delete anything from the vault after 72 hour cool off</li>
<li>On demand - manual backups created as needed</li>
<li>PITR - point in time recovery</li>
</ul>
<h2 id="ha--scaling">HA &#x26; SCALING<a aria-hidden="true" class="anchor-heading icon-link" href="#ha--scaling"></a></h2>
<h3 id="regional-and-global-aws-architecture">Regional and Global AWS Architecture<a aria-hidden="true" class="anchor-heading icon-link" href="#regional-and-global-aws-architecture"></a></h3>
<p>Architectural components to consider:</p>
<ul>
<li>Global service location and discovery</li>
<li>Content delivery (CDN) and optimisation</li>
<li>Global health checks and failover</li>
<li>Regional entry point</li>
<li>Regional scaling and resilience</li>
<li>Application services and components</li>
</ul>
<p>Netflix can be thought of as a global application also made up of blocks of regional services:</p>
<ul>
<li>Uses a global DNS for service/discovery (R53)</li>
<li>CDN layer at a global level (cloudfront)</li>
<li>Once a region is entered, user enters via web tier at the regional level</li>
<li>Web tier talks to compute tier eg ec2, lambda</li>
<li>compute tier consumes storage services e.g. EFS, S3</li>
<li>talks to DB tier</li>
<li>Sometimes gets data via caching layer</li>
<li>App services are used like SNS, Queues</li>
</ul>
<h3 id="evolution-of-the-elastic-load-balancer">Evolution of the Elastic Load Balancer<a aria-hidden="true" class="anchor-heading icon-link" href="#evolution-of-the-elastic-load-balancer"></a></h3>
<p>Three different types of ELBS split between v1 (avoid this) and v2 (prefer)</p>
<ol>
<li>Classic load Balancer (CLB) - v1 - not really layer 7 devices and lack advanced functionality - can only use 1 SSL cert per load balancer. Default to NOT using this</li>
<li>Application Load Balancer (ALB) - v2 - layer 7 devices that support HTTP/S/Websocket</li>
<li>Network Load Balancer (NLB) - v2 - TCP, TLS &#x26; UDP - good for any load balancing of anything that's not using HTTP(s)</li>
</ol>
<p>v2 = faster, cheaper and support target groups and rules
In exam you should be able to choose between ALB and NLB</p>
<h3 id="elastic-load-balancer-architecture">Elastic Load Balancer Architecture<a aria-hidden="true" class="anchor-heading icon-link" href="#elastic-load-balancer-architecture"></a></h3>
<ul>
<li>Accepts connections from customers and distributes them</li>
<li>When you provision a load balancer, you need to select which AZs it goes into and you do this by selecting ONE subnet in each AZ</li>
<li>Each ALB is configured with an A record DNS name which resolves to the ELB nodes</li>
<li>You must decide whether the ELB is internet facing or internal - if it's public facing then the ELB nodes have public and private IPs where as internal will only have private</li>
<li>LBs need at least 8+ free IPs per subnet - you should use a /27 or larger subnet to allow for scale</li>
<li>Internal LBs are usually used to separate application tiers</li>
<li>without LBs, the tiers need to have awareness of each other and they need to connect to specific instances. Tiers can then scale independently on each other</li>
</ul>
<p>Cross zone load balancing - allows each load balancer node to distribute connections evenly between all instances across availability zones. This is enabled as standard in load balancers. Without this, if you have two load balancer nodes and one zone has more instances than the other, the nodes in that instance will get a smaller distribution of traffic as opposed to the other zone.</p>
<ul>
<li>When you provision as an ELB, you see a DNS A record pointing at 1+ Nodes per AZ</li>
<li>Nodes in one subnet per AZ can scale</li>
<li>EC2 doesn't need to be public to work with an internet facing load balancer</li>
<li>Load balancers are configured by listener configuration which controls what it should listen to</li>
<li>8+ free IPs per subnet /28 is enough but AWS docs recommend /27 for scaling</li>
</ul>
<h3 id="application-load-balancing-alb-vs-network-load-balancing-nlb">Application Load balancing (ALB) vs Network Load Balancing (NLB)<a aria-hidden="true" class="anchor-heading icon-link" href="#application-load-balancing-alb-vs-network-load-balancing-nlb"></a></h3>
<p>Consolidation of LBs:</p>
<ul>
<li>Classic load balancers don't scale because each unique https name requires an individual CLB (1 SSL per CLB)</li>
<li>v2 load balancers support rules and target groups</li>
</ul>
<p>Application load balancer (ALB):</p>
<ul>
<li>Layer 7 which listens on HTTP/S</li>
<li>Can't understand any other layer 7 protocols e.g. SMTP, SSH, Gaming, TCP, UDP, TLS</li>
<li>Can understand l7 content e.g. cookies, custom headers, user location and app behaviour (protocol info)</li>
<li>Any incoming connections are always terminated on the ALB - you can't have an unbroken SSL connection</li>
<li>A new connection is made to the application</li>
<li>ALBs MUST have SSL certs if HTTPs is used</li>
<li>Slower than NLB as they are more levels of network stack to process</li>
<li>They can evaluate application health</li>
<li>Have the concept of rules</li>
<li>processed in priority order</li>
<li>Default rule is catch-all</li>
<li>Rule conditions - host-header, http-header, request method, path pattern, query string and source IP</li>
<li>Actions - forward, redirect, fixed-response, authenticate-oidc and incognito</li>
</ul>
<p>Network load balancer (NLB):</p>
<ul>
<li>Function at layer 4 - TCP, TLS, UDP, TCP_UDP</li>
<li>They have no visibility or understanding of HTTP or HTTPs</li>
<li>They can't interpet headers, cookies, session sticiness</li>
<li>They're very fast (millions of rps, 25% of ALB latency)</li>
<li>Ideal to deal with anything thats not http(s) e.g. game servers, smtp, ssh, financial apps</li>
<li>Health checks only check ICMP/TCP handshake - they're not app aware</li>
<li>They can be allocated with static IPs which is useful for whitelisting</li>
<li>They can forward TCP through to instances - unbroken end to end encryption - it can accept tcp only traffic so any layers above will not be terminated</li>
<li>Used with private link to provide services to other VPCs</li>
</ul>
<p>ALB vs NLB:</p>
<ul>
<li>Unbroken encryption- NLB</li>
<li>static IP for whitelisting - NLB</li>
<li>Fastest performing - NLB</li>
<li>protocols that arent http(s) - NLB</li>
<li>Privatelink requirement - NLB</li>
</ul>
<p>otherwise - ALB</p>
<h3 id="launch-configuration-and-templates">Launch Configuration and Templates<a aria-hidden="true" class="anchor-heading icon-link" href="#launch-configuration-and-templates"></a></h3>
<ul>
<li>LC and LT at a high level perform the same task - they allow you to define the configuration of EC2 instances in advance e.g AMI, instance type, storage and keypair, networking and security groups, userdata and IAM role</li>
<li>Both are not editable</li>
<li>LT provides newer features - T2/T3 unlimited, placement groups, capacity reservations and elastic graphics</li>
<li>LC provide configuration to be used by auto scaling groups - they are not editable nor do they have any versioning</li>
<li>LT can be used for the same thing but they can also be used to launch EC2 instances directly</li>
</ul>
<h3 id="auto-scaling-groups">Auto-Scaling Groups<a aria-hidden="true" class="anchor-heading icon-link" href="#auto-scaling-groups"></a></h3>
<ul>
<li>Provide auto scaling for ec2 and can be used for a self healing architecture</li>
<li>They use launch templates or configurations - always one at a time (one config definition)</li>
<li>Has 3 values - minimum, desired and maximum size e.g. (1:2:4)</li>
<li>Keeps number of running ec2 instances the same as desired capacity by provisioning and terminating instances</li>
<li>Scaling policies normally together with auto scaling groups to automate based on metrics</li>
</ul>
<p>Scaling policies are rules on ASG:</p>
<ul>
<li>manual scaling - manually adjust the desired capacity</li>
<li>schedule scaling - time based adjustment e.g. sales</li>
<li>dynamic scaling:
<ul>
<li>simple - e.g. either provision or terminate based on a metric (CPU, memory, disk I/O, length of SQS queue)</li>
<li>stepped scaling - more +/- which allows you to react quicker</li>
<li>target tracking - desired aggregate e.g.CPU = 40% and ASG handles it</li>
</ul>
</li>
<li>Cool down period - waits a certain amount of seconds before doing another action</li>
</ul>
<p>ASG + Load Balancers:</p>
<ul>
<li>ASG can use the load balancer health checks rather than EC2 status checks</li>
</ul>
<p>Scaling processes:</p>
<ul>
<li>Launch and terminate- SUSPEND and RESUME</li>
<li>AddToLoadBalancer - add to LB on launch</li>
<li>AlarmNotification -accept notification from CW</li>
<li>AZRebalance - Balances instances evenly across AZs</li>
<li>Healthcheck - instance health checks on/off</li>
<li>ReplaceUnhealthy - Terminate unhealthy and replace</li>
<li>Standby - use this for instances InService vs Standby - can be used for maintenance</li>
</ul>
<p>FInal points</p>
<ul>
<li>ASG are free</li>
<li>Only the resource created are billed, use cool down to avoid rapid scaling</li>
<li>Think about more, smaller instances - smaller instances mean more granularity</li>
<li>Use ALB for elasticity - abstraction</li>
<li>ASG defines when and where, LT defines what</li>
</ul>
<h3 id="asg-scaling-policies">ASG Scaling Policies<a aria-hidden="true" class="anchor-heading icon-link" href="#asg-scaling-policies"></a></h3>
<ul>
<li>ASGs don't NEED scaling policies - they can have none</li>
<li>WIthout policies they have static values</li>
<li>Manual scaling means manually adjusting min, max desired</li>
<li>Dynamic scaling:</li>
<li>Simple scaling - define actions which occur when alarm moves into alarm state and adds/removes a static amount</li>
<li>step scaling - adds and removes based on steps with upper and lower bounds</li>
<li>Target tracking - predefined set of metrics and you define an ideal value, the ASG calculates the scaling for you based on this</li>
<li>It's possible to scale based on SQS - ApproximateNumberOfMessagesVisible - scales up and down based on messages</li>
</ul>
<h3 id="asg-lifecycle-hooks">ASG Lifecycle hooks<a aria-hidden="true" class="anchor-heading icon-link" href="#asg-lifecycle-hooks"></a></h3>
<ul>
<li>Allow you to configure custom actions on instances during ASG actions</li>
<li>e.g. during instance launch or instance terminate transitions</li>
<li>When you create lifecycle hooks, instances are paused and they wait until a timeout and either continue or abandon, alternatively you resume the ASG process</li>
</ul>
<h3 id="asg-healthcheck-comparison---ec2-vs-elb">ASG HealthCheck Comparison - EC2 vs ELB<a aria-hidden="true" class="anchor-heading icon-link" href="#asg-healthcheck-comparison---ec2-vs-elb"></a></h3>
<p>Three different types of health checks on ASG:</p>
<ul>
<li>
<p>EC2 (default), ELB (can be enabled) &#x26; custom</p>
</li>
<li>
<p>EC2 - if anything other than status running then it's viewed as unhealthy</p>
</li>
<li>
<p>ELB - instance must be both running and passing ELB health check - this way it can be more application aware</p>
</li>
<li>
<p>Custom - instances marked as healthy and unhealthy by an external system</p>
</li>
<li>
<p>A health check grace period is the amount of time to delay before starting checks (default 300s) - allows system launch and bootstrap. You need to make sure this is a sufficient amount so that instances don't keep terminating and restarting over and over again</p>
</li>
</ul>
<h3 id="ssl-offload--session-stickiness">SSL Offload &#x26; Session Stickiness<a aria-hidden="true" class="anchor-heading icon-link" href="#ssl-offload--session-stickiness"></a></h3>
<p>SSL Offload - there are three ways a load balancer can handle secure connections:</p>
<ol>
<li>bridging</li>
</ol>
<ul>
<li>default mode of ELB</li>
<li>secure connection between the client and the load balancer - the LB needs an SSL certificate and a domain name that the application uses</li>
<li>AWS technically have access to that security certificate</li>
<li>It also creates new encrypted with the backend instances. This means that all the EC2 instances also need an SSL certificate which matches the domain name</li>
</ul>
<p>positives:</p>
<ul>
<li>ELB gets to see unecrypted HTTP
Negatives:</li>
<li>Cert has to be stored on the ELB itself which is a security risk</li>
<li>SSL certs need to be installed on the instances themselves which is an overhead since they need to perform the cryptographic operations</li>
</ul>
<ol start="2">
<li>pass-through</li>
</ol>
<ul>
<li>Client connects but the LB passes it to the backend instance. The LB doesn't need an SSL cert but the backend instances do</li>
<li>This LB must be a network load balancer</li>
<li>The LB is configured to use TCP. AWS never need to see the cert that you use</li>
<li>Negative is that you don't get to use load balancing based on the http part.</li>
</ul>
<ol start="3">
<li>offload</li>
</ol>
<ul>
<li>Clients connect to ELB using HTTPS</li>
<li>LB connects to backend instances via HTTP (unencrypted)</li>
<li>LB requires SSL but backend instances don't</li>
<li>downside is data is in plaintext in backend network</li>
</ul>
<p>Connection stickiness</p>
<ul>
<li>If state is stored on a specific server rather than being stateless, you need session stickiness</li>
<li>ELBs can pass a cookie to clients which ensures that users are always being passed to a specific server until there is a server failure (in which case the user is sent to a different server) or the cookie expires</li>
<li>It can cause uneven load on the backend servers - apps should be designed to use stateless by moving the session external to the ec2 instance e.g. dynamo DB</li>
</ul>
<h3 id="gateway-load-balancer">Gateway Load Balancer<a aria-hidden="true" class="anchor-heading icon-link" href="#gateway-load-balancer"></a></h3>
<ul>
<li>A product which AWS provides to help you run and scale 3rd party security appliances e.g. firewalls, intrusion detection and prevention systems</li>
<li>You can use these for inbound and outbound traffic</li>
<li>Has endpoints where traffic enters/leaves - similar to VPC endpoints</li>
<li>GWLB balances across multiple backend applications</li>
<li>Traffic and metadata is tunnelled using GENEVE protocol</li>
</ul>
<h2 id="serverless-and-application-services">SERVERLESS AND APPLICATION SERVICES<a aria-hidden="true" class="anchor-heading icon-link" href="#serverless-and-application-services"></a></h2>
<h3 id="architecture-deep-dive">Architecture Deep Dive<a aria-hidden="true" class="anchor-heading icon-link" href="#architecture-deep-dive"></a></h3>
<p><strong>Monolithic architecture</strong>:</p>
<ul>
<li>is one entity that fails together since they are all contained together</li>
<li>scales together as they're highly coupled - you need to vertically scale the system</li>
<li>Bill together and use resources even if they're not running - tends to be the least effective architecture</li>
</ul>
<p><strong>Tiered architecture</strong>:</p>
<ul>
<li>A way to evolve a monolithic architecture - you break it apart and each tier can be on the same server or different</li>
<li>Still tightly coupled</li>
<li>can vertically scale each tier independently</li>
<li>Can use load balancers between each tier so that there isn't a direct comm between a specific instance</li>
<li>Can horizontally scale if load balancer is used between each tier</li>
<li>because each tier relies on the other, you cannot scale any tier down to 0</li>
</ul>
<p><strong>Queues</strong>:</p>
<ul>
<li>A tiered architecture can be evolved with a queue</li>
<li>A queue based architecture is decoupled - each tier pushes messages onto a queue</li>
<li>Each tier doesn't care about other tiers, it uses async comms to wait for messages from the queue</li>
</ul>
<p><strong>Microservice architecture</strong>:</p>
<ul>
<li>A way to further break down a monolithic architecture</li>
<li>microservices do individual things e.g. upload, process, store, manage</li>
</ul>
<p><strong>Event-driven architecture</strong>:</p>
<ul>
<li>Events are produced and consumed</li>
<li>Only consume resources as and when required - nothing is constantly running or waiting</li>
<li>Producers generate events when something happens e.g. clicks, errors, criteria met, uploads, actions</li>
<li>Events are delivered to consumers (usually using an event router)</li>
<li>Actions are taken</li>
<li>Mature event-driven architecture only consumes resources when handling events (key component of serverless architecture)</li>
</ul>
<h3 id="aws-lambda">AWS Lambda<a aria-hidden="true" class="anchor-heading icon-link" href="#aws-lambda"></a></h3>
<ul>
<li>Lambda is a Function-as-a-service (FaaS) product - it's a short-running and focussed service</li>
<li>A lambda function - a piece of code that lambda runs</li>
<li>Functions use a runtime e.g. python 3.8</li>
<li>Functions are loaded and run in a runtime environment</li>
<li>environment has direct memory (and virtual CPU e.g. indirect CPU) allocation</li>
<li>You're only billed for the duration the function runs</li>
<li>A key part of serverless architectures</li>
<li>Docker is an anti-pattern for lambda - this will generally refer to ecs</li>
<li>Code loads, executes then terminates</li>
<li>Lambda functions are stateless so no data is left over from previous invocations - you need to make sure your code works in a new environment</li>
<li>This is the default but there are cases where it's not</li>
<li>memory is 128mb to 10240mb - you don't control the CPU, it's according to the memory you get</li>
<li>900s (15m) function timeout for each lambda function</li>
<li>Typically used in conjunction with other serverless applications e.g. s3, api gateway</li>
<li>Often used for things like file processing</li>
<li>For database triggers - dynamo db, streams</li>
<li>serverless cron - eventbridge/cwEvents</li>
<li>real time stream data processing - kinesis</li>
</ul>
<p>Networking</p>
<ul>
<li>Public and VPC networking</li>
<li>default is public networking - can access public space aws services and the internet</li>
<li>public networking offers the best performance because no customer specific vpc networking is required - however they won't have access to vpc based services unless public ips are allocated and security rules allow external access</li>
<li>lambda functions running in vpc can freely access other vpc resources but nothing outside unless it's specifically configured</li>
<li>You could use a natgateway and internet gateway or a vpc endpoint to be able to talk to anything outside the vpc</li>
<li>treat lambdas running in a vpc like anything running in a vpc</li>
</ul>
<p>Security</p>
<ul>
<li>Permissions
<ul>
<li>execution role (similar to an ec2 instance role)</li>
<li>resource policies - like a bucket policy on s3 to allow external accounts or services to interface with lambda - can only be manipulated with cli or api</li>
</ul>
</li>
<li>Lambda uses cloudwatch, cloudwatch logs and x-ray</li>
<li>Can be integrated with x-ray for distributed tracing</li>
<li>requires permissions via execution role in order to log to cloudwatch</li>
</ul>
<p>Invocation</p>
<ul>
<li>Synchronous
<ul>
<li>Result is returned during the request (success/failure). Errors and retries must be handled within the client.</li>
</ul>
</li>
<li>asynchronous
<ul>
<li>Typically used when AWS services invoke lambda functions on your behalf</li>
<li>For example, s3 won't wait for a response from lambda and the lambda is responsible for any re-processing</li>
<li>The function code needs to be idempotent</li>
<li>Any retries could potentially be sent to a dead letter queue which repeat failed processing</li>
<li>Lambda supports destinations where successful or failed events can be sent</li>
</ul>
</li>
<li>event source mappings
<ul>
<li>typically used on streams/queues which don't support events and polling is required</li>
<li>event source mapping reads from a source and sends an event batch to lambda</li>
<li>batches that fail can be sent to sqs or sns topics</li>
</ul>
</li>
</ul>
<p>Versions</p>
<ul>
<li>You can have different versions of lambda functions</li>
<li>each version is immutable</li>
<li>$latest points to the latest version</li>
<li>Can use Aliases to point to specific versions eg dev, stage, prod which can be changed</li>
</ul>
<p>startup times</p>
<ul>
<li>execution context needs to be created</li>
<li>deployment package is downloaded</li>
<li>this process is known as a cold start</li>
<li>if a future invocation is done in a short time span it could possibly use the same execution context - this is known as a warm start</li>
<li>if too long between invocations then a new function will need to be executed causing a cold start</li>
<li>one function invocation runs at a time per context</li>
<li>provisioned concurrency can be used where aws will keep a certain amount of contexts warm to improve start up speeds</li>
<li>the /tmp storage can also hold the data between warm functions</li>
</ul>
<h3 id="cloudwatchevents-and-eventbridge">CloudWatchEvents and EventBridge<a aria-hidden="true" class="anchor-heading icon-link" href="#cloudwatchevents-and-eventbridge"></a></h3>
<ul>
<li>Cloudwatch events delivers a near real time stream of system events which describe changes in aws products and services e.g. terminate, start</li>
<li>EventsBridge is the service which will replace CloudWatch Events</li>
<li>Can observe if X happens or at Y times ... do Z</li>
<li>EventBridge is basically Cloudwatch Events v2 - you should use it by default</li>
<li>Both of these use an event bus and there is a default one for the account</li>
<li>cloudwatch only has 1 bus and its implicit (not exposed)</li>
<li>EventBridge allows you to create additional busses and you can interact with them</li>
<li>You create rules for incoming events or schedule based rules</li>
</ul>
<h3 id="serverless-architecture">Serverless Architecture<a aria-hidden="true" class="anchor-heading icon-link" href="#serverless-architecture"></a></h3>
<ul>
<li>Serverless is a software architecture which's aim is to manage few servers as possible</li>
<li>Applications are a collection of small and specialised functions</li>
<li>The functions are run in stateless and ephemeral environments - they are billed via duration</li>
<li>Everything is event driven - things are only run when required</li>
<li>FaaS is used where possible for compute functionality</li>
<li>No persistent usage of compute</li>
<li>Managed services should be used where possible e.g. s3, dynamo, SSO</li>
</ul>
<h3 id="simple-notification-service-sns">Simple Notification Service (SNS)<a aria-hidden="true" class="anchor-heading icon-link" href="#simple-notification-service-sns"></a></h3>
<ul>
<li>A highly available, durable, secure pub sub service</li>
<li>It's on the Public AWS Service so you will need network connectivity with the public endpoint</li>
<li>Coordinates the sending and delivery of message</li>
<li>Messages are &#x3C;= 256kb (it's made for small files)</li>
<li>SNS Topics are the base of entity of SNS - permission and configuration</li>
<li>Publishers sends things to a topic</li>
<li>Subscribers receive messages from a topic e.g. http(s), emails, sqs, mobile push, sms messages, lambda</li>
<li>Used across AWS services e.g. cloudwatch and cloudformation</li>
</ul>
<p>Functionality it offers:</p>
<ul>
<li>Delivery status</li>
<li>Delivery retries - reliable delivery</li>
<li>HA and Scalable (Region)</li>
<li>SSE (server side encryption)</li>
<li>Cross-account via TOPIC policy</li>
</ul>
<h3 id="step-functions">Step Functions<a aria-hidden="true" class="anchor-heading icon-link" href="#step-functions"></a></h3>
<ul>
<li>Address some of the limitations/design decisions of Lambda</li>
<li>Lambda is FaaS - you should not be putting a full application in a function</li>
<li>15 minute max execution time</li>
<li>They can be chained together</li>
<li>Chaining together can get messy at scale</li>
<li>Runtime environments are stateless</li>
<li>Step functions let you create state machines</li>
</ul>
<p>State Machines</p>
<ul>
<li>State machines are like a workflow with start/end point and in between has states</li>
<li>States modify and output data</li>
<li>Maximum duration for state machine execution is 1 year</li>
<li>Standard workflow or express workflow available - standard is default, express is for high volume and they are for up to 5 minutes</li>
<li>They can be started via API gateway, IOT rules, Event bridge, lambda</li>
<li>Can be created via ASL (amazon states language) - JSON template</li>
<li>Interact with other services via IAM roles (permissions)</li>
</ul>
<p>States:</p>
<ul>
<li>SUCCEED &#x26; FAIL - where it arrives</li>
<li>WAIT - period of time or until - pauses the workflow</li>
<li>CHOICE - takes a path depending on an input</li>
<li>PARALLEL - allows you to create parallel branches in a state machine - perform multiple sets of thing at the same time</li>
<li>MAP - accepts a list of things, performs action(s) on each item</li>
<li>TASK - a single unit of work which allows you to perform action - integrates with many things e.g. lambda, batch, dynamodb, ecs, sns, sqs etc</li>
</ul>
<h3 id="api-gateway-101">API Gateway 101<a aria-hidden="true" class="anchor-heading icon-link" href="#api-gateway-101"></a></h3>
<ul>
<li>A service which lets you create and manage APIs</li>
<li>Act as an endpoint/entry point for applications</li>
<li>Sit between application and integration (services)</li>
<li>Highly available, scalable, handles authorisation, throttling, caching, CORS, transformations, openAPI spec, direct integration and much more</li>
<li>Can connect to services/endpoints in AWS or on-premises</li>
<li>Works with HTTP, REST and websockets</li>
</ul>
<p>Authentication:</p>
<ul>
<li>Supports a range of methods and can also be open access</li>
</ul>
<p>Endpoint types:</p>
<ul>
<li>Edge optimised - routed to the nearest cloudfront POP</li>
<li>Regional - clients in the same region</li>
<li>Private - only accessible within a vpc via interface endpoint</li>
</ul>
<p>Stages:</p>
<ul>
<li>APIs are deployed to stages each stage has one deployment e.g dev, prod</li>
<li>Can be rolled back</li>
<li>Allows canary deployments on stages and eventually be promoted</li>
</ul>
<p>Errors:</p>
<ul>
<li>4xxx - client error - invalid requests on the client side</li>
<li>5xxx - server errors - valid request, backend issue</li>
<li>400 - Bad Request - Generic</li>
<li>403 - Access Denied - authorizer denied or its been filtered</li>
<li>429 - API Gateway can throttle - its been exceeded</li>
<li>502 - Bad gateway exception - bad output returned by lambda</li>
<li>503 - service unavailable - endpoint offline or major service issues</li>
<li>504 - integration failure/timeout - 29s limit on lambda</li>
</ul>
<p>Caching:</p>
<ul>
<li>Configured per stage</li>
<li>Without a cache, applications make requests to the stage and the backend integrations will be used on each and every request</li>
<li>With cache, you can specify a size between 500mb-237GB - caching for 300s by default (otherwise 0-3600s). Can be encrypted. Calls are only made to backend if request is a cache miss</li>
</ul>
<h3 id="simple-queue-service-sqs">Simple Queue Service (SQS)<a aria-hidden="true" class="anchor-heading icon-link" href="#simple-queue-service-sqs"></a></h3>
<ul>
<li>
<p>Provides managed message queues</p>
</li>
<li>
<p>Public service</p>
</li>
<li>
<p>Fully managed</p>
</li>
<li>
<p>Highly available and highly performant - you don't need to worry about replication or resiliency</p>
</li>
<li>
<p>Either standard or FIFO - fifo guarantee an order. Standard is best effort but could be out of order</p>
</li>
<li>
<p>Msgs can be up to 256kb in size - you want to keep them small</p>
</li>
<li>
<p>Clients can send and other clients can poll the queue</p>
</li>
<li>
<p>Received messages are hidden (VisibilityTimeout) - if a client doesn't delete the message then it can reappear int he queue</p>
</li>
<li>
<p>Dead letter queues can be used for problem messages which means that different sets of processing can occur on problematic messages</p>
</li>
<li>
<p>Auto scaling groups can scale based on the queue lengths</p>
</li>
<li>
<p>Standard - at least once delivery , FIFO - exactly once delivery</p>
</li>
<li>
<p>FIFO performance is limited - 3000 messages per second with batching or up to 300 messages per second without</p>
</li>
<li>
<p>Billed based on requests</p>
</li>
<li>
<p>1 request = 1-10 messages up to 64kb total</p>
</li>
<li>
<p>Short (immediate) vs long (waitTimeSeconds) polling - waitTimeSeconds can be up to 20 second. Long polling is how you SHOULD poll SQS</p>
</li>
<li>
<p>Encryption at rest (KMS) &#x26; in transit. Data is encrypted by default in transit but not at rest</p>
</li>
<li>
<p>Queue policy can be used</p>
</li>
</ul>
<h3 id="sqs-standard-vs-fifo-queues">SQS Standard vs FIFO Queues<a aria-hidden="true" class="anchor-heading icon-link" href="#sqs-standard-vs-fifo-queues"></a></h3>
<ul>
<li>FIFO are single lane highways and standard are multi lane</li>
<li>Standard is scalable as wide as required near unlimited TPS</li>
<li>FIFO queues have to have a FIFO suffix to be a fifo queue</li>
<li>Great for workflow ordering, command ordering, price adjustments</li>
<li>Standard queues are faster however there is no rigid order of messaging.</li>
<li>Good for decoupling, worker pools, batch for future processing</li>
</ul>
<h3 id="sqs-delay-queues">SQS Delay Queues<a aria-hidden="true" class="anchor-heading icon-link" href="#sqs-delay-queues"></a></h3>
<ul>
<li>Allow you to postpone the delivery of messages to consumers</li>
<li>A delay queue has a DelaySeconds where messages are conceptually parked - they are not available on the queue. Maximum value is 15 minutes. </li>
<li>You cannot use it on FIFO queues</li>
</ul>
<h3 id="sqs-dead-letter-queues">SQS Dead-Letter Queues<a aria-hidden="true" class="anchor-heading icon-link" href="#sqs-dead-letter-queues"></a></h3>
<ul>
<li>Dead letter queues are designed to allow you to handle problematic messages </li>
<li>You can use a dead letter queue whereby when the recievecount of a message is more than maxRecieveCount it moves to a dead letter queue</li>
<li>It's a separate area to analyse/diagnose the messaging issues </li>
<li>All sqs have retention periods for messages which starts at the enqueue timestamp of the original queue.</li>
<li>A DLQ can be used for multiple source queues</li>
</ul>
<h3 id="kinesis-data-streams">Kinesis Data Streams<a aria-hidden="true" class="anchor-heading icon-link" href="#kinesis-data-streams"></a></h3>
<ul>
<li>Often confused with SQS</li>
<li>A scalable streaming service</li>
<li>Designed to ingest data from lots of devices and applications</li>
<li>streams can scale from low to near infinite data rates</li>
<li>public service &#x26; highly available by design </li>
<li>Provide a level of persistence - 24 hour moving window of data</li>
<li>Can be increased to 365 days for an additional cost</li>
<li>multiple consumers can access the data from that moving window </li>
<li>great for analytics and dashboards</li>
<li>Uses a shard architecture with each shard taking on more data </li>
<li>Kineses data records are max of 1mb</li>
<li>Questions about ingesting data is about kineses otherwise it could be sqs</li>
<li>SQS has 1 production group, 1 consumption group</li>
<li>SQS usually are used for decoupling and asynchronous communications</li>
<li>SQS doesn't really use any persistence or windows</li>
<li>Kinesis is designed for huge scale ingestion for multiple consumers over a rolling window</li>
<li>Kinesis is good for data ingestion, analytics, monitoring or app clicks </li>
</ul>
<h3 id="kinesis-data-firehose">Kinesis Data Firehose<a aria-hidden="true" class="anchor-heading icon-link" href="#kinesis-data-firehose"></a></h3>
<ul>
<li>Kinesis does not provide a default way to store data</li>
<li>Firehose is a fully managed service used to load data for data lakes, data stores and analytics services</li>
<li>Scales automatically - fully serverless, resilient</li>
<li>Near real time delivery (~60 seconds delay)</li>
<li>Supports transformation of data on the fly using lambda - can add latency</li>
<li>Billing - volume through firehose</li>
</ul>
<p>Valid destinations for firehose:</p>
<ul>
<li>
<p>HTTP endpoints</p>
</li>
<li>
<p>Splunk</p>
</li>
<li>
<p>Redshift</p>
</li>
<li>
<p>ElasticSearch</p>
</li>
<li>
<p>Destination Bucket s3</p>
</li>
<li>
<p>Kinesis data stream integrates with firehose to delegate the data</p>
</li>
<li>
<p>Firehose can also recieve data directly from sources </p>
</li>
<li>
<p>Even though it receives things in real time, firehose does not deliver in real time unlike kinesis data stream (~200ms vs ~60s)</p>
</li>
<li>
<p>Lambda can be used to transform data coming from firehose and back</p>
</li>
<li>
<p>The only exception to kineses firehose data store is redshift where s3 is used as an intermediary storage before it's saved onto redshift</p>
</li>
<li>
<p>Firehose is good for permanent storage of data, for transforming data (using lambda) to store, or if you want to put it into one of the supported products</p>
</li>
<li>
<p>remember it is not REAL TIME</p>
</li>
</ul>
<h3 id="kinesis-data-analytics">Kinesis Data Analytics<a aria-hidden="true" class="anchor-heading icon-link" href="#kinesis-data-analytics"></a></h3>
<ul>
<li>Real time data processing product</li>
<li>Uses SQL</li>
<li>Ingests from kineses data streams or firehose</li>
<li>Can be sent on in real time to destinations - firehose, s3, redshift, elasticsearch &#x26; splunk</li>
<li>AWS Lambda</li>
<li>Kineses data streams</li>
<li>It's realtime unless you use firehose</li>
<li>Allows you to use sql in real time on source streams</li>
<li>Kineses analaytics app can also take data from static resources e.g. s3 bucket </li>
<li>Static data can be used to enrich the real time streaming input</li>
<li>It processes input, performs application code on the data and outputs streams and puts them to kineses streams or kinesis firehose</li>
</ul>
<p>scenarios where you may use kineses data analytics:</p>
<ul>
<li>streaming data that needs reeal time sql processing</li>
<li>time series analytics - elections/e-sports</li>
<li>real time dashboards - leaderboards for games</li>
<li>real time metrics - security and response </li>
<li>Lambda is limited to simple manipulations, kineses data analytics is good for complex real time data manipulation </li>
</ul>
<h3 id="kinesis-video-streams">Kinesis Video Streams<a aria-hidden="true" class="anchor-heading icon-link" href="#kinesis-video-streams"></a></h3>
<ul>
<li>Kineses video streams ingests live video from producers</li>
<li>These can be security cameras, smartphones, cars, drones, time-serialised audio, thermal, depth and RADAR data</li>
<li>Consumers can access data frame-by-frame or as needed </li>
<li>Can persist and encrypt data in transit and at rest</li>
<li>You can't access the video data directly via storage you can only do it via apis</li>
<li>Integrates with AWS products - rekognition and Connect</li>
</ul>
<h3 id="amazon-cognito---user-and-identity-pools">Amazon Cognito - User and Identity Pools<a aria-hidden="true" class="anchor-heading icon-link" href="#amazon-cognito---user-and-identity-pools"></a></h3>
<ul>
<li>Cognito provides authentication, authorization and user management for web and mobile apps</li>
</ul>
<p>There are two parts of cognito:</p>
<ol>
<li>User pools - sign in and get a JWT (json web token) - most aws services CANNOT use jwts.</li>
</ol>
<ul>
<li>used for sign up, sign in, MFA and other security features</li>
<li>Allow SSO </li>
<li>Can't be used to access AWS resources</li>
</ul>
<ol start="2">
<li>Identity Pool - allows you to offer access to temporary AWS credentials</li>
</ol>
<ul>
<li>Unauthenticated identities for guest users </li>
<li>Swap temporary identity for short term AWS credentials </li>
<li>Assume an IAM role on behalf of an identity</li>
</ul>
<h3 id="aws-glue-101">AWS Glue 101<a aria-hidden="true" class="anchor-heading icon-link" href="#aws-glue-101"></a></h3>
<ul>
<li>Serverless ETL (extract, transform and load) </li>
<li>Datapipeline can do ETl but it uses servers</li>
<li>Moves and transforms data between source and destination </li>
<li>Crawls data sources and generates the AWS glue data catalog</li>
<li>Data sources can be any store e.g. s3, rds, jdbc compatible &#x26; dynamo db </li>
<li>Data sources can also be streams e.g. kinesis data streams &#x26; apache kafka</li>
<li>Data targets can be s3, rds, jdbc databases</li>
</ul>
<p>Data Catalog</p>
<ul>
<li>A collection of metadata combined with search tools</li>
<li>One catalog per region per account </li>
<li>Helps avoid data silos</li>
<li>AWS can use glue for etl and catalogue related services e.g. athena, redshift spectrum, aws lake formation</li>
</ul>
<h3 id="amazon-mq-101">Amazon MQ 101<a aria-hidden="true" class="anchor-heading icon-link" href="#amazon-mq-101"></a></h3>
<ul>
<li>
<p>A merge between SQS and SNS but using open standards</p>
</li>
<li>
<p>SNS/SQS utilise aws apis</p>
</li>
<li>
<p>SNS provides topics and sqs provides queues</p>
</li>
<li>
<p>SNS/SQS are both public services and can be accessed from anywhere</p>
</li>
<li>
<p>Both highly scalable and AWS integrated</p>
</li>
<li>
<p>Many orgs already use topics and queues (an on premise messaging system)</p>
</li>
<li>
<p>If they want to migrate to AWS, sns and sqs won't work out of the box</p>
</li>
<li>
<p>Amazon MQ is an open-source message broker</p>
</li>
<li>
<p>Based on managed apache activeMQ</p>
</li>
<li>
<p>Provides both queues and topics (1-1 and 1-many)</p>
</li>
<li>
<p>Provided with message broker service - either a single instance for test/dev/cheap or Highly available Pair (active/standbye)</p>
</li>
<li>
<p>Not a public service - runs in a VPC - requires private networking</p>
</li>
<li>
<p>no AWS native integration</p>
</li>
<li>
<p>Your default implementation should be SNS or SQS (new implementations)</p>
</li>
<li>
<p>SNS or SQS if AWS integration is required e.g. logging, permissions, encryption, service integration</p>
</li>
<li>
<p>Use Amazon MQ if you neeed to migrate from an existing system with little to no change</p>
</li>
<li>
<p>If you need to use open APIs</p>
</li>
<li>
<p>Remember you need to have private networking configured to use amazon MQ </p>
</li>
</ul>
<h3 id="amazon-appflow">Amazon AppFlow<a aria-hidden="true" class="anchor-heading icon-link" href="#amazon-appflow"></a></h3>
<ul>
<li>Fully managed integration service</li>
<li>Exchange data between applications (connectors) using flow</li>
<li>Source/destination connector</li>
<li>Sync data across applications</li>
<li>Aggregate data from different sources</li>
<li>Uses public endpoints but works with PrivateLink (privacy)</li>
<li>Can use a custom connector SDK (build your own)</li>
<li>e.g. of usage - sync contact records from salesforce to redshift or support tickets from zendesk to s3</li>
</ul>
<h2 id="global-content-delivery-and-optimization">GLOBAL CONTENT DELIVERY AND OPTIMIZATION<a aria-hidden="true" class="anchor-heading icon-link" href="#global-content-delivery-and-optimization"></a></h2>
<h3 id="cloudfront-architecture">Cloudfront Architecture<a aria-hidden="true" class="anchor-heading icon-link" href="#cloudfront-architecture"></a></h3>
<ul>
<li>Content Delivery Network - improve the delivery - uses caching and an efficient global network</li>
</ul>
<p>Cloudfront terms:</p>
<ul>
<li>
<p>Origin - the original location of content - S3 or Custom origin - S3 bucket or anywhere else</p>
</li>
<li>
<p>Distribution - The configuration unit of cloudfront - everything is configured in distribution (directly or indirectly)</p>
</li>
<li>
<p>Edge location - pieces of global infrastructure where content is cached</p>
</li>
<li>
<p>Regional Edge Cache - bigger than edge locations but designed to hold data that is accessed less frequently</p>
</li>
<li>
<p>Edge location is checked first, if there is a cache miss, the regional cache is checked, then finally its fetched from the origin if its not there. If its fetched from the origin then it's cached at regional and edge </p>
</li>
<li>
<p>Cloudfront performs no write caching - only read caching</p>
</li>
<li>
<p>A behaviour is configuration or "subconfiguration" of distribution</p>
</li>
<li>
<p>Behaviours sit architecturally between origins and distributions - Cloudfronts have at least 1 behaviour</p>
</li>
<li>
<p>Default behaviour is * which matches everything</p>
</li>
</ul>
<h3 id="cloudfront---ttl-and-invalidations">CloudFront - TTL and Invalidations<a aria-hidden="true" class="anchor-heading icon-link" href="#cloudfront---ttl-and-invalidations"></a></h3>
<ul>
<li>An edge location views an object as not expired if it's within it's TTL period</li>
<li>More frequent cache HITS = lower origin load</li>
<li>TTL default behaviour = 24 hours validity period</li>
<li>You can set Minimum TTL and Maximum TTL </li>
<li>There are different headers that can be used to direct cloudfront to use different TTL values:
<ul>
<li>Cache-Control max-age (seconds)</li>
<li>Cache-Control s-maxage (seconds)</li>
<li>Expires (Date &#x26; Time)</li>
</ul>
</li>
<li>For all of these, the TTL minimum and maximum will be used instead of the per-object setting if these don't fall in the range </li>
<li>Cache invalidations can be performed on a distribution - applies to all edge locations - takes time </li>
<li>Takes a path with wildcards to invalidate everything in that path e.g. /images/<em> or /images/whiskers</em></li>
<li>Invalidation should only be thought of as a way to correct errors - versioned file names are a good alternative to invalidation </li>
<li>versioned file names is not the same as s3 object versioning</li>
</ul>
<h3 id="acm---aws-certificate-manager">ACM - AWS Certificate Manager<a aria-hidden="true" class="anchor-heading icon-link" href="#acm---aws-certificate-manager"></a></h3>
<ul>
<li>HTTP was created as simple and secure</li>
<li>Once HTTP evolved, security vulnerabilities became an issue</li>
<li>HTTPS - SSL/TLS Layer of Encryption was added to HTTP</li>
<li>Data is encrypted in transit</li>
<li>Certificates prove identity </li>
<li>Chain of trust - signed by a trusted authority </li>
<li>ACM can function as a public or private certificate authority (CA) e.g. private can be used in an organisation</li>
<li>Private CA - applications need to trust your private CA</li>
<li>Public CA - browsers trust a list of providers </li>
<li>ACM can generate or import certificates</li>
<li>If generated, ACM can auto renew on your behalf</li>
<li>If imported, you will have to renew them yourself</li>
<li>ACM can be deployed out to supported services</li>
<li>Supported AWS services ONLY e.g. cloudfront and ALB but not EC2</li>
<li>ACM is a regional service </li>
<li>Certs cannot leave the region they are generated or imported in </li>
<li>If you want to use a certificate in a service, it MUST be in the same region in ACM</li>
<li>there is one exception - cloudfront operates as though within us-east-1 - you need to use this region in ACM</li>
<li>S3 does not use ACM for any certificates</li>
</ul>
<h3 id="securing-cf-and-s3-using-oai">Securing CF and S3 using OAI<a aria-hidden="true" class="anchor-heading icon-link" href="#securing-cf-and-s3-using-oai"></a></h3>
<ul>
<li>Origin Access Identity - OAI is a type of identity</li>
<li>Associated with cloudfront distribution </li>
<li>cloudfront "becomes" that OAI</li>
<li>OAI can be used in S3 Bucket Policies</li>
<li>Uses DENY all BUT one or more OAIs</li>
<li>We can deny any access directly to s3 by using an OAI policy - explicit allow for the OAI </li>
<li>when we have custom origns we can't use OAI</li>
</ul>
<p>With custom origins you can:</p>
<ul>
<li>use custom headers </li>
<li>and/or we have the IP ranges used by cloudfront so we can use a custom firewall</li>
</ul>
<h3 id="cloudfront---private-distribution--behaviours">CloudFront - Private Distribution &#x26; Behaviours<a aria-hidden="true" class="anchor-heading icon-link" href="#cloudfront---private-distribution--behaviours"></a></h3>
<ul>
<li>cloudfront can be run in public mode or private mode</li>
<li>if its private it needs to be access via cookie or signed url</li>
<li>you can have a mixed of multiple behaviours e.g. public or private</li>
<li>you need a signer to sign cookies and urls</li>
<li>Old way was via a cloudfront key via the account root user - you need to remember the term TRUSTED SIGNER</li>
<li>new method is TRUSTED KEY GROUP(s) - you don't need to use the root user.</li>
</ul>
<p>signed urls vs signed cookies:</p>
<ul>
<li>urls - provide access to ONE object only</li>
<li>use signed urls if your client doesn't support cookies</li>
<li>Cookies provides access to groups of objects</li>
<li>use cookies for groups of files/all files of a type</li>
<li>or if you want to maintain the application url </li>
</ul>
<h3 id="lambdaedge">Lambda@Edge<a aria-hidden="true" class="anchor-heading icon-link" href="#lambdaedge"></a></h3>
<ul>
<li>Allows you to run lightweight lambda functions at edge locations</li>
<li>can adjust traffic between the viewer and origin</li>
<li>Currently only support node js and python</li>
<li>you cannot access any VPC services since its in the public space</li>
<li>You can use it for A/B testing to change the viewer request and the url </li>
<li>Can use it to migrate between S3 origins e.g. by a weighted value</li>
<li>Can use it to customise behaviour based on the type of device the customer is using</li>
<li>Vary content by country </li>
</ul>
<h3 id="global-accelerator">Global Accelerator<a aria-hidden="true" class="anchor-heading icon-link" href="#global-accelerator"></a></h3>
<ul>
<li>used to optimise flow of data</li>
<li>this is an alternative to cloudfront</li>
<li>global accelerators use anycast IP addresses - they allow single IPs to be used in multiple locations</li>
<li>when we create a global accelerator, its allocated an anycast IP address</li>
</ul>
<p>Key Concepts:</p>
<ul>
<li>moves AWS network closer to customers</li>
<li>Aims to get users onto the global aws network as quickly and as close to their location as possible</li>
<li>its transited over AWS backbone to 1+ location </li>
<li>global accelerator is a network product and can be used for non http(s) e.g. TCP/UDP - if you need TCP/UDP you will need global accelerator. </li>
<li>cloudfront only caches HTTP, HTTP(S) content </li>
<li>GA does not cache anything , its just transmitting network data quickly</li>
</ul>
<h2 id="advanced-vpc-networking">ADVANCED VPC Networking<a aria-hidden="true" class="anchor-heading icon-link" href="#advanced-vpc-networking"></a></h2>
<h3 id="vpc-flow-logs">VPC Flow Logs<a aria-hidden="true" class="anchor-heading icon-link" href="#vpc-flow-logs"></a></h3>
<ul>
<li>Capture metadata (Not contents) e.g. source ip, destination ip, anything to do with flow of data to vpc</li>
<li>Can attach a VPC - all ENIs in that VPC</li>
<li>Subnet - All ENIs in that subnet</li>
<li>ENIs directly</li>
<li>they're NOT real time </li>
<li>can go to multiple destination - s3 or cloudwatch logs</li>
<li>can use athena for querying - ad hoc querying engine</li>
<li>A VPC flow logs has different fields e.g. srcaddr, dstaddr, srcport, dstport, protocol,action</li>
</ul>
<h3 id="egress-only-internet-gateway">Egress-Only Internet gateway<a aria-hidden="true" class="anchor-heading icon-link" href="#egress-only-internet-gateway"></a></h3>
<ul>
<li>IPV4 addresses are private or public</li>
<li>NAT allows private IPs to access public networks </li>
<li>Without allowing externally initiated connections (IN)</li>
<li>With IPv6, all IPS are public meaning internet gateways allows all IPs IN and OUT</li>
<li>Egress-only is outbound-only for IPV6 since NAT does not support this</li>
</ul>
<h3 id="vpc-endpoints-gateway">VPC Endpoints (Gateway)<a aria-hidden="true" class="anchor-heading icon-link" href="#vpc-endpoints-gateway"></a></h3>
<ul>
<li>Provide provide private access to public endpoints. At this point for S3 and DynamoDB</li>
<li>They allow a private only resource inside a VPC to access S3 and DynamoDB</li>
<li>Normally you would need an internet gateway to the VPC </li>
<li>Gateway endpoints allow you to access these services without creating a public infrastructure</li>
<li>A prefix list is added to route table for these subnets</li>
<li>that means any traffic leaving the subnet goes through the gateway endpoint rather than the internet gateway</li>
<li>It's HA across all AZs in a region by default </li>
<li>Endpoint policy is used to control what it can access e.g. particular s3 buckets</li>
<li>Can only access in same region - can't access cross-region services</li>
<li>These prevent leaky buckets - s3 can be set to private only by allowing access ONLY from a gateway endpoint. </li>
<li>gateway endpoints are NOT accessible outside the vpc </li>
</ul>
<h3 id="vpc-endpoints-inteface">VPC Endpoints (Inteface)<a aria-hidden="true" class="anchor-heading icon-link" href="#vpc-endpoints-inteface"></a></h3>
<ul>
<li>Similar to gateway but the way its done is different</li>
<li>Like gateway endpoints, they provide private access to AWS services</li>
<li>dynamoDB is still only available using gateway but interface can use s3</li>
<li>Allow private IP addressing to access public AWS services</li>
<li>interface endpoints are not highly available by default - they are added to specific subnets - ENI</li>
<li>One Interface Endpoint should be added to one subnet per AZ for high availability</li>
<li>Network access controlled via Security Groups - can't do this with gateway endpoints</li>
<li>Endpoint policies can be used to restrict what can be done with the endpoint</li>
<li>TCP and IPV4 ONLY</li>
<li>Uses PrivateLink</li>
</ul>
<h3 id="vpc-peering">VPC Peering<a aria-hidden="true" class="anchor-heading icon-link" href="#vpc-peering"></a></h3>
<ul>
<li>A service that lets you create a private encrypted network link between two VPCs</li>
<li>One peering connection links two and ONLY two vpcs </li>
<li>Works same/cross region and same/cross-account</li>
<li>Same region peers can reference peer Security Groups</li>
<li>VPC Peering does not support transitive peering e.g. A -> B and B -> C does NOT mean A -> C</li>
</ul>
<h2 id="hybrid-environments-and-migration">HYBRID ENVIRONMENTS AND MIGRATION<a aria-hidden="true" class="anchor-heading icon-link" href="#hybrid-environments-and-migration"></a></h2>
<h3 id="border-gateway-protocol-101">Border Gateway Protocol 101<a aria-hidden="true" class="anchor-heading icon-link" href="#border-gateway-protocol-101"></a></h3>
<ul>
<li>Made up of Autonomous Systems (AS) - Routers controlled by one entity </li>
<li>ASN (Autonomous system numbers) are unique and allocated by IANA</li>
<li>Reliable and distributed - operates over tcp/179</li>
<li>Not automatic - peering is manually configured </li>
<li>Path-vector protocol - exchanges the best path to a destination between peers. This path is known as the ASPATH</li>
<li>iBGP - Internal BGP - routing within AS</li>
<li>eBGP - External BGP - routing between AS</li>
</ul>
<h3 id="ipsec-vpn-fundamentals">IPSec VPN Fundamentals<a aria-hidden="true" class="anchor-heading icon-link" href="#ipsec-vpn-fundamentals"></a></h3>
<ul>
<li>A group of protocols that aim to set up secure tunnels across insecure networks</li>
<li>...between two peers (local and remote)</li>
<li>Provides authentication and is encrypted</li>
<li>IPSEC has two main phases:
<ol>
<li>IKE Phase 1 - Internet Key Exchange (slow and heavy)</li>
</ol>
<ul>
<li>Authenticate </li>
<li>Using asymmetric encryption to agree on </li>
<li>IKE SA created - phase 1 tunnel</li>
</ul>
<ol start="2">
<li>IKE Phase 2 - (fast and agile)</li>
</ol>
<ul>
<li>Uses keys agreed in phase 1</li>
<li>Agreed encryption method used</li>
<li>Created IPSEC SA - phase 2 tunnel </li>
</ul>
</li>
</ul>
<p>Policy vs route based VPNs:</p>
<ul>
<li>Policy - rule sets match traffic - a pair of SAs</li>
<li>route based - target matching (prefix) - matches a single pair of SAs</li>
</ul>
<h3 id="aws-site-to-site-vpn">AWS Site-to-Site VPN<a aria-hidden="true" class="anchor-heading icon-link" href="#aws-site-to-site-vpn"></a></h3>
<ul>
<li>Logical connection between a VPC and an on-premiss network - encrypted using IPSEC, running over public internet</li>
<li>Fully HA - if you design and implement correctly</li>
<li>Quick to provision - less than an hour</li>
<li>Virtual Private Gateway (VGW) - a logical gateway object that can be associated with a single VPC and one or more route tables</li>
<li>Customer Gateway (CGW) - logical config in AWS or physical device which it represents</li>
<li>VPN connection between VGW and CGW</li>
</ul>
<p>VPN Consideration:</p>
<ul>
<li>Speed limitation 1.25Gbps</li>
<li>Latency - inconsistent</li>
<li>Cost - AWS hourly cost, GB out cost, data cap (on premises)</li>
<li>Speed of setup is quick and usually quicker than other private connection technologies- hours, all software configuration </li>
<li>Can be used as a backup for direct connect (DX) </li>
<li>Can be used with Direct Connect (DX)</li>
</ul>
<h3 id="start-direct-connect-dx-concepts">Start Direct Connect (DX) Concepts<a aria-hidden="true" class="anchor-heading icon-link" href="#start-direct-connect-dx-concepts"></a></h3>
<ul>
<li>A physical connection into an AWS region - 1,10 or 100 Gbps</li>
<li>Business premises => DX location => AWS Region</li>
<li>You're given a port allocation at DX location </li>
<li>Cost is hourly and outbound data transfer</li>
<li>Provisioning time - requires physical cables and there is no resilience as its physical. This could take weeks</li>
<li>Low &#x26; consistent latency + high speeds</li>
<li>Can be used to access AWS Private services - can't be used to access public internet without additional configuration</li>
<li>DX location is not owned by AWS but is rented out by it </li>
</ul>
<h3 id="direct-connect-dx-resilience">Direct Connect (DX) Resilience<a aria-hidden="true" class="anchor-heading icon-link" href="#direct-connect-dx-resilience"></a></h3>
<ul>
<li>Direct connect is not resilient, it's a physical connectivity that needs to be architected to be resilient</li>
<li>What could go wrong:
<ul>
<li>DX location could fail e.g. power failure</li>
<li>DX Router </li>
<li>Cross Connect - it'sa cable</li>
<li>Customer DX router, </li>
<li>Extension</li>
<li>Customer premises</li>
<li>Customer router</li>
</ul>
</li>
</ul>
<p>We can add resilience by:</p>
<ul>
<li>Separate customer premises buildings - with separate routers</li>
<li>Several DX locations</li>
<li>Adding separate ports in each DX locations as well as premisses locations </li>
</ul>
<h3 id="direct-connect-dx---public-vif--vpn-encryption">Direct Connect (DX) - Public VIF + VPN (Encryption)<a aria-hidden="true" class="anchor-heading icon-link" href="#direct-connect-dx---public-vif--vpn-encryption"></a></h3>
<ul>
<li>Using a VPN gives you an encrypted and authenticated tunnel</li>
<li>OVer DX you will get low latency &#x26; consistency latency</li>
<li>This uses a public VIF</li>
<li>VPJ is transit agnostic - DX/Public internet</li>
<li>Public VIFs+IPSec VPN is a way to provide access to private VPC resources, using an encrypted IPSEC tunnel for transit.</li>
</ul>
<h3 id="transit-gateway">Transit Gateway<a aria-hidden="true" class="anchor-heading icon-link" href="#transit-gateway"></a></h3>
<ul>
<li>A network transit hub which connects VPCs to each other and to on premises networks using site to site VPNs and direct connect</li>
<li>It's designed to reduce network complexity</li>
<li>It's a single network object - HA &#x26; Scalable</li>
<li>You create attachments to other network types</li>
<li>attachments - VPC, Site to site VPN and DX gateway</li>
<li>Supports transitive routing </li>
<li>Can be used to create global networks</li>
<li>Share transit gateways between accounts using AWS RAM</li>
<li>you can peer different regions on same or cross accounts</li>
<li>It offers much less complexity than without TGW</li>
</ul>
<h3 id="storage-gateway---volume">Storage Gateway - Volume<a aria-hidden="true" class="anchor-heading icon-link" href="#storage-gateway---volume"></a></h3>
<ul>
<li>Runs as a virtual machine on premises (although can be ordered as hardware appliance)</li>
<li>presents storage using iSCSI, NFS or SMB</li>
<li>Integrates with EBS, s3 and glacier</li>
<li>used for migrations, extensions, storage tier-ing, DR and replacement of backup systems </li>
<li>When you're using volume storage in volume stored mode everything is stored locally</li>
<li>It asynchronously syncs to storage gateway endpoint which stores EBS snapshots in an s3 bucket</li>
<li>if you need full disk backups and DR, this is not the right solution</li>
<li>Volume cached mode - instead of local storage, it has a local cache but it stores all data in s3. The AWS bucket is an aws managed area so its not available to just look at </li>
<li>the main difference between Volume stored vs volume cached is the location of the data</li>
<li>volume cache uses aws as the primary location </li>
</ul>
<h3 id="storage-gateway---tape-vtl">Storage Gateway - Tape (VTL)<a aria-hidden="true" class="anchor-heading icon-link" href="#storage-gateway---tape-vtl"></a></h3>
<ul>
<li>tapes - LTO - storing to tapes</li>
<li>this really only allows write as a whole or read as a whole as editing tapes is not really possible</li>
</ul>
<h3 id="storage-gateway---file">Storage Gateway - File<a aria-hidden="true" class="anchor-heading icon-link" href="#storage-gateway---file"></a></h3>
<ul>
<li>File bridges on premises file storage and s3</li>
<li>you create mount points (shares) available via NFS or SMB </li>
<li>they map directly onto an S3 bucket</li>
<li>files stored into a mount point are visible as objects in an s3 bucket</li>
<li>does read/write caching and ensures LAN-like performance</li>
</ul>
<h3 id="snowball--edge--snowmobile">Snowball / Edge / Snowmobile<a aria-hidden="true" class="anchor-heading icon-link" href="#snowball--edge--snowmobile"></a></h3>
<ul>
<li>Designed to move large amounts of data in and out of AWS</li>
<li>The devices in this series are big physical storage</li>
<li>You can either order them empty, load and return </li>
<li>or order with data, empty and return </li>
</ul>
<p>Snowball:</p>
<ul>
<li>ordered from AWS </li>
<li>data encrypted using KMS</li>
<li>50tb or 80tb capacity</li>
<li>1GBPS or 10GBPS network</li>
<li>10TB to 10PB of data transfer most economical - you can order multiple devices</li>
<li>You can move the devices to multiple premises</li>
<li>only storage is included in the device</li>
</ul>
<p>Snowball edge:</p>
<ul>
<li>Comes with storage and compute </li>
<li>Larger capacity</li>
<li>10gbs, 10/25, 45/50/100 - faster network</li>
<li>storage optimized with EC2 </li>
<li>Compute optimized variant - for aggressive compute requirements</li>
<li>Compute with GPU </li>
<li>Snowball is older, snowball edge is ideal for remote sites where data processing on ingestion is needed </li>
</ul>
<p>Snowmobile:</p>
<ul>
<li>Portable data center within a shipping container on a truck</li>
<li>ideal for single location when 10+ PB is required</li>
<li>up to 100PB per snowmobile</li>
<li>It's a single truck - not economical for multi site (unless huge) or sub 10pb</li>
</ul>
<h3 id="directory-service">Directory Service<a aria-hidden="true" class="anchor-heading icon-link" href="#directory-service"></a></h3>
<p>directories:</p>
<ul>
<li>store objects within a structure (domain/tree)</li>
<li>multiple trees can be grouped into a forest</li>
<li>Microsoft active directory domain service (AD DS) is a common implementation</li>
<li>Directory Service is AWS managed implementation</li>
<li>Runs within a VPC</li>
<li>Provides HA - deploys within multiple AZs</li>
<li>some aws services need a directory e.g. amazon workplaces </li>
<li>can be isolated directory or integrated with existing on-premises </li>
<li>or act as a proxy back to on premises</li>
</ul>
<p>It can function in 3 modes:</p>
<ul>
<li>
<p>Simple AD - an implementation of Samba 4</p>
</li>
<li>
<p>AWS Managed Microsoft AD - an actual microsoft AD DS implementation</p>
</li>
<li>
<p>AD Connector which proxies requests back to an on premises directory </p>
</li>
<li>
<p>Start off with simple AD</p>
</li>
<li>
<p>Move to Microsoft AD if applications in AWS need MS DS or you need a trust relationship with AD DS</p>
</li>
<li>
<p>If you need a directory without storing any directory info in the cloud - use AD Connector </p>
</li>
</ul>
<h3 id="datasync">DataSync<a aria-hidden="true" class="anchor-heading icon-link" href="#datasync"></a></h3>
<ul>
<li>A data transfer service to transfer data into and out of AWS</li>
<li>Designed to work at huge scale</li>
<li>Keeps metadata (e.g. permissions and timestamps)</li>
<li>Built in data validation</li>
<li>Scalable - 10gbps per agent (~ 100TB per day)</li>
<li>can use bandwith limiters</li>
<li>incremental and scheduled transfer options</li>
<li>supports compression and encryption</li>
<li>automatic recovery</li>
<li>service integration - S3, EFS, FSx</li>
<li>Pay as you use</li>
</ul>
<h3 id="fsx-for-windows-servers">FSx for Windows Servers<a aria-hidden="true" class="anchor-heading icon-link" href="#fsx-for-windows-servers"></a></h3>
<ul>
<li>fully managed native windows file servers/shares</li>
<li>designed for integration with windows environments</li>
<li>can integrate with directory service or self managed AD</li>
<li>Resilient and HA - single or multi AZ within a VPC</li>
<li>on demand and scheduled backups</li>
<li>Accessible over VPC, peering, DX</li>
<li>Highly performant</li>
<li>VSS - User driven restores - unique to Fsx - can do this without a sys admin</li>
<li>Native file system accessible over SMB </li>
<li>Uses windows permission model</li>
<li>Supports DFS</li>
<li>Managed - no file server admin</li>
<li>can be integrated with DS and your own directory</li>
</ul>
<h3 id="fsx-for-lustre">FSx For Lustre<a aria-hidden="true" class="anchor-heading icon-link" href="#fsx-for-lustre"></a></h3>
<ul>
<li>Managed implementation of Lustre - designed for HPC - Linux clients (POSIX)</li>
<li>For machine learning, big data, financial model</li>
<li>can scale to 100s GBs throughput and sub millisecond latency</li>
<li>Deployment types:
<ul>
<li>scratch - highly optimised for short term, fast</li>
<li>persistent - longer term, HA in one AZ and self healing</li>
</ul>
</li>
<li>Available over a VPN or DX</li>
<li>Metadata is stored on metadata targets</li>
<li>objects are stored on object storage targets</li>
<li>baseline performance based on size </li>
<li>Use scratch for short term or temp workloads - NO HA, NO REPLICATION</li>
<li>persistent has replication but within ONE AZ only</li>
<li>Auto heals when hardware failure occurs</li>
<li>You can backup to S3 with both</li>
</ul>
<h3 id="aws-transfer-family">AWS Transfer Family<a aria-hidden="true" class="anchor-heading icon-link" href="#aws-transfer-family"></a></h3>
<ul>
<li>Provides managed file transfer service - supports transfers to and from s3 and efs</li>
<li>provides managed "servers"
Protocols used:
<ul>
<li>FTP</li>
<li>FTPS </li>
<li>SSH (SFTP)</li>
<li>AS2 - B2B data</li>
</ul>
</li>
<li>Create servers / endpoints:
<ul>
<li>public - via aws  - SFTP</li>
<li>VPC - internet - SFTP, FTPS, AS2</li>
<li>VPC - internal - SFTP, FTP, FTPS, AS2 </li>
</ul>
</li>
<li>Multi az </li>
<li>provisioned server per hour + data transfered</li>
<li>FTP and FTPS - directory service or custom IDP only</li>
<li>FTP - VPC only (cannot be public)</li>
<li>AS2 - VPC internal/internet only</li>
</ul>
<h2 id="security-deployment--operations">SECURITY, DEPLOYMENT &#x26; OPERATIONS<a aria-hidden="true" class="anchor-heading icon-link" href="#security-deployment--operations"></a></h2>
<h3 id="aws-secrets-manager">AWS Secrets Manager<a aria-hidden="true" class="anchor-heading icon-link" href="#aws-secrets-manager"></a></h3>
<ul>
<li>Shares functionality with parameter store</li>
<li>designed specifically for secrets e.g. passwords, api keys</li>
<li>Usable via console, cli, api or sdks</li>
<li>supports automatic rotation </li>
<li>directly integrates with some aws products e.g. rds</li>
</ul>
<h3 id="application-layer-l7-firewall">Application Layer (L7) Firewall<a aria-hidden="true" class="anchor-heading icon-link" href="#application-layer-l7-firewall"></a></h3>
<p>Normal Firewalls (layer 3/4/5):</p>
<ul>
<li>layer 3-4 requests to/from are seen as different streams of data</li>
<li>with layer 5, using a session, the two requests can be seen as one</li>
<li>each of these don't understand anything above the layer they operate at e.g. they cannot see HTTP, they just see general packet data</li>
<li>layer 7 fix many of these limitations</li>
</ul>
<p>Layer 7:</p>
<ul>
<li>Layer 7 firewalls are aware of layer 7 protocl e.g. HTTP</li>
<li>can identify normal or abnormal requests and attacks</li>
</ul>
<h3 id="web-application-firewall-waf-webacls-rule-groups-and-rules">Web Application Firewall (WAF), WEBACLs, Rule Groups and Rules<a aria-hidden="true" class="anchor-heading icon-link" href="#web-application-firewall-waf-webacls-rule-groups-and-rules"></a></h3>
<ul>
<li>A web application firewall that helps protect your web applications or APIs against common web exploits and bots</li>
<li>Outputs logs</li>
<li>A protection pack (web ACL) gives you fine-grained control over all of the HTTP(S) web requests that your protected resource responds to</li>
</ul>
<p>Web ACL:</p>
<ul>
<li>Controls what traffic is allowed or blocked - (ALLOW or BLOCK)</li>
<li>Resource type - cloudfront or regional service </li>
<li>Have to add rule groups or rules processed in order</li>
<li>WCU - acl capacity units - default is 1500 but can be increased via support tickets</li>
<li>WebACLS are associated with resources , this can take some time</li>
<li>Adjusting an existing WEBACL can take less time than creating a new one</li>
</ul>
<p>Rule groups:</p>
<ul>
<li>rule groups contain rules</li>
<li>No default actions - thats defined when added to webacls</li>
<li>managed by aws, you, services owned</li>
<li>Can be reused by multiple webACLS</li>
<li>You have to define the WCU capacity upfront (max 1500*)</li>
</ul>
<p>WAF Rules:</p>
<ul>
<li>
<p>Type, Statement, Action</p>
</li>
<li>
<p>Regular or Rate-based (e.g. x100 in a 5 minute period)</p>
</li>
<li>
<p>Statement: WHAT to match or COUNT</p>
</li>
<li>
<p>Action: Allow, block, count, captcha and custom responses</p>
</li>
<li>
<p>WebACL - monthly $5/month</p>
</li>
<li>
<p>Rule - $1 / month</p>
</li>
<li>
<p>Requests - monthly $0.6/million</p>
</li>
<li>
<p>Intelligent threat mitigation: bot control ($10/month) &#x26; $1/1 mil requests</p>
</li>
<li>
<p>Captcha, fraud control, marketplace groups extra costs</p>
</li>
</ul>
<h3 id="aws-shield">AWS Shield<a aria-hidden="true" class="anchor-heading icon-link" href="#aws-shield"></a></h3>
<ul>
<li>Standard and Advance - DDOS Protection</li>
<li>Shield is free and advanced has a cost</li>
<li>Network volumetric attacks (L3) - Saturate Capacity</li>
<li>Network Protocol Attacks (L4) - TCP SYN FLood</li>
<li>...Leave connections open, prevent new ones</li>
<li>Application Layer Attacks (L7) e.g. web request floods</li>
</ul>
<p>Standard:</p>
<ul>
<li>Free</li>
<li>Protection at the perimeter at region/vpc or at AWS edge</li>
<li>Common network (L3) or Transport (L4)</li>
<li>Best protection using r53, cloudfront, aws global accelerator </li>
</ul>
<p>Advanced:</p>
<ul>
<li>$3000 per month per org - 1 year lock in</li>
<li>Protects CF, R53, Accelerator, anything associated with EIPS (ec2), ALBS, CLBs, NLBs</li>
<li>not automatic - must be explicitly enabled </li>
<li>Cost protection for unmitigated attacks e.g. ec2 scaling</li>
<li>Proactive engagement &#x26; aws shield response team will contact you when attacks are detected</li>
<li>Integrates with WAF</li>
<li>Application Layer 7 ddos protection</li>
<li>real time visibility of DDOS events and attacks</li>
<li>Health based detection </li>
<li>Protection groups</li>
</ul>
<h3 id="cloudhsm">CloudHSM<a aria-hidden="true" class="anchor-heading icon-link" href="#cloudhsm"></a></h3>
<ul>
<li>with KMS its AWS managed. It's a shared service which means other AWS accounts use it </li>
<li>CloudHSM - a true Single Tenant hardware security module (HSM)</li>
<li>AWS Provision but its fully customer managed</li>
<li>Fully FIPS 140-2 Level 3 compliant (KMS is l3 overall some l3)</li>
<li>CloudHSM has to be accessed via industry standard APIs - pks#11, java cryptography extensions JCE, microsoft cryptoNG (CNG) libraries</li>
<li>KMS can use cloudhsm as a custom key store and cloudhsm integration with KMS</li>
<li>Deployed on a cloud VPC you have no visibility of</li>
<li>AWS CloudHSM client needs to be installed on the VPC devices to be accessed</li>
</ul>
<p>Use cases:</p>
<ul>
<li>No native integration e.g. no s3, SSE</li>
<li>Offload the SSL/TLS processing for web servers - more economical and efficient than doing on a general purpose ec2 instance</li>
<li>enable transparent data encryption (TDE) for oracle databases</li>
<li>protect the private keys for an issuing certificate authority (CA)</li>
</ul>
<p>For anything that requires aws integration then cloudHSM is not suitable </p>
<h3 id="aws-config">AWS Config<a aria-hidden="true" class="anchor-heading icon-link" href="#aws-config"></a></h3>
<ul>
<li>A service which records config changes over time on resources</li>
<li>For auditing of changes, compliance with standards</li>
<li>does not prevent changes happening - no protection</li>
<li>Regional service - supports cross region and account aggregation</li>
<li>Can generate SNS notifications and near real time events via event bridge and lambda</li>
<li>Config rules can be used to evaluate resources and determining whether their non-compliant</li>
</ul>
<h3 id="amazon-macie">Amazon Macie<a aria-hidden="true" class="anchor-heading icon-link" href="#amazon-macie"></a></h3>
<ul>
<li>data security and data privacy service</li>
<li>Discover, monitor and protect data stored in S3 buckets</li>
<li>Automated discovery of data i.e. PII, PHI, Finance</li>
<li>Managed data identifiers - build-in using ML/Patterns</li>
<li>Custom data identifiers - proprietary - regex based</li>
<li>Integrates - with security hub &#x26; finding events to event bridge</li>
<li>Uses a multi account architecture - centrally managed ether via aws ORG or one macie account inviting</li>
</ul>
<p>Identifiers:</p>
<ul>
<li>Managed via AWS:
<ul>
<li>via a growing list of common sensitive data types e.g. credentials, finance, health, personal identifiers</li>
</ul>
</li>
<li>Custom - created by you
<ul>
<li>regex</li>
<li>Keywords - optional sequences </li>
<li>Maximum match distance</li>
<li>ignore words</li>
</ul>
</li>
</ul>
<p>Findings:</p>
<ul>
<li>Policy or sensitive data findings</li>
<li>Policy e.g. S3BlockPublicAccessDisabled/EncryptionDIsabled/BucketSharedExternally etc...</li>
<li>Sensitive data - S3Object/Credentials, S3Object/CustomIdentifiers, S3Object/Financial etc...</li>
</ul>
<h3 id="amazon-inspector">Amazon Inspector<a aria-hidden="true" class="anchor-heading icon-link" href="#amazon-inspector"></a></h3>
<ul>
<li>Designed to check EC2 instances and the instances OS</li>
<li>Provides report ordered by severity</li>
<li>Network assessment (agentless)</li>
<li>Network and Host assessment (agent)</li>
<li>Rules package - network reachability (no agent required)</li>
<li>Agent can provide additional OS visibility</li>
<li>Check reachability end to end</li>
<li>Packages - Host assessments, agent required:
<ul>
<li>common vulnerabilities and exposures (CVE)</li>
<li>Center for internet security (CIS) benchmarks</li>
<li>Security best practices for amazon inspector e.g. password complexity checks</li>
</ul>
</li>
</ul></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#aws-accounts" title="AWS Accounts">AWS Accounts</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#technical-fundamentals" title="Technical fundamentals">Technical fundamentals</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#aws-fundamentals" title="AWS Fundamentals">AWS Fundamentals</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#public-vs-private-services" title="Public vs Private services">Public vs Private services</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#aws-global-infrastructure" title="AWS Global Infrastructure">AWS Global Infrastructure</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#aws-default-virtual-private-cloud-vpc" title="AWS Default Virtual Private Cloud (VPC)">AWS Default Virtual Private Cloud (VPC)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#elastic-compute-cloud-ec2" title="Elastic Compute Cloud (EC2)">Elastic Compute Cloud (EC2)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#simple-storage-service-s3" title="Simple Storage Service (S3)">Simple Storage Service (S3)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#cloudformation-cfn-basics" title="CloudFormation (CFN) basics">CloudFormation (CFN) basics</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#cloudwatch-cw-basics" title="CloudWatch (CW) Basics">CloudWatch (CW) Basics</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#shared-responsibility-model" title="Shared Responsibility Model">Shared Responsibility Model</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#high-availability-vs-fault-tolerance-vs-disaster-recovery" title="High-Availability vs Fault-Tolerance vs Disaster Recovery">High-Availability vs Fault-Tolerance vs Disaster Recovery</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#route53-r53-fundamentals" title="Route53 (R53) Fundamentals">Route53 (R53) Fundamentals</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#dns-record-types" title="DNS Record Types">DNS Record Types</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#iam-accounts-and-aws-organisations" title="IAM, Accounts and AWS Organisations">IAM, Accounts and AWS Organisations</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#iam-identity-policies" title="IAM Identity Policies">IAM Identity Policies</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#iam-users-and-arns" title="IAM Users and ARNs">IAM Users and ARNs</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#iam-groups" title="IAM Groups">IAM Groups</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#iam-roles" title="IAM Roles">IAM Roles</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#when-to-use-iam-roles" title="When to use IAM Roles">When to use IAM Roles</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#service-linked-roles-and-passrole" title="Service-linked Roles and PassRole">Service-linked Roles and PassRole</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#aws-organisations" title="AWS Organisations">AWS Organisations</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#service-control-policies" title="Service Control Policies">Service Control Policies</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#cloudwatch-logs" title="CloudWatch Logs">CloudWatch Logs</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#cloudtrail-essentials" title="CloudTrail Essentials">CloudTrail Essentials</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#aws-control-tower" title="AWS Control Tower">AWS Control Tower</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#simple-storage-service" title="Simple Storage Service">Simple Storage Service</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#s3-security-resource-policies-and-acls" title="S3 Security (Resource Policies and ACLs)">S3 Security (Resource Policies and ACLs)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#s3-static-hosting" title="S3 Static Hosting">S3 Static Hosting</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#object-versioning-and-mfa-delete" title="Object Versioning and MFA Delete">Object Versioning and MFA Delete</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#s3-performance-optimization" title="S3 Performance Optimization">S3 Performance Optimization</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#key-management-system" title="Key Management System">Key Management System</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#s3-object-encryption-csesse" title="S3 Object Encryption CSE/SSE">S3 Object Encryption CSE/SSE</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#s3-bucket-keys" title="S3 Bucket Keys">S3 Bucket Keys</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#s3-object-storage-classes" title="S3 Object Storage Classes">S3 Object Storage Classes</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#s3-lifecycle-configuration" title="S3 Lifecycle Configuration">S3 Lifecycle Configuration</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#s3-replication" title="S3 Replication">S3 Replication</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#s3-presigned-urls" title="S3 PreSigned URLs">S3 PreSigned URLs</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#s3-select-and-glacier-select" title="S3 Select and Glacier Select">S3 Select and Glacier Select</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#s3-events" title="S3 Events">S3 Events</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#s3-access-logs" title="S3 Access Logs">S3 Access Logs</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#s3-object-lock" title="S3 Object Lock">S3 Object Lock</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#s3-access-points" title="S3 Access Points">S3 Access Points</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#virtual-private-cloud-vpc-basics" title="Virtual Private Cloud (VPC) Basics">Virtual Private Cloud (VPC) Basics</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#vpc-sizing-and-structure" title="VPC Sizing and Structure">VPC Sizing and Structure</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#custom-vpcs" title="Custom VPCs">Custom VPCs</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#vpc-subnets" title="VPC Subnets">VPC Subnets</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#vpc-routing-internet-gateway--bastion-hosts" title="VPC Routing, Internet Gateway &amp; Bastion Hosts">VPC Routing, Internet Gateway &amp; Bastion Hosts</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#stateful-vs-stateless-firewalls" title="Stateful vs Stateless Firewalls">Stateful vs Stateless Firewalls</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#network-access-control-lists-nacls" title="Network Access Control Lists (NACLs)">Network Access Control Lists (NACLs)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#security-groups-sg" title="Security Groups (SG)">Security Groups (SG)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#network-address-translation-nat--nat-gateway" title="Network Address Translation (NAT) &amp; NAT Gateway">Network Address Translation (NAT) &amp; NAT Gateway</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#elastic-compute-cloud-ec2-basics" title="Elastic Compute Cloud (EC2) Basics">Elastic Compute Cloud (EC2) Basics</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#virtualization-101" title="Virtualization 101">Virtualization 101</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#ec2-architecture-and-resilience" title="EC2 Architecture and Resilience">EC2 Architecture and Resilience</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#ec2-instance-types" title="EC2 Instance Types">EC2 Instance Types</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#storage-refresher" title="Storage Refresher">Storage Refresher</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#elastic-block-store-ebs-service-architecture" title="Elastic Block Store (EBS) Service Architecture">Elastic Block Store (EBS) Service Architecture</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#ebs-volume-types---general-purpose" title="EBS Volume Types - General Purpose">EBS Volume Types - General Purpose</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#ebs-volume-types---provisioned-iops" title="EBS Volume Types - Provisioned IOPS">EBS Volume Types - Provisioned IOPS</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#ebs-volume-types---hdd-based" title="EBS Volume Types - HDD-Based">EBS Volume Types - HDD-Based</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#instance-store-volumes---architecture" title="Instance Store Volumes - Architecture">Instance Store Volumes - Architecture</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#choosing-between-the-ec2-instance-store-and-ebs" title="Choosing between the EC2 Instance Store and EBS">Choosing between the EC2 Instance Store and EBS</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#snapshots-restore--fast-snapshot-restore-fsr" title="Snapshots, Restore &amp; Fast Snapshot Restore (FSR)">Snapshots, Restore &amp; Fast Snapshot Restore (FSR)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#ebs-encryption" title="EBS Encryption">EBS Encryption</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#network-interfaces-instance-ips-and-dns" title="Network Interfaces, Instance IPs and DNS">Network Interfaces, Instance IPs and DNS</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#amazon-machine-images-ami" title="Amazon Machine Images (AMI)">Amazon Machine Images (AMI)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#ec2-purchase-options" title="EC2 Purchase Options">EC2 Purchase Options</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#reserved-instances---the-rest" title="Reserved Instances - the rest">Reserved Instances - the rest</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#instance-status-checks--auto-recovery" title="Instance Status Checks &amp; Auto Recovery">Instance Status Checks &amp; Auto Recovery</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#horizontal--vertical-scaling" title="Horizontal &amp; Vertical Scaling">Horizontal &amp; Vertical Scaling</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#instance-metadata" title="Instance Metadata">Instance Metadata</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#containers--ecs" title="Containers &amp; ECS">Containers &amp; ECS</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#introduction-to-containers" title="Introduction to Containers">Introduction to Containers</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#ecs---concepts" title="ECS - Concepts">ECS - Concepts</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#ecs---cluster-mode" title="ECS - Cluster Mode">ECS - Cluster Mode</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#elastic-container-registry-ecr" title="Elastic Container Registry (ECR)">Elastic Container Registry (ECR)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#kubernetes-101" title="Kubernetes 101">Kubernetes 101</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#elastic-kubernetes-service-eks-101" title="Elastic Kubernetes Service (EKS) 101">Elastic Kubernetes Service (EKS) 101</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#advanced-ec2" title="Advanced EC2">Advanced EC2</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#bootstrapping-ec2-using-user-data" title="Bootstrapping EC2 using User Data">Bootstrapping EC2 using User Data</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#enhanced-bootstrapping-with-cfn-init" title="Enhanced Bootstrapping with CFN-INIT">Enhanced Bootstrapping with CFN-INIT</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#ec2-instance-roles--profile" title="EC2 Instance Roles &amp; Profile">EC2 Instance Roles &amp; Profile</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#ssm-parameter-store" title="SSM Parameter Store">SSM Parameter Store</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#system-and-application-logging-on-ec2" title="System and Application Logging on EC2">System and Application Logging on EC2</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#ec2-placement-groups" title="EC2 Placement Groups">EC2 Placement Groups</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#dedicated-hosts" title="Dedicated Hosts">Dedicated Hosts</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#enhanced-networking--ebs-optimized" title="Enhanced Networking &amp; EBS Optimized">Enhanced Networking &amp; EBS Optimized</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#route-53---global-dns" title="Route 53 - Global DNS">Route 53 - Global DNS</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#r53-public-hosted-zones" title="R53 Public Hosted Zones">R53 Public Hosted Zones</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#r53-private-hosted-zones" title="R53 Private Hosted Zones">R53 Private Hosted Zones</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#cname-vs-r53-alias" title="CNAME vs R53 Alias">CNAME vs R53 Alias</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#simple-routing" title="Simple Routing">Simple Routing</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#r53-health-checks" title="R53 Health Checks">R53 Health Checks</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#failover-routing" title="Failover Routing">Failover Routing</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#multi-value-routing" title="Multi value routing">Multi value routing</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#weighted-routing" title="Weighted Routing">Weighted Routing</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#latency-routing" title="Latency Routing">Latency Routing</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#geolocation-routing" title="Geolocation Routing">Geolocation Routing</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#geoproximity" title="Geoproximity">Geoproximity</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#r53-interoperability" title="R53 Interoperability">R53 Interoperability</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#implementing-dnssec-using-route53" title="Implementing DNSSEC using Route53">Implementing DNSSEC using Route53</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#relational-database-service-rds" title="Relational Database Service (RDS)">Relational Database Service (RDS)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#database-refresher--models---part1" title="Database Refresher &amp; MODELS - PART1">Database Refresher &amp; MODELS - PART1</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#database-refresher--models---part2" title="Database Refresher &amp; MODELS - PART2">Database Refresher &amp; MODELS - PART2</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#acid-vs-base" title="ACID vs BASE">ACID vs BASE</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#databases-on-ec2" title="Databases on EC2">Databases on EC2</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#relational-database-service-rds-architecture" title="Relational Database Service (RDS) Architecture">Relational Database Service (RDS) Architecture</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#relational-database-service-rds-multiaz---instance-and-cluster" title="Relational Database Service (RDS) MultiAZ - Instance and Cluster">Relational Database Service (RDS) MultiAZ - Instance and Cluster</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#rds-automatic-backup-rds-snapshots-and-restore" title="RDS Automatic Backup, RDS Snapshots and Restore">RDS Automatic Backup, RDS Snapshots and Restore</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#rds-read-replicas" title="RDS Read-Replicas">RDS Read-Replicas</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#rds-data-security" title="RDS Data Security">RDS Data Security</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#rds-custom" title="RDS Custom">RDS Custom</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#aurora-architecture" title="Aurora Architecture">Aurora Architecture</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#aurora-serverless" title="Aurora Serverless">Aurora Serverless</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#aurora-global-database" title="Aurora Global Database">Aurora Global Database</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#multi-master-writes" title="Multi-master writes">Multi-master writes</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#relational-database-service-rds---rds-proxy" title="Relational Database Service (RDS) - RDS Proxy">Relational Database Service (RDS) - RDS Proxy</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#database-migration-service-dms" title="Database Migration Service (DMS)">Database Migration Service (DMS)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#network-storage--data-lifecycle" title="Network Storage &amp; Data Lifecycle">Network Storage &amp; Data Lifecycle</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#efs-architecture" title="EFS Architecture">EFS Architecture</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#aws-backup" title="AWS Backup">AWS Backup</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#ha--scaling" title="HA &amp; SCALING">HA &amp; SCALING</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#regional-and-global-aws-architecture" title="Regional and Global AWS Architecture">Regional and Global AWS Architecture</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#evolution-of-the-elastic-load-balancer" title="Evolution of the Elastic Load Balancer">Evolution of the Elastic Load Balancer</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#elastic-load-balancer-architecture" title="Elastic Load Balancer Architecture">Elastic Load Balancer Architecture</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#application-load-balancing-alb-vs-network-load-balancing-nlb" title="Application Load balancing (ALB) vs Network Load Balancing (NLB)">Application Load balancing (ALB) vs Network Load Balancing (NLB)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#launch-configuration-and-templates" title="Launch Configuration and Templates">Launch Configuration and Templates</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#auto-scaling-groups" title="Auto-Scaling Groups">Auto-Scaling Groups</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#asg-scaling-policies" title="ASG Scaling Policies">ASG Scaling Policies</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#asg-lifecycle-hooks" title="ASG Lifecycle hooks">ASG Lifecycle hooks</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#asg-healthcheck-comparison---ec2-vs-elb" title="ASG HealthCheck Comparison - EC2 vs ELB">ASG HealthCheck Comparison - EC2 vs ELB</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#ssl-offload--session-stickiness" title="SSL Offload &amp; Session Stickiness">SSL Offload &amp; Session Stickiness</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#gateway-load-balancer" title="Gateway Load Balancer">Gateway Load Balancer</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#serverless-and-application-services" title="SERVERLESS AND APPLICATION SERVICES">SERVERLESS AND APPLICATION SERVICES</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#architecture-deep-dive" title="Architecture Deep Dive">Architecture Deep Dive</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#aws-lambda" title="AWS Lambda">AWS Lambda</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#cloudwatchevents-and-eventbridge" title="CloudWatchEvents and EventBridge">CloudWatchEvents and EventBridge</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#serverless-architecture" title="Serverless Architecture">Serverless Architecture</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#simple-notification-service-sns" title="Simple Notification Service (SNS)">Simple Notification Service (SNS)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#step-functions" title="Step Functions">Step Functions</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#api-gateway-101" title="API Gateway 101">API Gateway 101</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#simple-queue-service-sqs" title="Simple Queue Service (SQS)">Simple Queue Service (SQS)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#sqs-standard-vs-fifo-queues" title="SQS Standard vs FIFO Queues">SQS Standard vs FIFO Queues</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#sqs-delay-queues" title="SQS Delay Queues">SQS Delay Queues</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#sqs-dead-letter-queues" title="SQS Dead-Letter Queues">SQS Dead-Letter Queues</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#kinesis-data-streams" title="Kinesis Data Streams">Kinesis Data Streams</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#kinesis-data-firehose" title="Kinesis Data Firehose">Kinesis Data Firehose</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#kinesis-data-analytics" title="Kinesis Data Analytics">Kinesis Data Analytics</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#kinesis-video-streams" title="Kinesis Video Streams">Kinesis Video Streams</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#amazon-cognito---user-and-identity-pools" title="Amazon Cognito - User and Identity Pools">Amazon Cognito - User and Identity Pools</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#aws-glue-101" title="AWS Glue 101">AWS Glue 101</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#amazon-mq-101" title="Amazon MQ 101">Amazon MQ 101</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#amazon-appflow" title="Amazon AppFlow">Amazon AppFlow</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#global-content-delivery-and-optimization" title="GLOBAL CONTENT DELIVERY AND OPTIMIZATION">GLOBAL CONTENT DELIVERY AND OPTIMIZATION</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#cloudfront-architecture" title="Cloudfront Architecture">Cloudfront Architecture</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#cloudfront---ttl-and-invalidations" title="CloudFront - TTL and Invalidations">CloudFront - TTL and Invalidations</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#acm---aws-certificate-manager" title="ACM - AWS Certificate Manager">ACM - AWS Certificate Manager</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#securing-cf-and-s3-using-oai" title="Securing CF and S3 using OAI">Securing CF and S3 using OAI</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#cloudfront---private-distribution--behaviours" title="CloudFront - Private Distribution &amp; Behaviours">CloudFront - Private Distribution &amp; Behaviours</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#lambdaedge" title="Lambda@Edge">Lambda@Edge</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#global-accelerator" title="Global Accelerator">Global Accelerator</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#advanced-vpc-networking" title="ADVANCED VPC Networking">ADVANCED VPC Networking</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#vpc-flow-logs" title="VPC Flow Logs">VPC Flow Logs</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#egress-only-internet-gateway" title="Egress-Only Internet gateway">Egress-Only Internet gateway</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#vpc-endpoints-gateway" title="VPC Endpoints (Gateway)">VPC Endpoints (Gateway)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#vpc-endpoints-inteface" title="VPC Endpoints (Inteface)">VPC Endpoints (Inteface)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#vpc-peering" title="VPC Peering">VPC Peering</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#hybrid-environments-and-migration" title="HYBRID ENVIRONMENTS AND MIGRATION">HYBRID ENVIRONMENTS AND MIGRATION</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#border-gateway-protocol-101" title="Border Gateway Protocol 101">Border Gateway Protocol 101</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#ipsec-vpn-fundamentals" title="IPSec VPN Fundamentals">IPSec VPN Fundamentals</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#aws-site-to-site-vpn" title="AWS Site-to-Site VPN">AWS Site-to-Site VPN</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#start-direct-connect-dx-concepts" title="Start Direct Connect (DX) Concepts">Start Direct Connect (DX) Concepts</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#direct-connect-dx-resilience" title="Direct Connect (DX) Resilience">Direct Connect (DX) Resilience</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#direct-connect-dx---public-vif--vpn-encryption" title="Direct Connect (DX) - Public VIF + VPN (Encryption)">Direct Connect (DX) - Public VIF + VPN (Encryption)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#transit-gateway" title="Transit Gateway">Transit Gateway</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#storage-gateway---volume" title="Storage Gateway - Volume">Storage Gateway - Volume</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#storage-gateway---tape-vtl" title="Storage Gateway - Tape (VTL)">Storage Gateway - Tape (VTL)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#storage-gateway---file" title="Storage Gateway - File">Storage Gateway - File</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#snowball--edge--snowmobile" title="Snowball / Edge / Snowmobile">Snowball / Edge / Snowmobile</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#directory-service" title="Directory Service">Directory Service</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#datasync" title="DataSync">DataSync</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#fsx-for-windows-servers" title="FSx for Windows Servers">FSx for Windows Servers</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#fsx-for-lustre" title="FSx For Lustre">FSx For Lustre</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#aws-transfer-family" title="AWS Transfer Family">AWS Transfer Family</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#security-deployment--operations" title="SECURITY, DEPLOYMENT &amp; OPERATIONS">SECURITY, DEPLOYMENT &amp; OPERATIONS</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#aws-secrets-manager" title="AWS Secrets Manager">AWS Secrets Manager</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#application-layer-l7-firewall" title="Application Layer (L7) Firewall">Application Layer (L7) Firewall</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#web-application-firewall-waf-webacls-rule-groups-and-rules" title="Web Application Firewall (WAF), WEBACLs, Rule Groups and Rules">Web Application Firewall (WAF), WEBACLs, Rule Groups and Rules</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#aws-shield" title="AWS Shield">AWS Shield</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#cloudhsm" title="CloudHSM">CloudHSM</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#aws-config" title="AWS Config">AWS Config</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#amazon-macie" title="Amazon Macie">Amazon Macie</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#amazon-inspector" title="Amazon Inspector">Amazon Inspector</a></div></div></div></div></div></div></div></div></div></div></div><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></main></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"jeybygpftmwnk69ylywov78","title":"Solutions Architect Associate","desc":"Notes for the SAA certification","updated":1759880042451,"created":1734484581601,"custom":{},"fname":"architecture.aws.solutions-architect-associate","type":"note","vault":{"fsPath":"vault"},"contentHash":"214477e753b4b9b8d5f591074fbf3967","links":[{"type":"wiki","from":{"fname":"architecture.aws.solutions-architect-associate","id":"jeybygpftmwnk69ylywov78","vaultName":"vault"},"value":"architecture.tech-fundamentals","position":{"start":{"line":25,"column":1,"offset":1305},"end":{"line":25,"column":35,"offset":1339},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"architecture.tech-fundamentals"}}],"anchors":{"aws-accounts":{"type":"header","text":"AWS Accounts","value":"aws-accounts","line":10,"column":0,"depth":2},"technical-fundamentals":{"type":"header","text":"Technical fundamentals","value":"technical-fundamentals","line":28,"column":0,"depth":2},"aws-fundamentals":{"type":"header","text":"AWS Fundamentals","value":"aws-fundamentals","line":33,"column":0,"depth":2},"public-vs-private-services":{"type":"header","text":"Public vs Private services","value":"public-vs-private-services","line":35,"column":0,"depth":3},"aws-global-infrastructure":{"type":"header","text":"AWS Global Infrastructure","value":"aws-global-infrastructure","line":44,"column":0,"depth":3},"aws-default-virtual-private-cloud-vpc":{"type":"header","text":"AWS Default Virtual Private Cloud (VPC)","value":"aws-default-virtual-private-cloud-vpc","line":61,"column":0,"depth":3},"elastic-compute-cloud-ec2":{"type":"header","text":"Elastic Compute Cloud (EC2)","value":"elastic-compute-cloud-ec2","line":77,"column":0,"depth":3},"simple-storage-service-s3":{"type":"header","text":"Simple Storage Service (S3)","value":"simple-storage-service-s3","line":102,"column":0,"depth":3},"cloudformation-cfn-basics":{"type":"header","text":"CloudFormation (CFN) basics","value":"cloudformation-cfn-basics","line":134,"column":0,"depth":3},"cloudwatch-cw-basics":{"type":"header","text":"CloudWatch (CW) Basics","value":"cloudwatch-cw-basics","line":151,"column":0,"depth":3},"shared-responsibility-model":{"type":"header","text":"Shared Responsibility Model","value":"shared-responsibility-model","line":166,"column":0,"depth":3},"high-availability-vs-fault-tolerance-vs-disaster-recovery":{"type":"header","text":"High-Availability vs Fault-Tolerance vs Disaster Recovery","value":"high-availability-vs-fault-tolerance-vs-disaster-recovery","line":178,"column":0,"depth":3},"route53-r53-fundamentals":{"type":"header","text":"Route53 (R53) Fundamentals","value":"route53-r53-fundamentals","line":196,"column":0,"depth":3},"dns-record-types":{"type":"header","text":"DNS Record Types","value":"dns-record-types","line":210,"column":0,"depth":3},"iam-accounts-and-aws-organisations":{"type":"header","text":"IAM, Accounts and AWS Organisations","value":"iam-accounts-and-aws-organisations","line":233,"column":0,"depth":2},"iam-identity-policies":{"type":"header","text":"IAM Identity Policies","value":"iam-identity-policies","line":235,"column":0,"depth":3},"iam-users-and-arns":{"type":"header","text":"IAM Users and ARNs","value":"iam-users-and-arns","line":273,"column":0,"depth":3},"iam-groups":{"type":"header","text":"IAM Groups","value":"iam-groups","line":292,"column":0,"depth":3},"iam-roles":{"type":"header","text":"IAM Roles","value":"iam-roles","line":308,"column":0,"depth":3},"when-to-use-iam-roles":{"type":"header","text":"When to use IAM Roles","value":"when-to-use-iam-roles","line":322,"column":0,"depth":3},"service-linked-roles-and-passrole":{"type":"header","text":"Service-linked Roles and PassRole","value":"service-linked-roles-and-passrole","line":335,"column":0,"depth":3},"aws-organisations":{"type":"header","text":"AWS Organisations","value":"aws-organisations","line":343,"column":0,"depth":3},"service-control-policies":{"type":"header","text":"Service Control Policies","value":"service-control-policies","line":352,"column":0,"depth":3},"cloudwatch-logs":{"type":"header","text":"CloudWatch Logs","value":"cloudwatch-logs","line":366,"column":0,"depth":3},"cloudtrail-essentials":{"type":"header","text":"CloudTrail Essentials","value":"cloudtrail-essentials","line":376,"column":0,"depth":3},"aws-control-tower":{"type":"header","text":"AWS Control Tower","value":"aws-control-tower","line":395,"column":0,"depth":3},"simple-storage-service":{"type":"header","text":"Simple Storage Service","value":"simple-storage-service","line":436,"column":0,"depth":2},"s3-security-resource-policies-and-acls":{"type":"header","text":"S3 Security (Resource Policies and ACLs)","value":"s3-security-resource-policies-and-acls","line":438,"column":0,"depth":3},"s3-static-hosting":{"type":"header","text":"S3 Static Hosting","value":"s3-static-hosting","line":470,"column":0,"depth":3},"object-versioning-and-mfa-delete":{"type":"header","text":"Object Versioning and MFA Delete","value":"object-versioning-and-mfa-delete","line":489,"column":0,"depth":3},"s3-performance-optimization":{"type":"header","text":"S3 Performance Optimization","value":"s3-performance-optimization","line":508,"column":0,"depth":3},"key-management-system":{"type":"header","text":"Key Management System","value":"key-management-system","line":522,"column":0,"depth":3},"s3-object-encryption-csesse":{"type":"header","text":"S3 Object Encryption CSE/SSE","value":"s3-object-encryption-csesse","line":556,"column":0,"depth":3},"s3-bucket-keys":{"type":"header","text":"S3 Bucket Keys","value":"s3-bucket-keys","line":589,"column":0,"depth":3},"s3-object-storage-classes":{"type":"header","text":"S3 Object Storage Classes","value":"s3-object-storage-classes","line":600,"column":0,"depth":3},"s3-lifecycle-configuration":{"type":"header","text":"S3 Lifecycle Configuration","value":"s3-lifecycle-configuration","line":653,"column":0,"depth":3},"s3-replication":{"type":"header","text":"S3 Replication","value":"s3-replication","line":671,"column":0,"depth":3},"s3-presigned-urls":{"type":"header","text":"S3 PreSigned URLs","value":"s3-presigned-urls","line":711,"column":0,"depth":3},"s3-select-and-glacier-select":{"type":"header","text":"S3 Select and Glacier Select","value":"s3-select-and-glacier-select","line":722,"column":0,"depth":3},"s3-events":{"type":"header","text":"S3 Events","value":"s3-events","line":730,"column":0,"depth":3},"s3-access-logs":{"type":"header","text":"S3 Access Logs","value":"s3-access-logs","line":739,"column":0,"depth":3},"s3-object-lock":{"type":"header","text":"S3 Object Lock","value":"s3-object-lock","line":744,"column":0,"depth":3},"s3-access-points":{"type":"header","text":"S3 Access Points","value":"s3-access-points","line":766,"column":0,"depth":3},"virtual-private-cloud-vpc-basics":{"type":"header","text":"Virtual Private Cloud (VPC) Basics","value":"virtual-private-cloud-vpc-basics","line":775,"column":0,"depth":2},"vpc-sizing-and-structure":{"type":"header","text":"VPC Sizing and Structure","value":"vpc-sizing-and-structure","line":777,"column":0,"depth":3},"custom-vpcs":{"type":"header","text":"Custom VPCs","value":"custom-vpcs","line":802,"column":0,"depth":3},"vpc-subnets":{"type":"header","text":"VPC Subnets","value":"vpc-subnets","line":823,"column":0,"depth":3},"vpc-routing-internet-gateway--bastion-hosts":{"type":"header","text":"VPC Routing, Internet Gateway \u0026 Bastion Hosts","value":"vpc-routing-internet-gateway--bastion-hosts","line":850,"column":0,"depth":3},"stateful-vs-stateless-firewalls":{"type":"header","text":"Stateful vs Stateless Firewalls","value":"stateful-vs-stateless-firewalls","line":882,"column":0,"depth":3},"network-access-control-lists-nacls":{"type":"header","text":"Network Access Control Lists (NACLs)","value":"network-access-control-lists-nacls","line":892,"column":0,"depth":3},"security-groups-sg":{"type":"header","text":"Security Groups (SG)","value":"security-groups-sg","line":905,"column":0,"depth":3},"network-address-translation-nat--nat-gateway":{"type":"header","text":"Network Address Translation (NAT) \u0026 NAT Gateway","value":"network-address-translation-nat--nat-gateway","line":917,"column":0,"depth":3},"elastic-compute-cloud-ec2-basics":{"type":"header","text":"Elastic Compute Cloud (EC2) Basics","value":"elastic-compute-cloud-ec2-basics","line":946,"column":0,"depth":2},"virtualization-101":{"type":"header","text":"Virtualization 101","value":"virtualization-101","line":948,"column":0,"depth":3},"ec2-architecture-and-resilience":{"type":"header","text":"EC2 Architecture and Resilience","value":"ec2-architecture-and-resilience","line":962,"column":0,"depth":3},"ec2-instance-types":{"type":"header","text":"EC2 Instance Types","value":"ec2-instance-types","line":985,"column":0,"depth":3},"storage-refresher":{"type":"header","text":"Storage Refresher","value":"storage-refresher","line":1013,"column":0,"depth":3},"elastic-block-store-ebs-service-architecture":{"type":"header","text":"Elastic Block Store (EBS) Service Architecture","value":"elastic-block-store-ebs-service-architecture","line":1036,"column":0,"depth":3},"ebs-volume-types---general-purpose":{"type":"header","text":"EBS Volume Types - General Purpose","value":"ebs-volume-types---general-purpose","line":1051,"column":0,"depth":3},"ebs-volume-types---provisioned-iops":{"type":"header","text":"EBS Volume Types - Provisioned IOPS","value":"ebs-volume-types---provisioned-iops","line":1073,"column":0,"depth":3},"ebs-volume-types---hdd-based":{"type":"header","text":"EBS Volume Types - HDD-Based","value":"ebs-volume-types---hdd-based","line":1083,"column":0,"depth":3},"instance-store-volumes---architecture":{"type":"header","text":"Instance Store Volumes - Architecture","value":"instance-store-volumes---architecture","line":1105,"column":0,"depth":3},"choosing-between-the-ec2-instance-store-and-ebs":{"type":"header","text":"Choosing between the EC2 Instance Store and EBS","value":"choosing-between-the-ec2-instance-store-and-ebs","line":1128,"column":0,"depth":3},"snapshots-restore--fast-snapshot-restore-fsr":{"type":"header","text":"Snapshots, Restore \u0026 Fast Snapshot Restore (FSR)","value":"snapshots-restore--fast-snapshot-restore-fsr","line":1150,"column":0,"depth":3},"ebs-encryption":{"type":"header","text":"EBS Encryption","value":"ebs-encryption","line":1173,"column":0,"depth":3},"network-interfaces-instance-ips-and-dns":{"type":"header","text":"Network Interfaces, Instance IPs and DNS","value":"network-interfaces-instance-ips-and-dns","line":1187,"column":0,"depth":3},"amazon-machine-images-ami":{"type":"header","text":"Amazon Machine Images (AMI)","value":"amazon-machine-images-ami","line":1205,"column":0,"depth":3},"ec2-purchase-options":{"type":"header","text":"EC2 Purchase Options","value":"ec2-purchase-options","line":1228,"column":0,"depth":3},"reserved-instances---the-rest":{"type":"header","text":"Reserved Instances - the rest","value":"reserved-instances---the-rest","line":1276,"column":0,"depth":3},"instance-status-checks--auto-recovery":{"type":"header","text":"Instance Status Checks \u0026 Auto Recovery","value":"instance-status-checks--auto-recovery","line":1295,"column":0,"depth":3},"horizontal--vertical-scaling":{"type":"header","text":"Horizontal \u0026 Vertical Scaling","value":"horizontal--vertical-scaling","line":1302,"column":0,"depth":3},"instance-metadata":{"type":"header","text":"Instance Metadata","value":"instance-metadata","line":1327,"column":0,"depth":3},"containers--ecs":{"type":"header","text":"Containers \u0026 ECS","value":"containers--ecs","line":1339,"column":0,"depth":2},"introduction-to-containers":{"type":"header","text":"Introduction to Containers","value":"introduction-to-containers","line":1341,"column":0,"depth":3},"ecs---concepts":{"type":"header","text":"ECS - Concepts","value":"ecs---concepts","line":1361,"column":0,"depth":3},"ecs---cluster-mode":{"type":"header","text":"ECS - Cluster Mode","value":"ecs---cluster-mode","line":1378,"column":0,"depth":3},"elastic-container-registry-ecr":{"type":"header","text":"Elastic Container Registry (ECR)","value":"elastic-container-registry-ecr","line":1408,"column":0,"depth":3},"kubernetes-101":{"type":"header","text":"Kubernetes 101","value":"kubernetes-101","line":1424,"column":0,"depth":3},"elastic-kubernetes-service-eks-101":{"type":"header","text":"Elastic Kubernetes Service (EKS) 101","value":"elastic-kubernetes-service-eks-101","line":1455,"column":0,"depth":3},"advanced-ec2":{"type":"header","text":"Advanced EC2","value":"advanced-ec2","line":1466,"column":0,"depth":2},"bootstrapping-ec2-using-user-data":{"type":"header","text":"Bootstrapping EC2 using User Data","value":"bootstrapping-ec2-using-user-data","line":1468,"column":0,"depth":3},"enhanced-bootstrapping-with-cfn-init":{"type":"header","text":"Enhanced Bootstrapping with CFN-INIT","value":"enhanced-bootstrapping-with-cfn-init","line":1491,"column":0,"depth":3},"ec2-instance-roles--profile":{"type":"header","text":"EC2 Instance Roles \u0026 Profile","value":"ec2-instance-roles--profile","line":1504,"column":0,"depth":3},"ssm-parameter-store":{"type":"header","text":"SSM Parameter Store","value":"ssm-parameter-store","line":1513,"column":0,"depth":3},"system-and-application-logging-on-ec2":{"type":"header","text":"System and Application Logging on EC2","value":"system-and-application-logging-on-ec2","line":1524,"column":0,"depth":3},"ec2-placement-groups":{"type":"header","text":"EC2 Placement Groups","value":"ec2-placement-groups","line":1531,"column":0,"depth":3},"dedicated-hosts":{"type":"header","text":"Dedicated Hosts","value":"dedicated-hosts","line":1575,"column":0,"depth":3},"enhanced-networking--ebs-optimized":{"type":"header","text":"Enhanced Networking \u0026 EBS Optimized","value":"enhanced-networking--ebs-optimized","line":1592,"column":0,"depth":3},"route-53---global-dns":{"type":"header","text":"Route 53 - Global DNS","value":"route-53---global-dns","line":1612,"column":0,"depth":2},"r53-public-hosted-zones":{"type":"header","text":"R53 Public Hosted Zones","value":"r53-public-hosted-zones","line":1614,"column":0,"depth":3},"r53-private-hosted-zones":{"type":"header","text":"R53 Private Hosted Zones","value":"r53-private-hosted-zones","line":1631,"column":0,"depth":3},"cname-vs-r53-alias":{"type":"header","text":"CNAME vs R53 Alias","value":"cname-vs-r53-alias","line":1641,"column":0,"depth":3},"simple-routing":{"type":"header","text":"Simple Routing","value":"simple-routing","line":1662,"column":0,"depth":3},"r53-health-checks":{"type":"header","text":"R53 Health Checks","value":"r53-health-checks","line":1670,"column":0,"depth":3},"failover-routing":{"type":"header","text":"Failover Routing","value":"failover-routing","line":1682,"column":0,"depth":3},"multi-value-routing":{"type":"header","text":"Multi value routing","value":"multi-value-routing","line":1687,"column":0,"depth":3},"weighted-routing":{"type":"header","text":"Weighted Routing","value":"weighted-routing","line":1699,"column":0,"depth":3},"latency-routing":{"type":"header","text":"Latency Routing","value":"latency-routing","line":1709,"column":0,"depth":3},"geolocation-routing":{"type":"header","text":"Geolocation Routing","value":"geolocation-routing","line":1718,"column":0,"depth":3},"geoproximity":{"type":"header","text":"Geoproximity","value":"geoproximity","line":1727,"column":0,"depth":3},"r53-interoperability":{"type":"header","text":"R53 Interoperability","value":"r53-interoperability","line":1734,"column":0,"depth":3},"implementing-dnssec-using-route53":{"type":"header","text":"Implementing DNSSEC using Route53","value":"implementing-dnssec-using-route53","line":1750,"column":0,"depth":3},"relational-database-service-rds":{"type":"header","text":"Relational Database Service (RDS)","value":"relational-database-service-rds","line":1758,"column":0,"depth":2},"database-refresher--models---part1":{"type":"header","text":"Database Refresher \u0026 MODELS - PART1","value":"database-refresher--models---part1","line":1760,"column":0,"depth":3},"database-refresher--models---part2":{"type":"header","text":"Database Refresher \u0026 MODELS - PART2","value":"database-refresher--models---part2","line":1770,"column":0,"depth":3},"acid-vs-base":{"type":"header","text":"ACID vs BASE","value":"acid-vs-base","line":1815,"column":0,"depth":3},"databases-on-ec2":{"type":"header","text":"Databases on EC2","value":"databases-on-ec2","line":1840,"column":0,"depth":3},"relational-database-service-rds-architecture":{"type":"header","text":"Relational Database Service (RDS) Architecture","value":"relational-database-service-rds-architecture","line":1864,"column":0,"depth":3},"relational-database-service-rds-multiaz---instance-and-cluster":{"type":"header","text":"Relational Database Service (RDS) MultiAZ - Instance and Cluster","value":"relational-database-service-rds-multiaz---instance-and-cluster","line":1886,"column":0,"depth":3},"rds-automatic-backup-rds-snapshots-and-restore":{"type":"header","text":"RDS Automatic Backup, RDS Snapshots and Restore","value":"rds-automatic-backup-rds-snapshots-and-restore","line":1910,"column":0,"depth":3},"rds-read-replicas":{"type":"header","text":"RDS Read-Replicas","value":"rds-read-replicas","line":1941,"column":0,"depth":3},"rds-data-security":{"type":"header","text":"RDS Data Security","value":"rds-data-security","line":1958,"column":0,"depth":3},"rds-custom":{"type":"header","text":"RDS Custom","value":"rds-custom","line":1975,"column":0,"depth":3},"aurora-architecture":{"type":"header","text":"Aurora Architecture","value":"aurora-architecture","line":1982,"column":0,"depth":3},"aurora-serverless":{"type":"header","text":"Aurora Serverless","value":"aurora-serverless","line":2012,"column":0,"depth":3},"aurora-global-database":{"type":"header","text":"Aurora Global Database","value":"aurora-global-database","line":2042,"column":0,"depth":3},"multi-master-writes":{"type":"header","text":"Multi-master writes","value":"multi-master-writes","line":2054,"column":0,"depth":3},"relational-database-service-rds---rds-proxy":{"type":"header","text":"Relational Database Service (RDS) - RDS Proxy","value":"relational-database-service-rds---rds-proxy","line":2065,"column":0,"depth":3},"database-migration-service-dms":{"type":"header","text":"Database Migration Service (DMS)","value":"database-migration-service-dms","line":2089,"column":0,"depth":3},"network-storage--data-lifecycle":{"type":"header","text":"Network Storage \u0026 Data Lifecycle","value":"network-storage--data-lifecycle","line":2106,"column":0,"depth":2},"efs-architecture":{"type":"header","text":"EFS Architecture","value":"efs-architecture","line":2108,"column":0,"depth":3},"aws-backup":{"type":"header","text":"AWS Backup","value":"aws-backup","line":2124,"column":0,"depth":3},"ha--scaling":{"type":"header","text":"HA \u0026 SCALING","value":"ha--scaling","line":2139,"column":0,"depth":2},"regional-and-global-aws-architecture":{"type":"header","text":"Regional and Global AWS Architecture","value":"regional-and-global-aws-architecture","line":2141,"column":0,"depth":3},"evolution-of-the-elastic-load-balancer":{"type":"header","text":"Evolution of the Elastic Load Balancer","value":"evolution-of-the-elastic-load-balancer","line":2163,"column":0,"depth":3},"elastic-load-balancer-architecture":{"type":"header","text":"Elastic Load Balancer Architecture","value":"elastic-load-balancer-architecture","line":2174,"column":0,"depth":3},"application-load-balancing-alb-vs-network-load-balancing-nlb":{"type":"header","text":"Application Load balancing (ALB) vs Network Load Balancing (NLB)","value":"application-load-balancing-alb-vs-network-load-balancing-nlb","line":2192,"column":0,"depth":3},"launch-configuration-and-templates":{"type":"header","text":"Launch Configuration and Templates","value":"launch-configuration-and-templates","line":2237,"column":0,"depth":3},"auto-scaling-groups":{"type":"header","text":"Auto-Scaling Groups","value":"auto-scaling-groups","line":2245,"column":0,"depth":3},"asg-scaling-policies":{"type":"header","text":"ASG Scaling Policies","value":"asg-scaling-policies","line":2285,"column":0,"depth":3},"asg-lifecycle-hooks":{"type":"header","text":"ASG Lifecycle hooks","value":"asg-lifecycle-hooks","line":2296,"column":0,"depth":3},"asg-healthcheck-comparison---ec2-vs-elb":{"type":"header","text":"ASG HealthCheck Comparison - EC2 vs ELB","value":"asg-healthcheck-comparison---ec2-vs-elb","line":2302,"column":0,"depth":3},"ssl-offload--session-stickiness":{"type":"header","text":"SSL Offload \u0026 Session Stickiness","value":"ssl-offload--session-stickiness","line":2313,"column":0,"depth":3},"gateway-load-balancer":{"type":"header","text":"Gateway Load Balancer","value":"gateway-load-balancer","line":2351,"column":0,"depth":3},"serverless-and-application-services":{"type":"header","text":"SERVERLESS AND APPLICATION SERVICES","value":"serverless-and-application-services","line":2359,"column":0,"depth":2},"architecture-deep-dive":{"type":"header","text":"Architecture Deep Dive","value":"architecture-deep-dive","line":2361,"column":0,"depth":3},"aws-lambda":{"type":"header","text":"AWS Lambda","value":"aws-lambda","line":2398,"column":0,"depth":3},"cloudwatchevents-and-eventbridge":{"type":"header","text":"CloudWatchEvents and EventBridge","value":"cloudwatchevents-and-eventbridge","line":2470,"column":0,"depth":3},"serverless-architecture":{"type":"header","text":"Serverless Architecture","value":"serverless-architecture","line":2481,"column":0,"depth":3},"simple-notification-service-sns":{"type":"header","text":"Simple Notification Service (SNS)","value":"simple-notification-service-sns","line":2491,"column":0,"depth":3},"step-functions":{"type":"header","text":"Step Functions","value":"step-functions","line":2510,"column":0,"depth":3},"api-gateway-101":{"type":"header","text":"API Gateway 101","value":"api-gateway-101","line":2539,"column":0,"depth":3},"simple-queue-service-sqs":{"type":"header","text":"Simple Queue Service (SQS)","value":"simple-queue-service-sqs","line":2581,"column":0,"depth":3},"sqs-standard-vs-fifo-queues":{"type":"header","text":"SQS Standard vs FIFO Queues","value":"sqs-standard-vs-fifo-queues","line":2602,"column":0,"depth":3},"sqs-delay-queues":{"type":"header","text":"SQS Delay Queues","value":"sqs-delay-queues","line":2611,"column":0,"depth":3},"sqs-dead-letter-queues":{"type":"header","text":"SQS Dead-Letter Queues","value":"sqs-dead-letter-queues","line":2617,"column":0,"depth":3},"kinesis-data-streams":{"type":"header","text":"Kinesis Data Streams","value":"kinesis-data-streams","line":2625,"column":0,"depth":3},"kinesis-data-firehose":{"type":"header","text":"Kinesis Data Firehose","value":"kinesis-data-firehose","line":2644,"column":0,"depth":3},"kinesis-data-analytics":{"type":"header","text":"Kinesis Data Analytics","value":"kinesis-data-analytics","line":2668,"column":0,"depth":3},"kinesis-video-streams":{"type":"header","text":"Kinesis Video Streams","value":"kinesis-video-streams","line":2689,"column":0,"depth":3},"amazon-cognito---user-and-identity-pools":{"type":"header","text":"Amazon Cognito - User and Identity Pools","value":"amazon-cognito---user-and-identity-pools","line":2698,"column":0,"depth":3},"aws-glue-101":{"type":"header","text":"AWS Glue 101","value":"aws-glue-101","line":2712,"column":0,"depth":3},"amazon-mq-101":{"type":"header","text":"Amazon MQ 101","value":"amazon-mq-101","line":2728,"column":0,"depth":3},"amazon-appflow":{"type":"header","text":"Amazon AppFlow","value":"amazon-appflow","line":2750,"column":0,"depth":3},"global-content-delivery-and-optimization":{"type":"header","text":"GLOBAL CONTENT DELIVERY AND OPTIMIZATION","value":"global-content-delivery-and-optimization","line":2760,"column":0,"depth":2},"cloudfront-architecture":{"type":"header","text":"Cloudfront Architecture","value":"cloudfront-architecture","line":2762,"column":0,"depth":3},"cloudfront---ttl-and-invalidations":{"type":"header","text":"CloudFront - TTL and Invalidations","value":"cloudfront---ttl-and-invalidations","line":2779,"column":0,"depth":3},"acm---aws-certificate-manager":{"type":"header","text":"ACM - AWS Certificate Manager","value":"acm---aws-certificate-manager","line":2794,"column":0,"depth":3},"securing-cf-and-s3-using-oai":{"type":"header","text":"Securing CF and S3 using OAI","value":"securing-cf-and-s3-using-oai","line":2815,"column":0,"depth":3},"cloudfront---private-distribution--behaviours":{"type":"header","text":"CloudFront - Private Distribution \u0026 Behaviours","value":"cloudfront---private-distribution--behaviours","line":2828,"column":0,"depth":3},"lambdaedge":{"type":"header","text":"Lambda@Edge","value":"lambdaedge","line":2843,"column":0,"depth":3},"global-accelerator":{"type":"header","text":"Global Accelerator","value":"global-accelerator","line":2853,"column":0,"depth":3},"advanced-vpc-networking":{"type":"header","text":"ADVANCED VPC Networking","value":"advanced-vpc-networking","line":2868,"column":0,"depth":2},"vpc-flow-logs":{"type":"header","text":"VPC Flow Logs","value":"vpc-flow-logs","line":2869,"column":0,"depth":3},"egress-only-internet-gateway":{"type":"header","text":"Egress-Only Internet gateway","value":"egress-only-internet-gateway","line":2879,"column":0,"depth":3},"vpc-endpoints-gateway":{"type":"header","text":"VPC Endpoints (Gateway)","value":"vpc-endpoints-gateway","line":2886,"column":0,"depth":3},"vpc-endpoints-inteface":{"type":"header","text":"VPC Endpoints (Inteface)","value":"vpc-endpoints-inteface","line":2900,"column":0,"depth":3},"vpc-peering":{"type":"header","text":"VPC Peering","value":"vpc-peering","line":2912,"column":0,"depth":3},"hybrid-environments-and-migration":{"type":"header","text":"HYBRID ENVIRONMENTS AND MIGRATION","value":"hybrid-environments-and-migration","line":2919,"column":0,"depth":2},"border-gateway-protocol-101":{"type":"header","text":"Border Gateway Protocol 101","value":"border-gateway-protocol-101","line":2921,"column":0,"depth":3},"ipsec-vpn-fundamentals":{"type":"header","text":"IPSec VPN Fundamentals","value":"ipsec-vpn-fundamentals","line":2931,"column":0,"depth":3},"aws-site-to-site-vpn":{"type":"header","text":"AWS Site-to-Site VPN","value":"aws-site-to-site-vpn","line":2949,"column":0,"depth":3},"start-direct-connect-dx-concepts":{"type":"header","text":"Start Direct Connect (DX) Concepts","value":"start-direct-connect-dx-concepts","line":2965,"column":0,"depth":3},"direct-connect-dx-resilience":{"type":"header","text":"Direct Connect (DX) Resilience","value":"direct-connect-dx-resilience","line":2975,"column":0,"depth":3},"direct-connect-dx---public-vif--vpn-encryption":{"type":"header","text":"Direct Connect (DX) - Public VIF + VPN (Encryption)","value":"direct-connect-dx---public-vif--vpn-encryption","line":2991,"column":0,"depth":3},"transit-gateway":{"type":"header","text":"Transit Gateway","value":"transit-gateway","line":2999,"column":0,"depth":3},"storage-gateway---volume":{"type":"header","text":"Storage Gateway - Volume","value":"storage-gateway---volume","line":3011,"column":0,"depth":3},"storage-gateway---tape-vtl":{"type":"header","text":"Storage Gateway - Tape (VTL)","value":"storage-gateway---tape-vtl","line":3024,"column":0,"depth":3},"storage-gateway---file":{"type":"header","text":"Storage Gateway - File","value":"storage-gateway---file","line":3028,"column":0,"depth":3},"snowball--edge--snowmobile":{"type":"header","text":"Snowball / Edge / Snowmobile","value":"snowball--edge--snowmobile","line":3036,"column":0,"depth":3},"directory-service":{"type":"header","text":"Directory Service","value":"directory-service","line":3066,"column":0,"depth":3},"datasync":{"type":"header","text":"DataSync","value":"datasync","line":3088,"column":0,"depth":3},"fsx-for-windows-servers":{"type":"header","text":"FSx for Windows Servers","value":"fsx-for-windows-servers","line":3101,"column":0,"depth":3},"fsx-for-lustre":{"type":"header","text":"FSx For Lustre","value":"fsx-for-lustre","line":3116,"column":0,"depth":3},"aws-transfer-family":{"type":"header","text":"AWS Transfer Family","value":"aws-transfer-family","line":3132,"column":0,"depth":3},"security-deployment--operations":{"type":"header","text":"SECURITY, DEPLOYMENT \u0026 OPERATIONS","value":"security-deployment--operations","line":3150,"column":0,"depth":2},"aws-secrets-manager":{"type":"header","text":"AWS Secrets Manager","value":"aws-secrets-manager","line":3151,"column":0,"depth":3},"application-layer-l7-firewall":{"type":"header","text":"Application Layer (L7) Firewall","value":"application-layer-l7-firewall","line":3158,"column":0,"depth":3},"web-application-firewall-waf-webacls-rule-groups-and-rules":{"type":"header","text":"Web Application Firewall (WAF), WEBACLs, Rule Groups and Rules","value":"web-application-firewall-waf-webacls-rule-groups-and-rules","line":3170,"column":0,"depth":3},"aws-shield":{"type":"header","text":"AWS Shield","value":"aws-shield","line":3202,"column":0,"depth":3},"cloudhsm":{"type":"header","text":"CloudHSM","value":"cloudhsm","line":3229,"column":0,"depth":3},"aws-config":{"type":"header","text":"AWS Config","value":"aws-config","line":3247,"column":0,"depth":3},"amazon-macie":{"type":"header","text":"Amazon Macie","value":"amazon-macie","line":3255,"column":0,"depth":3},"amazon-inspector":{"type":"header","text":"Amazon Inspector","value":"amazon-inspector","line":3278,"column":0,"depth":3}},"children":[],"parent":"gb52lee4nm5k27xqxprhu2w","data":{}},"body":"\u003ch1 id=\"solutions-architect-associate\"\u003eSolutions Architect Associate\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#solutions-architect-associate\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003eNotes attributed to \u003ca href=\"https://learn.cantrill.io/courses/enrolled/1820301\"\u003ethis course\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"aws-accounts\"\u003eAWS Accounts\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#aws-accounts\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eAn AWS account is a container for identities (users) and resources\u003c/li\u003e\n\u003cli\u003eEvery AWS account has a root user\u003c/li\u003e\n\u003cli\u003eThe account root user can't be restricted it has full access to everything within this account.\u003c/li\u003e\n\u003cli\u003eThe credit card used with the root account will be the \u003cstrong\u003eAccount\u003c/strong\u003e Payment method, everything will be billed to that card\u003c/li\u003e\n\u003cli\u003eAWS is a pay-as-you-go/consume platform\u003c/li\u003e\n\u003cli\u003eCertain resources have a free-tier\u003c/li\u003e\n\u003cli\u003eIAM - every AWS account comes with it's own IAM Database\u003c/li\u003e\n\u003cli\u003eIAM lets you create 3 different IAM profiles - Users, groups and roles\n\u003cul\u003e\n\u003cli\u003eUsers represent humans or applications that need access to your account - this is for individual purposes\u003c/li\u003e\n\u003cli\u003eGroups are a collection of related users\u003c/li\u003e\n\u003cli\u003eRoles can be used for granting external access to your account\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eIAM policy - used to allow/deny access to AWS services attached to other identities\u003c/li\u003e\n\u003cli\u003eIAM is an identity provider, which also authenticates and authorizes\u003c/li\u003e\n\u003cli\u003eIAM Access Keys are long term credentials with up to 2 available per IAM user typically used in CLIs or applications\u003c/li\u003e\n\u003cli\u003eAccess Keys are made up of Access Key ID and the Secret Access Key\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"technical-fundamentals\"\u003eTechnical fundamentals\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#technical-fundamentals\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003ePre-cursor to the concepts covered in this course summarized here:\n\u003ca href=\"/KnowledgeGarden/notes/fqi20n3dabq8rhrs04h6tk3\"\u003eTech Fundamentals\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"aws-fundamentals\"\u003eAWS Fundamentals\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#aws-fundamentals\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003ch3 id=\"public-vs-private-services\"\u003ePublic vs Private services\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#public-vs-private-services\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eServices can be categorized into two types: public and private services\u003c/li\u003e\n\u003cli\u003eAWS public and private service are separated by network access.\u003c/li\u003e\n\u003cli\u003ePublic service is something which can be accessed using public endpoints e.g. s3\u003c/li\u003e\n\u003cli\u003eA private aws service runs within a vpc so only what is connected to that vpc can access it\u003c/li\u003e\n\u003cli\u003eAWS has three zones - the public internet zone, the private network and the AWS public zone which runs in between the public and private zone.\u003c/li\u003e\n\u003cli\u003eAWS public zone is where public services operate from e.g. s3\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"aws-global-infrastructure\"\u003eAWS Global Infrastructure\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#aws-global-infrastructure\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eAWS have created their infrastructure platform consisting of isolated regions connected together.\u003c/li\u003e\n\u003cli\u003eA region is a creation of AWS which covers an area over the world which contains a full deployment of AWS infrastructure. New regions are added all the time.\u003c/li\u003e\n\u003cli\u003eWhen interacting with most AWS services you're doing it at a particular region e.g. elastic compute cloud in North virginia is different to interacting to elastic compute in Sydney.\u003c/li\u003e\n\u003cli\u003eAWS also provides Edge locations which are smaller than regions and they typically have only content distribution services as well as some types of edge computing. They are useful for companies like Netflix who want to store tv shows and movies as close to their customers as possible to allow low for low latency and high speed distribution\u003c/li\u003e\n\u003cli\u003eSome services act from a global perspective e.g. IAM\u003c/li\u003e\n\u003cli\u003eRegions have three main benefits:\u003c/li\u003e\n\u003c/ul\u003e\n\u003col\u003e\n\u003cli\u003eEach reason is separate geographically which isolates any faults\u003c/li\u003e\n\u003cli\u003eGeopolitical separation - different governance depending the region\u003c/li\u003e\n\u003cli\u003eLocation control - tune architecture performance relative to an area\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003eRegions also have a code e.g. Sydney is ep-southeast-2, as well as a name - Asia Pacific (Sydney)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eInside every region, AWS also provide multiple availability zones. These give isolated infrastructure within a region. If a region experiences an isolated issue but only one availability zone is affected, the others are likely to be still fully functional. A solutions architect may distribute the services across multiple availability zones. This is used to build resilience.\u003c/p\u003e\n\u003ch3 id=\"aws-default-virtual-private-cloud-vpc\"\u003eAWS Default Virtual Private Cloud (VPC)\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#aws-default-virtual-private-cloud-vpc\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA VPC is a Virtual Network inside AWS\u003c/li\u003e\n\u003cli\u003eA VPC is a regional service that operates within that region\u003c/li\u003e\n\u003cli\u003eA VPC by default is private and isolated. Services deployed into the same vpc can communicate but it's isolated from other vpcs and the AWS zone/public internet.\u003c/li\u003e\n\u003cli\u003eThere are two types of VPCs per account:\u003c/li\u003e\n\u003c/ul\u003e\n\u003col\u003e\n\u003cli\u003eDefault VPCs - can only have one per region. Configured by AWS.\u003c/li\u003e\n\u003cli\u003eCustom VPCs - can have many per region. You use these in almost all serious AWS deployments to configure them how you like.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003eVPCs cannot communicate with each other without you configuring them to do so.\u003c/li\u003e\n\u003cli\u003eVPCs are regionally resilient\u003c/li\u003e\n\u003cli\u003eThe default VPC gets a default CIDR IP range which is always the same - 172.31.0.0/16\u003c/li\u003e\n\u003cli\u003eA VPC can be subdivided into subnets for resilience. Each subnet inside a VPC can be put into an availability zone. The default VPC has one subnet in every availability zone in that region.\u003c/li\u003e\n\u003cli\u003ethe default VPC assigns a public address to the services by default.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"elastic-compute-cloud-ec2\"\u003eElastic Compute Cloud (EC2)\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#elastic-compute-cloud-ec2\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eEC2 is a service which allows you to provision virtual machines known as instances with an operating system.\u003c/li\u003e\n\u003cli\u003eEC2 is IAAS (Infrastructure as a Service) which provides access to virtual machines (instances)\u003c/li\u003e\n\u003cli\u003eAn instance is just an operating system configured in a certain way\u003c/li\u003e\n\u003cli\u003eEC2 is a private AWS service by default - it uses VPC. You can configure it to have public access\u003c/li\u003e\n\u003cli\u003eAn EC2 is AZ (availability zone) resilient. If the AZ fails then the instance fails\u003c/li\u003e\n\u003cli\u003eYou can choose an instance with various sizes and capabilities\u003c/li\u003e\n\u003cli\u003eEC2 provides on-demand billing - per second\u003c/li\u003e\n\u003cli\u003eInstances can use different types of storage e.g. local host storage (ec2 host) or Elastic Block Store (EBS) which is network storage made available\u003c/li\u003e\n\u003cli\u003eEC2 instances have a state e.g. RUNNING -\u003e STOPPED -\u003e TERMINATED\u003c/li\u003e\n\u003cli\u003eEC2 can be moved from RUNNING TO STOPPED and back again\u003c/li\u003e\n\u003cli\u003eTERMINATING an instance is a one way change, you can do that from the RUNNING or STOPPED state. It's a non-reversible action\u003c/li\u003e\n\u003cli\u003eAt a high level, an instance is composed of CPU, memory, disk and networking. You are charged for all four of those instances.\u003c/li\u003e\n\u003cli\u003eWhen an instance is STOPPED, it means no CPU, memory or network is being used therefore you won't be charged for any running costs of that instance. Storage however is still being used when it's in the stopped state which means you will be charged for it.\u003c/li\u003e\n\u003cli\u003eIn order to have no costs for an EC2 instance you need to terminate it.\u003c/li\u003e\n\u003cli\u003eAn Amazon Machine Image (AMI) is an image of an EC2 instance.\u003c/li\u003e\n\u003cli\u003eAn AMI can be used to create an EC2 instance or an AMI can be created from an EC2 instance.\u003c/li\u003e\n\u003cli\u003eAn AMI is similar to a server image in a physical server\u003c/li\u003e\n\u003cli\u003eAn AMI contains:\n\u003cul\u003e\n\u003cli\u003eAttached permissions - who can use the image e.g only owner vs specific accounts vs public\u003c/li\u003e\n\u003cli\u003eRoot volume - the drive that boots the operating system\u003c/li\u003e\n\u003cli\u003eBlock device mapping - configuration which links the volumes that the AMI has and how they're presented to the operating system e.g boot vs data volume\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eEC2 can host different OS e.g. linux, windows, macos. You can connect to them via remote desktop (windows) or SSH (linux/macos)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"simple-storage-service-s3\"\u003eSimple Storage Service (S3)\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#simple-storage-service-s3\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eS3 is a global storage platform - it's regionally resilient. The data is replicated across availability zones in that regions. It can tolerate a fault in an AZ\u003c/li\u003e\n\u003cli\u003eS3 is a public service\u003c/li\u003e\n\u003cli\u003eIt's used to host a large amount of data e.g. movies, audio, photos, text, large data sets\u003c/li\u003e\n\u003cli\u003eEconomical and can be accessed via a variety of methods e.g. UI/CLI/API/HTTP\u003c/li\u003e\n\u003cli\u003eS3 delivers two main things:\u003c/li\u003e\n\u003c/ul\u003e\n\u003col\u003e\n\u003cli\u003eObjects - the data s3 stores\u003c/li\u003e\n\u003cli\u003eBuckets - containers for objects\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003eObjects\u003c/strong\u003e are basically files that are made up of two components:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003ethe object key (name) - usually the file name\u003c/li\u003e\n\u003cli\u003ethe object value (data) - the data or contents of the object\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eThe bucket name needs to be \u003cstrong\u003eglobally unique\u003c/strong\u003e - this is across all regions and aws accounts. It should be between 3-63 characters, all lower case, no underscores. Must start with a lowercase letter or a number. It can't be formatted like an IP address.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eA bucket can hold an unlimited number of objects and an unlimited amount of data - it's an infinitely scalable service.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eA bucket may show on the UI that it has folders but the underlying structure is flat and everything sits in the root. Folders are referred to as prefixes in s3 as they prefix the object names.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThere is a soft limit of 100 buckets for an s3 account and a hard limit of 1000 buckets using support request.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eYou can have unlimited objects in a bucket, with each object able to range between 0 to 5TB in size.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eS3 is not a file or block. It is an object store\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eYou can't mount an s3 bucket as a drive e.g. K:\\ or /images\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003es3 is great for large scale data storage, distribution or upload\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003egreat for offloading - moving data from a server to the s3\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eMost services can use s3 as an INPUT or OUTPUT. s3 is a good default for data storage.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"cloudformation-cfn-basics\"\u003eCloudFormation (CFN) basics\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#cloudformation-cfn-basics\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eCloudFormation is Infrastructure as Code (IaC) which allows automation infrastructure creation, update and deletion.\u003c/li\u003e\n\u003cli\u003eCFN uses templates written in either YAML or JSON\u003c/li\u003e\n\u003cli\u003eA template:\n\u003cul\u003e\n\u003cli\u003ehas a list of resources to do the action on (at least one - mandatory)\u003c/li\u003e\n\u003cli\u003edescription - the only restriction with this is if the template has an AWSTemplateFormatVersion, the description must come directly after it (this can be a trick question in the exam)\u003c/li\u003e\n\u003cli\u003emetadata - controls how the UI presents the template\u003c/li\u003e\n\u003cli\u003eparameters - adds fields which need to be added with input (default values could be provided)\u003c/li\u003e\n\u003cli\u003emappings - allows you to create lookup tables\u003c/li\u003e\n\u003cli\u003econditions - decision making in the template\u003c/li\u003e\n\u003cli\u003eoutputs - once the template is finished it can present outputs based on the resource e.g. the instance ID of the ec2\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eCloudFormation takes a template and creates a stack. A stack contains all the logical resources the template tells it to contain. CFN will create a corresponding physical resource in your AWS account.\u003c/li\u003e\n\u003cli\u003eYou can update or delete the logical resources in the template and the template will do this to the physical resources on your account\u003c/li\u003e\n\u003cli\u003eCFN exists to automate infrastructure\u003c/li\u003e\n\u003cli\u003eCFN can be used as part of change management as it can be put in code repositories\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"cloudwatch-cw-basics\"\u003eCloudWatch (CW) Basics\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#cloudwatch-cw-basics\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eCloudWatch is a support service which is used by many other AWS services. It collects and manages operational data detailing how it performs, runs or logging data\u003c/li\u003e\n\u003cli\u003eIt performs 3 main jobs:\u003c/li\u003e\n\u003c/ul\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eMetrics\u003c/strong\u003e - collects metrics from AWS products, Apps, on-premises\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLogs\u003c/strong\u003e - collects logs as above\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eEvents\u003c/strong\u003e - Cloudwatch can generate events to do something\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003eNamespace is a container for monitoring data. It's a way of separating things into different areas e.g. AWS/EC2\u003c/li\u003e\n\u003cli\u003eA metric is a collection of related data points in a time ordered structure e.g. cpu utilization, network I/O or disk I/O\u003c/li\u003e\n\u003cli\u003eData points are measurements of data consisting of a timestamp and value\u003c/li\u003e\n\u003cli\u003eDimensions are used to separate data points within the same metric e.g. instance ID (i-xxxxx) and instance type (t3.small)\u003c/li\u003e\n\u003cli\u003eWe can take action on metrics using alarms\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"shared-responsibility-model\"\u003eShared Responsibility Model\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#shared-responsibility-model\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eShared responsibility in AWS is the principal that some areas you have to manage vs AWS have to manage\u003c/li\u003e\n\u003cli\u003eAt a high level, AWS is responsible for the security of the cloud where as customers are responsible for the security in the cloud\u003c/li\u003e\n\u003cli\u003eAWS responsibilities include managing security of regions, Availability Zones and Edge locations specifically the hardware/global infrastructure.\u003c/li\u003e\n\u003cli\u003eAWS also manage the security around compute, storage, database and networking as well as any software that is used to provide those services\u003c/li\u003e\n\u003cli\u003eCustomers need to take care of client side data encryption, server side encryption and network traffic protection.\u003c/li\u003e\n\u003cli\u003eCustomers need to take care of OS, network and firewall configuration\u003c/li\u003e\n\u003cli\u003eCustomers need to take care of platform, applications, identity and access management as well as customer data.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/KnowledgeGarden/assets/images/srp-model.png\" alt=\"Shared Responsibility Model\"\u003e\u003c/p\u003e\n\u003ch3 id=\"high-availability-vs-fault-tolerance-vs-disaster-recovery\"\u003eHigh-Availability vs Fault-Tolerance vs Disaster Recovery\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#high-availability-vs-fault-tolerance-vs-disaster-recovery\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eHigh Availability (HA) aims to ensure an agreed level of operational performance, usually uptime. for a higher than normal period\u003c/li\u003e\n\u003cli\u003eHA is about maximizing a system's online time\u003c/li\u003e\n\u003cli\u003eSystem availability is usually expressed as a percentage of uptime e.g. 99.9% a year means 8.77 hours p/year downtime\u003c/li\u003e\n\u003cli\u003eFault tolerance (FA) is the property that enables a system to continue operating properly in the event of the failure of one or more of its components\u003c/li\u003e\n\u003cli\u003eHA is just about maximizing uptime where as FA is operating through failure e.g. a airplane can't just be highly available it must be fault tolerant\u003c/li\u003e\n\u003cli\u003eFA is much more complex and more costly to implement as you need to minimize outages but also design a system that will tolerate a failure\u003c/li\u003e\n\u003cli\u003eDisaster recovery (DR) is a set of policies, tools and procedures to enable the recovery or continuation of vital technology infrastructure and systems following a natural or human-induced disaster\u003c/li\u003e\n\u003cli\u003eYou need to plan what should be done in the event of a failure. An example of DR planning is having off-site backup storage\u003c/li\u003e\n\u003cli\u003eDR planning should happen in advance so that the process is automated\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSummary\u003c/strong\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eHA - minimise outages\u003c/li\u003e\n\u003cli\u003eFA - operate through faults\u003c/li\u003e\n\u003cli\u003eDR - used when these don't work\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"route53-r53-fundamentals\"\u003eRoute53 (R53) Fundamentals\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#route53-r53-fundamentals\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eRoute53 provides two main services:\u003c/li\u003e\n\u003c/ul\u003e\n\u003col\u003e\n\u003cli\u003eAllows you to register domains\u003c/li\u003e\n\u003cli\u003eHosts zones on managed nameservers it provides\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003eRoute53 is a global service with a single Database. You don't need to pick a region\u003c/li\u003e\n\u003cli\u003eIt is globally resilient so it can tolerate the fault of multiple regions\u003c/li\u003e\n\u003cli\u003eRoute53 provides DNS zones as well as hosting for those zones\u003c/li\u003e\n\u003cli\u003eZone files are created and hosted on four managed name servers\u003c/li\u003e\n\u003cli\u003eHosted zones can be public or private (VPC)\u003c/li\u003e\n\u003cli\u003eA hosted zone hosts DNS records (recordsets)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"dns-record-types\"\u003eDNS Record Types\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#dns-record-types\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eThere are different records that can be stored in DNS:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eNameserver (NS) - allow delegation to occur end to end in DNS. e.g example.com → ns1.example.com, ns2.example.com\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eA and AAAA Records - A record will point to a v4 IP address and the AAAA will point to the v6 IP address. For example:\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e A Record:\u003c/strong\u003e example.com → 192.168.1.1\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e AAAA Record:\u003c/strong\u003e example.com → 2001:db8::1\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eCNAME - Canonical Name - lets you create the equivalent of DNS shortcuts by pointing to the same A record. E.g. \u003ca href=\"http://www.example.com\"\u003ewww.example.com\u003c/a\u003e → example.com\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eMX Record - how a server can find a mail server for a specific domain. Includes a priority number\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eexample.com\n  Priority: 10 → mail1.example.com\n  Priority: 20 → mail2.example.com\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eTXT - allow you to add arbitrary text to a domain that must be matched to prove domain ownership.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eTTL (Time To Live) is the time set by the DNS to determine how long a DNS record is cached by a resolver (DNS server o browser) before it must check for an updated record from an authoritative server.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"iam-accounts-and-aws-organisations\"\u003eIAM, Accounts and AWS Organisations\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#iam-accounts-and-aws-organisations\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003ch3 id=\"iam-identity-policies\"\u003eIAM Identity Policies\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#iam-identity-policies\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eIAM policies are a type of policy which get attached to identities in AWS\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIdentities are IAM users, groups and roles\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIAM Policies:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eprovides and denies access to features in AWS\u003c/li\u003e\n\u003cli\u003ePolicy documents are created using JSON containing one or more statements\u003c/li\u003e\n\u003cli\u003ethe first part of a statement is a Sid (Statement ID) which is an optional field that lets you identify a statement and what it does. Using these is best practice to inform the reader\u003c/li\u003e\n\u003cli\u003eEvery statement will have a resource you're interacting with and the action you're wanting to perform on that resource\u003c/li\u003e\n\u003cli\u003eThe action is in the format \"service:operation\" where the operation can possibly be a wild card or a list of multiple actions\u003c/li\u003e\n\u003cli\u003eResources is the same only it matches AWS resources. Individual resources are referred to using the ARN\u003c/li\u003e\n\u003cli\u003eEffect is either allow or deny. It is possible to be allowed and denied at the same time\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre class=\"language-json\"\u003e\u003ccode class=\"language-json\"\u003e\u0026#x3C;!-- Policy document example --\u003e\n\u003cspan class=\"token punctuation\"\u003e{\u003c/span\u003e\n  \u003cspan class=\"token property\"\u003e\"Version\"\u003c/span\u003e\u003cspan class=\"token operator\"\u003e:\u003c/span\u003e \u003cspan class=\"token string\"\u003e\"2012-10-17\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n  \u003cspan class=\"token property\"\u003e\"Statement\"\u003c/span\u003e\u003cspan class=\"token operator\"\u003e:\u003c/span\u003e \u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"token punctuation\"\u003e{\u003c/span\u003e\n      \u003cspan class=\"token property\"\u003e\"Sid\"\u003c/span\u003e\u003cspan class=\"token operator\"\u003e:\u003c/span\u003e \u003cspan class=\"token string\"\u003e\"FullAccess\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n      \u003cspan class=\"token property\"\u003e\"Effect\"\u003c/span\u003e\u003cspan class=\"token operator\"\u003e:\u003c/span\u003e \u003cspan class=\"token string\"\u003e\"Allow\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n      \u003cspan class=\"token property\"\u003e\"Action\"\u003c/span\u003e\u003cspan class=\"token operator\"\u003e:\u003c/span\u003e \u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"s3:*\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n      \u003cspan class=\"token property\"\u003e\"Resource\"\u003c/span\u003e\u003cspan class=\"token operator\"\u003e:\u003c/span\u003e \u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"*\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\n    \u003cspan class=\"token punctuation\"\u003e}\u003c/span\u003e\n  \u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\n\u003cspan class=\"token punctuation\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003ewhen there is an overlap in permissions, then both of the statements are processed where the priority begins at explicit denies. Denies overrule everything else. The second priority are explicit allows. Allows take effect unless there are explicit denies. The default if no rules are in place, the default is DENY.\u003c/li\u003e\n\u003cli\u003eWith the exception of the account root user, aws identity start of with NO ACCESS to aws resources.\u003c/li\u003e\n\u003cli\u003eRemember: explicit DENY \u003e explicit ALLOW \u003e DENY\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThere are two types of policies: Inline policies and managed policies\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eInline policies are when you apply individual JSON policy documents to each individual account. This is good for exceptional or special access rights for an individual as opposed to a group or a number of people\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eManaged policies are another JSON policy that you'd attach to identities in a reusable way. These should be used for the normal default rights in a business as they are low overhead\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThere are two types of managed policies: AWS managed policies and customer managed policies which you can create and manage for exact requirements\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"iam-users-and-arns\"\u003eIAM Users and ARNs\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#iam-users-and-arns\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eIAM users are an identity used for anything required long term AWS access e.g. humans, applications or service accounts\u003c/li\u003e\n\u003cli\u003eA principal (a person/application) makes a request to IAM to authenticate to a resource\u003c/li\u003e\n\u003cli\u003eAuthentication for IAM users is done using either username and password or access keys. Access keys are usually used by applications or by humans using CLI tools.\u003c/li\u003e\n\u003cli\u003eOnce a principal goes through the access tools, they become an authenticated identity\u003c/li\u003e\n\u003cli\u003eOnce a principal is identified AWS knows which policies apply to an identity. This is the process of authorization.\u003c/li\u003e\n\u003cli\u003eAuthentication is how a principal can prove to IAM it's who they say they are where as Authorization checks the policies attached to the identity to give them permission for a resource\u003c/li\u003e\n\u003cli\u003eARN (Amazon Resource Name) uniquely identify resources within any AWS accounts.\u003c/li\u003e\n\u003cli\u003eARN is used to allow you to refer to a single or group of resources using wild cards\u003c/li\u003e\n\u003cli\u003eARNs are used in IAM policies\u003c/li\u003e\n\u003cli\u003eThe format is:\n\u003ccode\u003earn:partition:service:region:account-id:resource-id\u003c/code\u003e\n\u003ccode\u003earn:partition:service:region:account-id:resource-type/resource-id\u003c/code\u003e\n\u003ccode\u003earn:partition:service:region:account-id:resource-type:resource-id\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eYou can only have 5000 IAM users per account\u003c/li\u003e\n\u003cli\u003eAn IAM User can be a member of 10 groups\u003c/li\u003e\n\u003cli\u003eIf you have more than 5000 identifiable users then IAM users is not the right identity to use for that solution. You can fix this with IAM roles or Identity Federation.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"iam-groups\"\u003eIAM Groups\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#iam-groups\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eIAM groups are containers for IAM users\u003c/li\u003e\n\u003cli\u003eYou can't log into IAM groups nor do they have credentials of their own\u003c/li\u003e\n\u003cli\u003eThey are used solely to manage and organise IAM users\u003c/li\u003e\n\u003cli\u003ean IAM user can be part of multiple IAM groups\u003c/li\u003e\n\u003cli\u003eGroups can have policies attached to them, both inline and managed\u003c/li\u003e\n\u003cli\u003eYou can also have individual inline/managed policies at the user level\u003c/li\u003e\n\u003cli\u003eYou should collect all the policies that apply to a user from their groups and individual policies and apply the same deny-allow-deny rule to work out what their permissions are\u003c/li\u003e\n\u003cli\u003eThere is no limit for the amount of users in an IAM group but the IAM user limit of 5000 exists for the whole account\u003c/li\u003e\n\u003cli\u003eThere is no such 'all users' group in IAM built in. You can create this and manage it manually\u003c/li\u003e\n\u003cli\u003eYou cannot have any nesting in groups\u003c/li\u003e\n\u003cli\u003eThere is a limit of 300 groups per account but it can be increased with a support ticket\u003c/li\u003e\n\u003cli\u003ePolicies can be attached to resources as well for example a bucket can have a policy attached to it where it allows and denies identities access to that bucket.\u003c/li\u003e\n\u003cli\u003eA resource can be refer to a user or role to give permission to itself but it cannot give it to a group. This is because a group is not a true identity and they can't be referenced as a principal in a policy\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"iam-roles\"\u003eIAM Roles\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#iam-roles\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eA role is a type of identity that exists inside an IAM account\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIAM user is when a single principal wants to use AWS\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIAM roles are best suited to be used by multiple principals e.g. multiple users in the aws account or users, apps or services inside or outside of the aws account.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIf you can't identify the number of principals that use an identity or if you have more than 5000 principals you could consider using an IAM role\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eUsually roles are used on a temporary basis to borrow permissions\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIAM roles have two types of policies that can be attached:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eTrust policy - which identities can assume that role. This can be entities in AWS accounts, other accounts, anonymous users and SSO providers e.g. facebook, google etc\u003c/li\u003e\n\u003cli\u003ePermissions policy - temporary credentials are given to identities assuming the role and these credentials are used to check the permissions\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003etemporary credentials are generated to roles using STS (Secure Token Service).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"when-to-use-iam-roles\"\u003eWhen to use IAM Roles\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#when-to-use-iam-roles\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eOne of the most common uses of IAM roles is AWS services as they need permission and access rights to perform certain actions\u003c/li\u003e\n\u003cli\u003eAn example is AWS Lambda - it may start/stop ec2 instances, perform backups or other tasks that need permission\u003c/li\u003e\n\u003cli\u003eInstead of hardcoding the access keys into the Lambda, the IAM role 'Lambda execution role' can grant access to aws product/services. It will use the sts:AssumeRole operation to generate temporary credentials to use AWS services.\u003c/li\u003e\n\u003cli\u003eThis is a better approach than using access keys as it's more secure and it won't need key rotation\u003c/li\u003e\n\u003cli\u003eRoles are also useful for emergency or unusual situations. A person can assume an emergency role when absolutely required for a short time.\u003c/li\u003e\n\u003cli\u003eRoles are useful for an existing corporate environment. If a corporate has over 5000 staff you cant assign each of them an IAM user.\u003c/li\u003e\n\u003cli\u003eYou could allow an IAM role inside your AWS account to be used by an external identity e.g. active directory\u003c/li\u003e\n\u003cli\u003eIf you create an app with over 5000 users that needs AWS access, you can use web identity federation which uses IAM roles. Web identities can be providers such as google, facebook or twitter/X\u003c/li\u003e\n\u003cli\u003eThe pro of using web identities is that no AWS credentials are stored on the app and it uses existing accounts that customers have. This can scale to 100 million+ users\u003c/li\u003e\n\u003cli\u003eIf you want to use resources across aws accounts, aws roles can also be used.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"service-linked-roles-and-passrole\"\u003eService-linked Roles and PassRole\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#service-linked-roles-and-passrole\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eService-linked roles are a special time of IAM role linked to a specific AWS service\u003c/li\u003e\n\u003cli\u003etheir permissions are pre-defined by an AWS service\u003c/li\u003e\n\u003cli\u003eThe main difference between a regular IAM role and a service-linked role is that you cannot delete a service-linked role until it's no longer required\u003c/li\u003e\n\u003cli\u003eThey are either created by a service or by you during set up\u003c/li\u003e\n\u003cli\u003ePassrole permissions give the users the ability to use a service linked role without being able to create or edit the role. This is similar to using a pre-created role in a cloud formation stack.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"aws-organisations\"\u003eAWS Organisations\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#aws-organisations\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eAWS organisations take a single AWS account (standard account) to create an organisation. This account becomes the management account (previously called Master account).\u003c/li\u003e\n\u003cli\u003eThe management account invites existing standard AWS accounts into the organisation. Once they join they change from being standard to member accounts.\u003c/li\u003e\n\u003cli\u003eAn AWS organisation has only ONE management account and zero or more member accounts\u003c/li\u003e\n\u003cli\u003eAn organisational root is not the same as an AWS account root user. The root of an AWS organisation is just a container for aws accounts and organisational units. It's the top level of the hierarchical structure of an organisation.\u003c/li\u003e\n\u003cli\u003eConsolidating billing for organisations changes the billing methods for member accounts by removing them and passing them through to the management account. In the context of consolidated billing this is known as the Payer Account.\u003c/li\u003e\n\u003cli\u003eMaster, management and payment account refer to the same thing - the account that was used to create the organisation.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"service-control-policies\"\u003eService Control Policies\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#service-control-policies\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eSCPs are a feature of AWS organisations which allow restrictions to be placed on member accounts in the form of boundaries\u003c/li\u003e\n\u003cli\u003eSCPs are policy documents or JSON that can be attached to the organisation as a whole or organisational units or individual AWS accounts\u003c/li\u003e\n\u003cli\u003eThey inherit down the organisation tree so that nested units will be affected by it and everything below it will be affected too\u003c/li\u003e\n\u003cli\u003eManagement accounts are special as they cannot be restricted and not affected by service control policies.\u003c/li\u003e\n\u003cli\u003eThey can limit what a root user can do though\u003c/li\u003e\n\u003cli\u003eSCP do not grant permissions. They just control what an account can and cannot grant via identity policies\u003c/li\u003e\n\u003cli\u003eBy default, SCP applies FullAWsAccess which means no restrictions\u003c/li\u003e\n\u003cli\u003eSCP also has implicit deny if there is an absence of an allow\u003c/li\u003e\n\u003cli\u003eOnly permissions allowed within the intersection of Identity policies and SCPs are allowed\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/KnowledgeGarden/assets/images/SCP-policies-venn.png\" alt=\"SCP and Identity Policies Venn\"\u003e\u003c/p\u003e\n\u003ch3 id=\"cloudwatch-logs\"\u003eCloudWatch Logs\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#cloudwatch-logs\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA public service that allows you to store, monitor and access logging data\u003c/li\u003e\n\u003cli\u003eHas built in AWS integration with services eg EC2, VPC, Lambda, CloudTrail, R53\u003c/li\u003e\n\u003cli\u003eCan generate metrics based on logs (metric filter)\u003c/li\u003e\n\u003cli\u003eLog events are stored in log streams. Log streams are from one specific source e.g. one ec2 instance\u003c/li\u003e\n\u003cli\u003eLog groups are containers for multiple log streams for the same type of logging\u003c/li\u003e\n\u003cli\u003eLog groups are where we define retention and permission policies and metric filters\u003c/li\u003e\n\u003cli\u003eMetrics can have associated alarms\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"cloudtrail-essentials\"\u003eCloudTrail Essentials\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#cloudtrail-essentials\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA product which logs API calls and account events/activities e.g. creating, deleting s3 bucket, stopping a service etc\u003c/li\u003e\n\u003cli\u003eA cloudtrail event is a call/activity on an aws account\u003c/li\u003e\n\u003cli\u003eStores 90 days of event history - enabled by default for no cost. You don't get any s3 storage unless you configure a trail.\u003c/li\u003e\n\u003cli\u003eTo customise this you must create 1 or more Trails\u003c/li\u003e\n\u003cli\u003eManagement Events and Data Events are the type of trails\u003c/li\u003e\n\u003cli\u003eManagement Events are control plane operations\u003c/li\u003e\n\u003cli\u003eData events are resource operations e.g. uploading objects, lambda functions being invoked\u003c/li\u003e\n\u003cli\u003eBy default, cloud trail only logs Management events\u003c/li\u003e\n\u003cli\u003eA trail logs events for an AWS region it's created in\u003c/li\u003e\n\u003cli\u003eCloud trail is a regional service\u003c/li\u003e\n\u003cli\u003eA trail can be set to all regions or one region\u003c/li\u003e\n\u003cli\u003eBy default, regional trails will log to the region they're in but global services will log to \u003cstrong\u003eus-east-1\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eIf you create a trail, it is stored in an s3 bucket as compressed JSON log files\u003c/li\u003e\n\u003cli\u003eCloudTrail could also be integrated into Cloudwatch logs\u003c/li\u003e\n\u003cli\u003eYou can create an organisational trail which is a single management point for every event across the whole organisation\u003c/li\u003e\n\u003cli\u003eCloudTrail is NOT real time. There can be a 15+ minute delay\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"aws-control-tower\"\u003eAWS Control Tower\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#aws-control-tower\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eAWS Control Tower gives an easy and quick way to set up a multi-account environment\u003c/li\u003e\n\u003cli\u003eControl Tower orchestrates other services to provide this functionality e.g. Organizations, IAM identity center, cloudformation, config\u003c/li\u003e\n\u003cli\u003eIt's another evolution of AWS Organisation with more capability\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThere are a few different parts of control tower:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eLanding zone - multi-account environment\u003c/li\u003e\n\u003cli\u003eGuard Rails - detect/mandates rules and standards across all accounts\u003c/li\u003e\n\u003cli\u003eAccount Factory - automates and standardises new account creation\u003c/li\u003e\n\u003cli\u003eDashboard - single page oversight of the entire environment\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eLanding Zone\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eHome region - the region you deploy the region\u003c/li\u003e\n\u003cli\u003ebrings features of multiple AWS products together e.g. Organizations, AWS Config, Cloudformation\u003c/li\u003e\n\u003cli\u003eSecurity OU - organisational unit that has log archive and audit accounts\u003c/li\u003e\n\u003cli\u003eSandbox OU - which is for testing and less rigid security\u003c/li\u003e\n\u003cli\u003eYou can create other OU's and Accounts\u003c/li\u003e\n\u003cli\u003eUtilises the IAM Identity Center (AWS SSO) - SSO, multi account, ID Federation\u003c/li\u003e\n\u003cli\u003eMonitoring and Notifications - cloudwatch and SNS\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eGuard Rails\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCome in either Mandatory, Strongly Recommended or Elective\u003c/li\u003e\n\u003cli\u003eFunction in two ways\u003c/li\u003e\n\u003c/ul\u003e\n\u003col\u003e\n\u003cli\u003epreventative - stop you from doing things - either enforced or not enabled\u003c/li\u003e\n\u003cli\u003edetective - compliance check for identifying issues - either clear, in violation or not enabled\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003eAccount Factory\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAutomate account provisioning\u003c/li\u003e\n\u003cli\u003eCan be done with cloud admins or end users with appropriate permissions\u003c/li\u003e\n\u003cli\u003eThis provisioning comes with Guardrails which are automatically added\u003c/li\u003e\n\u003cli\u003eAccount admin given to a named user to allow people in the organisation to provision accounts\u003c/li\u003e\n\u003cli\u003eAccounts are set up with standard configuration\u003c/li\u003e\n\u003cli\u003eAccounts can be closed or repurposed\u003c/li\u003e\n\u003cli\u003eCan be fully integrated with a business SDLC\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"simple-storage-service\"\u003eSimple Storage Service\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#simple-storage-service\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003ch3 id=\"s3-security-resource-policies-and-acls\"\u003eS3 Security (Resource Policies and ACLs)\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#s3-security-resource-policies-and-acls\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eS3 is private by default\u003c/li\u003e\n\u003cli\u003eThe only identity which has any access to s3 by default is the account root user\u003c/li\u003e\n\u003cli\u003eYou can grant permission to s3 via S3 \u003cstrong\u003eBucket Policies\u003c/strong\u003e which are:\n\u003cul\u003e\n\u003cli\u003eA form of resource policies\u003c/li\u003e\n\u003cli\u003elike identity policies but attached to a bucket\u003c/li\u003e\n\u003cli\u003eFrom the perspective of the resource - you control who can access that resource\u003c/li\u003e\n\u003cli\u003eIdentity policies are limited by only being able to give control to the current account, so you cannot give another account access to an s3 bucket. Resource policies allows this for the current or different accounts.\u003c/li\u003e\n\u003cli\u003eResource policies can ALLOW/DENY anonymous principals. This can't be done with identity policies since they need to be attached to a valid identity in AWS. Therefore the resource policies can be given to external access.\u003c/li\u003e\n\u003cli\u003eResource policies have a 'principal' component which specifies which principals this policy applies to\u003c/li\u003e\n\u003cli\u003eAn identity policy doesn't have a principal because the policy always applies to the account that created it. A good way to identify identity vs resource policy is checking the absence of principal\u003c/li\u003e\n\u003cli\u003eIdentity policy as well as the bucket policy applies to both internal and cross account access. For anonymous only the bucket policy applies.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAccess Control Lists (ACLs):\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAnother form of s3 security used less frequently these days. They aren't recommended any more by AWS\u003c/li\u003e\n\u003cli\u003eA sub-resource of an object or bucket.\u003c/li\u003e\n\u003cli\u003eYou cannot use ACLs on a group of objects\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBlock Public Access:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAnother layer of permission to block all public access as a fail safe\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eChoosing between resource or identity policies depends on the business' requirements and personal preference but sometimes choosing one over the other makes sense in specific situations:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIf you're granting/denying permissions on lots of different resources across an aws account, then you will need to use identity as not all services support resource policies.\u003c/li\u003e\n\u003cli\u003eIf you prefer to manage resources from one place then identity makes sense because this is done in IAM\u003c/li\u003e\n\u003cli\u003eIf you're managing a specific product then resource makes sense\u003c/li\u003e\n\u003cli\u003eCross account or anonymous resources should use resource policies\u003c/li\u003e\n\u003cli\u003eDo not use ACLs unless you MUST\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"s3-static-hosting\"\u003eS3 Static Hosting\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#s3-static-hosting\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eWithout static hosting, you access S3 Via AWS APIs\u003c/li\u003e\n\u003cli\u003eWith static hosting, you can access those resources via HTTP e.g. websites, blogs etc\u003c/li\u003e\n\u003cli\u003eYou must set an Index and Error document for s3 hosting. We point the index document to a specific html file object in the bucket as well as Error\u003c/li\u003e\n\u003cli\u003eA website endpoint is created for hosting\u003c/li\u003e\n\u003cli\u003eYou can use a custom domain via R53 but the bucket name MUST match the domain name\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThere are two scenarios that are perfect for s3\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eOffloading - moving large data from a compute service to s3 is cheaper\u003c/li\u003e\n\u003cli\u003eOut-of-band pages - if a server is offline for maintenance or has performance bugs we can point users to a static page on s3 that contains something like a status message\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003ePricing:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePer GB per month charge\u003c/li\u003e\n\u003cli\u003eTransfer fee - in is free, out is per gig charge\u003c/li\u003e\n\u003cli\u003eRequest and data retrieval - every operation e.g. GET, POST incurs a cost\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"object-versioning-and-mfa-delete\"\u003eObject Versioning and MFA Delete\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#object-versioning-and-mfa-delete\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eDisabled by default. \u003cstrong\u003eOnce enabled you cannot disable it\u003c/strong\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eYou can suspend it and a suspended bucket can be re-enabled\n\u003cimg src=\"/KnowledgeGarden/assets/images/s3-versioning-state.png\" alt=\"S3 versioning state\"\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eVersioning let's you store multiple version of objects within a bucket where as without it, there is a unique object name and the object gets replaced each time.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ethe 'id' is null if versioning is disabled, if it is enabled then s3 will allocate an id\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003enewer versions will have a new ID\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe newest version is known as Latest or current version\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIf you don't specify to s3 a specific version, you always get the latest. You can access individual versions by specifying the ID\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIf we delete an object, the object is not deleted, it's just hidden and marked with a delete marker. This is when we don't specify an ID/version\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eif we specify a version ID then an object is actually deleted\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eImportant: \u003cstrong\u003eversioning CANNOT be switched off - only suspended*\u003c/strong\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eSpace is consumed by ALL versions and you are billed for ALL versions\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eOnly way to remove all costs is to delete the bucket. Suspending does not remove the old versions\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eMFA Delete - enabled in versioning configuration which means you need an MFA token to change bucket versioning state or delete version\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eYou would need to pass in MFA and the code passed with API calls to do these actions\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"s3-performance-optimization\"\u003eS3 Performance Optimization\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#s3-performance-optimization\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eDefault upload in s3 is using single data stream to s3. The issue with this is if the stream fails the entire upload fails and you need a full restart\u003c/li\u003e\n\u003cli\u003eA single PUT upload in AWS is limited to 5GB as a maximum\u003c/li\u003e\n\u003cli\u003eA solution to a single stream is using a \u003cstrong\u003emulti-part upload\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eThis breaks the original blob into individual parts\u003c/li\u003e\n\u003cli\u003eThe \u003cstrong\u003eminimum\u003c/strong\u003e data size to use multi part upload is 100MB. It's recommended to use it for anything over 100mb.\u003c/li\u003e\n\u003cli\u003eAn upload can be split into a maximum of 10,000 parts with each part between 5mb -\u003e 5gb\u003c/li\u003e\n\u003cli\u003eEach individual part is treated as it's own isolated upload and can be restarted in isolation\u003c/li\u003e\n\u003cli\u003eIt also improves transfer rates by uploading in parallel\u003c/li\u003e\n\u003cli\u003eS3 Accelerated transfer\n\u003cul\u003e\n\u003cli\u003eusing the public internet is not the most ideal way to get data from source to destination as the route chosen by ISPs is not always optimal. S3 transfer acceleration uses the network of AWS Edge locations located in convenient areas. This feature needs to be switched on.\u003c/li\u003e\n\u003cli\u003eEdge locations then use AWS Network as an 'express train' to get to the destination\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"key-management-system\"\u003eKey Management System\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#key-management-system\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eA regional and Public service\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eLet's you create, store and manage keys\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHandles both Symmetric and Asymmetric keys\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eCapable of performing cryptographic operations (encrypt, decrypt)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eKeys never leave KMS\u003c/strong\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eUses a FIPS 140-2 (L2) - the L2 matters for the exam\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eKMS Keys are the keys that KMS manages\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThese are logical containers which contain ID, date, policy, desc and state.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eKMS keys are backed by physical key material\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe material is generated or imported and can be used for up to 4kb of data\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eKMS Keys do not leave the KMS product and the unencrypted form is never stored on disk\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eData Encryption Keys (DEKs) are another type of key in KMS\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eDEK uses GenerateDataKey which can be used to encrypt and decrypt data more than 4kb in size\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eKMS does NOT store DEK, it provides it to you and discards it.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eKMS will provide you with the plaintext and ciphertext version of this key\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eKMS does not do the encryption or decryption using DEK - you do or the service using KMS does\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eServices such as s3 use DEK for every object\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eKMS keys are isolated to a region and never leave\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eKMS keys CAN be multi region\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eTHey can be AWS owned or customer owned\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eTHere are two types of customer owned keys:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eAWS managed - created automatically by services\u003c/li\u003e\n\u003cli\u003eCustomer managed - created by customers and are more configurable\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eBoth of these keys support rotation - with AWS managed keys this cannot be disabled but with customer it is optional\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eA KMS key contains a backing key which means previous backing keys can be used\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eCan use alias\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eEvery KMS Key has a key policy (resource). For customer managed keys you can change it\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eKMS has to be explicitly be told which AWS account to manage it\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eUsually you use a combination of Key policies and IAM policies to manage KMS\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"s3-object-encryption-csesse\"\u003eS3 Object Encryption CSE/SSE\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#s3-object-encryption-csesse\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eBuckets aren't encrypted - objects are\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eData can be stored in disk in two different ways:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eClient side encryption - objects are being encrypted by the client before they ever leave. AWS receives it in a scrambled form and stores it in a scrambled form\u003c/li\u003e\n\u003cli\u003eServer side encryption - in transit, the data is in it's original form, once it's hitting s3 it's encrypted by the s3 servers\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg src=\"/KnowledgeGarden/assets/images/s3-encryption.png\" alt=\"S3 Encryption\"\u003e\u003c/p\u003e\n\u003cp\u003eThere are 3 types of encryption for server side encryption:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eSSE-C - Server side encryption with customer provided keys\u003c/li\u003e\n\u003cli\u003eSSE-S3 - with amazon s3 managed keys (this is the default)\u003c/li\u003e\n\u003cli\u003eSSE-KMS - with KMS Keys stored in AWS Key management service\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eSSE-C:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCustomer is responsible for the keys and S3 manages the s3 encryption/decryption processes. When you put an object into s3 you put it through as plaintext alongside the encryption key. When it goes through https it will be encrypted to an external observer. The key is destroyed at s3.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSSE-S3:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAWS handles both the encryption and the keys. You provide the plaintext data, the s3 encrypts it via a generated key for the object. You don't get to choose the key or customise it.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSSE-KMS:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eYou use KMS to create a key. Client sends data via plaintext and it's encrypted by S3 via the KMS key. That key is used by s3 to generate an encryption Key. Using this method, key managers can decide who can see the unencrypted data\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSummary of encryption types\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/KnowledgeGarden/assets/images/s3-encryption-summary.png\" alt=\"summary\"\u003e\u003c/p\u003e\n\u003ch3 id=\"s3-bucket-keys\"\u003eS3 Bucket Keys\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#s3-bucket-keys\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA way to help s3 scale with server side encryption\u003c/li\u003e\n\u003cli\u003eusing SSE-KMS, AWS KMS is called every single time a call is made to s3 to generate a DEK\u003c/li\u003e\n\u003cli\u003eThis starts to cost a lot upon scaling\u003c/li\u003e\n\u003cli\u003eInstead of generating a new DEK from KMS every time, \u003cstrong\u003ebucket keys\u003c/strong\u003e will ask KMS to generate a time limited bucket key used to generate DEKs within s3\u003c/li\u003e\n\u003cli\u003eThis significantly reduces KMS API calls, reduces cost and increases scalability\u003c/li\u003e\n\u003cli\u003eUsing bucket keys means cloudtrail kms events now show the bucket not te object\u003c/li\u003e\n\u003cli\u003eBucket key works with replication, object encryption is maintained\u003c/li\u003e\n\u003cli\u003eIf you replicate a plain text bucket to a bucket that is encrypted, it will get encrypted at the destination side\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"s3-object-storage-classes\"\u003eS3 Object Storage Classes\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#s3-object-storage-classes\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eS3 standard\u003c/strong\u003e is the default storage class. This replicates objects across at least 3 availability zones (AZs) in the AWS region\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eif s3 object is stored, a HTTP 1.1 200 OK response is provided by the s3 API endpoint\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eYou're billed a GB/m fee for data stored, a $ per GB charge for transfer OUT (in is free) and a price per 1,000 requests. No specific retrieval fee, no minimum duration, no minimum size\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eS3 standards can be made publicly available\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eS3 standard should be used for frequently accessed data which is important and non-replaceable. This should be used as the default and only investigate moving other classes if you need a specific use case.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eS3 Standard-IA (infrequent Access)\u003c/strong\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe same as S3 standard in most ways however has a lower GB storage price and a retrieval fee that increases with frequent data access\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ethere is a minimum duration charge for using it (30 days)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHas a min capacity charge of 128kb per object\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eS3 Standard-ia should be used for long-lived data which is important but where access is infrequent\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eS3 One Zone-IA (infrequent Access)\u003c/strong\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eShares many of the considerations of standard-IA\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe big difference is that the data is stored in one AZ in the region\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eShould be used for long-lived data which is non-critical and replaceable and where access is infrequent\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eExamples could be intermediate data you can afford to use or for replica copies\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eS3 Glacier - Instant\u003c/strong\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eLike s3 standard IA except it has cheaper storage, more expensive retrieval costs, and longer minimums\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003emore for when you want to access something once a quarter as opposed to once a month\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eS3 Glacier - Flexible\u003c/strong\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eA cheaper storage solution\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eStored as if 'cold' and therefore cannot be made publicly accessible. Retrieving requires a retrieval process\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eRetrieved to s3 standard-IA temporarily\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThere are 3 different retrieval methods:\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003col\u003e\n\u003cli\u003eexpedited - 1-5 minutes\u003c/li\u003e\n\u003cli\u003estandard - 3-5 hours\u003c/li\u003e\n\u003cli\u003ebulk - 5-12 hours\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003ethe faster the retrieval the more expensive\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003esituations for when you need to store archival data where frequent or realtime access isn't needed (e.g. yearly) and the access takes time.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eS3 Glacier - Deep Archive\u003c/strong\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIf you consider Flexible to be a 'chilled' state, then data in Deep Archive is in a 'frozen' state\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e180 day minimum duration\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe retrieval methods are:\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003col\u003e\n\u003cli\u003estandard (12 hours)\u003c/li\u003e\n\u003cli\u003ebulk (up to 48 hours)\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003ebest for data that rarely if ever needs to be accessed e.g. legal or regulation data storage\u003c/li\u003e\n\u003cli\u003eit's a cheaper storage\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eIntelligent Tiering\u003c/strong\u003e\nMonitors and automatically moves any objects not accessed for 30 days to a low cost infrequent access tier and eventually to archive instant access, archive access or deep archive tiers. If objects start to become more popular and frequently accessed, they will be moved back up the tiers to frequent access at no charge\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDesigned for long lived data with changing or unknown patterns\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"s3-lifecycle-configuration\"\u003eS3 Lifecycle Configuration\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#s3-lifecycle-configuration\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eYou can create life cycle rules on objects in an s3 bucket\u003c/li\u003e\n\u003cli\u003eA set of rules that consist of actions based on a criteria\u003c/li\u003e\n\u003cli\u003eCan be applied on a bucket or group of objects\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003etwo types of actions can be applied\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eTransition actions - change the storage class of the object(s) e.g. from s3 standard to s3 IA after 30 days\n\u003cul\u003e\n\u003cli\u003eall the transitions transition 'downward' in a waterfall fashion, not upward\u003c/li\u003e\n\u003cli\u003ethe only exception of a transition not available downward is one zone-IA into S3 Glacier Instant Retrieval\u003c/li\u003e\n\u003cli\u003eif you transition objects you need to be aware of the minimum days before transition for example s3 standard to standard IA or one zone IA it would need to have been in s3 standard for at least 30 days\u003c/li\u003e\n\u003cli\u003esmaller objects can cost more upon transitioning due to minimum sizes\u003c/li\u003e\n\u003cli\u003emoving from s3 to IA also requires an additional 30 days before you can move them again to glacier classes\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eExpiration actions - delete object(s) or versions\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eYou can't apply these rules based on 'access frequency' in the same way intelligent tiering does\u003c/p\u003e\n\u003ch3 id=\"s3-replication\"\u003eS3 Replication\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#s3-replication\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eS3 has two replication features which allow objects to be replicated between source and destination buckets in the same or different AWS accounts:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eCross region replication (CRR) - allows the replication of objects from a source bucket to one or more destination buckets in different AWS regions\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eSame region replication (SSR) - as above but same region\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eThe architecture replication is applied to the source bucket. It specifies:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ethe destination bucket\u003c/li\u003e\n\u003cli\u003ean IAM role to use for the replication process - s3 assumes that role\u003c/li\u003e\n\u003cli\u003eFor replication across AWS accounts, the role isn't by default trusted by the destination account, therefore there needs to be a bucket policy in the destination account to allow the role to replicate into it\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eReplication Options:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eWhat to replicate - all objects or subset\u003c/li\u003e\n\u003cli\u003ewhich storage class the destination bucket will use - the default is the destination uses the same class as the source\u003c/li\u003e\n\u003cli\u003eyou can define the ownership of the objects in the destination. Across accounts, the bucket objects will by default be owned by the source bucket account\u003c/li\u003e\n\u003cli\u003eReplication time control (RTC) - adds a guaranteed 15 minute SLA on to the replication process.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eReplication consideration:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eBy default, it's not retroactive - only from the point you enable replication will objects in the bucket be replicated. Objects prior to that time will not.\u003c/li\u003e\n\u003cli\u003eVersioning MUST be enabled for replication\u003c/li\u003e\n\u003cli\u003ebatch replication can be turned on to replicate existing objects\u003c/li\u003e\n\u003cli\u003eobjects are replicated only one way i.e. source to destination - there is a bi-directional setting that can be configured\u003c/li\u003e\n\u003cli\u003ereplication can be unencrypted, SSE-S3, SSE-KMS (with extra config) and SSE-C\u003c/li\u003e\n\u003cli\u003eSource bucket owner needs permission to the object they replicate\u003c/li\u003e\n\u003cli\u003eIt will not replicate system events that are made by life cycle management. Neither can it replicate glacier or glacier deep archive objects\u003c/li\u003e\n\u003cli\u003eDelete markers are not replicated - but can be enabled\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWhy use replication?\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSSR (Same region replication) - Log aggregation - sync logs into a single s3 bucket\u003c/li\u003e\n\u003cli\u003eSSR - Prod and test sync\u003c/li\u003e\n\u003cli\u003eSSR - resilience with strict sovereignty\u003c/li\u003e\n\u003cli\u003eCRR (Cross region replication) - global resilience improvements\u003c/li\u003e\n\u003cli\u003eCRR - Latency reduction by replicating data to buckets closer to source\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"s3-presigned-urls\"\u003eS3 PreSigned URLs\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#s3-presigned-urls\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003ePresigned URLS in s3 are a way to generate a URL with access permissions in a safe way.\u003c/li\u003e\n\u003cli\u003eIf a bucket is not public, only an authenticated aws user can access it\u003c/li\u003e\n\u003cli\u003eAWS offers pre-signed urls for the case where we don't want to give someone short term access to the bucket without making it public or creating an aws identity for them\u003c/li\u003e\n\u003cli\u003eThis can be used for both PUT and GET operations\u003c/li\u003e\n\u003cli\u003ePre-signed urls allow someone to access a certain object in a private bucket with the same access rights as the user who generated the url for a certain period of time\u003c/li\u003e\n\u003cli\u003eYou can create a pre-signed url for an object you don't have access to where the url will also not provide access to the object\u003c/li\u003e\n\u003cli\u003ethe url has the same permissions of the identity as of the time the url was made\u003c/li\u003e\n\u003cli\u003eDon't generate pre-signed urls with a role - URLs will stop working when temporary credentials expire - because assuming an IAM role gives you temporary credentials and the pre-signed url may expire far later than the credentials. It's best to use long term identities i.e. an IAM user\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"s3-select-and-glacier-select\"\u003eS3 Select and Glacier Select\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#s3-select-and-glacier-select\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eWays you can retrieve parts of objects rather than all of an object\u003c/li\u003e\n\u003cli\u003eS3 can store objects up to 5TB in size\u003c/li\u003e\n\u003cli\u003eRetrieving a whole object will take time\u003c/li\u003e\n\u003cli\u003eS3/Glacier select lets you use SQL like statements to select part of an object\u003c/li\u003e\n\u003cli\u003eWorks on many file types such as CSV, JSON, Parquet, BZIP2 compression for CSV and JSON\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"s3-events\"\u003eS3 Events\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#s3-events\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eAllows you to create event notifications on a bucket\u003c/li\u003e\n\u003cli\u003eWhen enabled, a notification is delivered when something happens on a bucket. It can be delivered to SNS, SQS and lambda functions\u003c/li\u003e\n\u003cli\u003eCan be generated when objects are created (PUT, POST, COPY and Multi part upload)\u003c/li\u003e\n\u003cli\u003eCan be generated on Delete (as well as delete markers)\u003c/li\u003e\n\u003cli\u003eFor object restores (start and end)\u003c/li\u003e\n\u003cli\u003eReplication events\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"s3-access-logs\"\u003eS3 Access Logs\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#s3-access-logs\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eAccess logging provides detailed records for the requests that are made to a bucket. They are best effort - they are usually logged in target bucket within a few hours\u003c/li\u003e\n\u003cli\u003eLet you help the access patterns of your customer base\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"s3-object-lock\"\u003eS3 Object Lock\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#s3-object-lock\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eEnable on new S3 buckets only otherwise you will need to contact AWS for an existing\u003c/li\u003e\n\u003cli\u003eYou cannot disable object lock or versioning\u003c/li\u003e\n\u003cli\u003eWrite Once Read Many (WORM) - No delete, no overwrite\u003c/li\u003e\n\u003cli\u003eRequires versioning to be enabled and individual versions are locked\u003c/li\u003e\n\u003cli\u003eAn object version can have one, both or none of \u003cstrong\u003eretention period\u003c/strong\u003e or \u003cstrong\u003elegal hold\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eRetention Locking:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSpecified in days and years\u003c/li\u003e\n\u003cli\u003eThe two types you can do:\n\u003col\u003e\n\u003cli\u003eCompliance mode - an object version can't be adjusted, deleted or overwritten for that period. The retention period and mode cannot be changed even by the account root user. This is the most strict form of object lock. This could be good for compliance reasons e.g. medical or legal\u003c/li\u003e\n\u003cli\u003eGovernance - can grant special permissions to allow locking settings to be adjusted (s3:ByPassGovernanceRetention). Useful if you want to prevent accidental deletions\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLegal Hold Locking:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSet on object version either on or off, no retention period\u003c/li\u003e\n\u003cli\u003eYou can't delete or change until removed\u003c/li\u003e\n\u003cli\u003eYou need permission to add or remove the legal hold\u003c/li\u003e\n\u003cli\u003eGood to prevent accidental deletion of critical object versions\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"s3-access-points\"\u003eS3 Access Points\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#s3-access-points\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA feature of S3 which improves the manageability of s3 buckets\u003c/li\u003e\n\u003cli\u003eRather than having 1 bucket with 1 bucket policy you can conceptually split it into many access points with different policies\u003c/li\u003e\n\u003cli\u003eEach access point can be limited in terms of where they can be accessed from with it's own endpoint address\u003c/li\u003e\n\u003cli\u003eCan be created via the console of via the cli: \u003ccode\u003eaws s3control create-access-point --name secretcats --account-id 12355423 --bucket catpics\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eYou can think of access points as mini buckets or views. The DNS of each AP is given to a section of users and those mini buckets are individually controlled\u003c/li\u003e\n\u003cli\u003eAny definitions defined in the access point policy need to be defined in the bucket policy e.g. giving permission to certain users for the access point\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"virtual-private-cloud-vpc-basics\"\u003eVirtual Private Cloud (VPC) Basics\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#virtual-private-cloud-vpc-basics\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003ch3 id=\"vpc-sizing-and-structure\"\u003eVPC Sizing and Structure\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#vpc-sizing-and-structure\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eA private network inside AWS\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eYou need to decide what IP range to use in advance - it's not easy to change later. There are a few things you should keep in mind:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eWhat size should the VPC be? This influences how many services can fit into the VPC\u003c/li\u003e\n\u003cli\u003eAre there any networks we can't use? Duplicate or overlapping ranges complicate things\u003c/li\u003e\n\u003cli\u003eBe mindful of other VPC ranges, other cloud envs, on premises, partners and vendors and their IP ranges\u003c/li\u003e\n\u003cli\u003eTry to plan for the future\u003c/li\u003e\n\u003cli\u003eConsider the VPC structure - tiers and resiliency\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eA VPC can be at the smallest a /28 network (16 IP) and at most /16 (65536 IPs)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eAvoid common ranges\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eRanges can be determined by the number of regions a business operates in. A suggestion is to reserve 2+ networks per region being used per account\ne.g. 3 US, Europe, Australia - 5 regions x 2 - Assume 4 accounts - total 40 ranges ideally\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eDeciding what size VPC to get, you should ask:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eHow many subnets will you need in each VPC?\u003c/li\u003e\n\u003cli\u003eHow many IP Addresses will you need in total ad how many per subnet?\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eServices use subnets and subnets operate in 1 availability zone. THerefore you need to consider regions as some regions have more availability zones than others.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003epick how many AZs yours would use - possibly use 4 as a default. This means you need 4 smaller networks\u003c/li\u003e\n\u003cli\u003eA suggested default is to start with four tiers - Web, application, database and a spare. If you only used 1 az then you would each tier would need it's own subnet so 4 subnets\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/KnowledgeGarden/./assets/images/vpc-design.png\" alt=\"VPC Design\"\u003e\u003c/p\u003e\n\u003ch3 id=\"custom-vpcs\"\u003eCustom VPCs\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#custom-vpcs\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eVPCs are a regionally isolated and regionally resilient service\u003c/li\u003e\n\u003cli\u003eLets you create an isolated network in AWS\u003c/li\u003e\n\u003cli\u003eNothing is allowed IN or OUT without explicit configuration\u003c/li\u003e\n\u003cli\u003eFlexible configuration\u003c/li\u003e\n\u003cli\u003eHybrid networking\u003c/li\u003e\n\u003cli\u003eYou have the option of created default or dedicated tenancy - allows you to either put the VPC in shared or dedicated hardware - If you put default you can change this later. If you put dedicated \u003cstrong\u003eit's locked in and any resources on this vpc will have to be dedicated too\u003c/strong\u003e. Only choose this if you really need it as it comes at a premium cost\u003c/li\u003e\n\u003cli\u003eCan use IPv4 private and public IPs\u003c/li\u003e\n\u003cli\u003ePrivate CIDR block is the main method of communication for the VPC\u003c/li\u003e\n\u003cli\u003eThis primary block at it's smallest can be /28 (16 IP) and max /16 (65,536 IP)\u003c/li\u003e\n\u003cli\u003eYou can create optional secondary IPv4 block\u003c/li\u003e\n\u003cli\u003eCan be configured to use IPv6 (/56). However, you can't pick a range, AWS chooses them for you unless you own specific IPv6 IPS\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eDNS in a VPC:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eProvided by R53\u003c/li\u003e\n\u003cli\u003eAvailable on the base IP address of the VPC +2\u003c/li\u003e\n\u003cli\u003eenableDnsHostnames - gives public DNS hostnames to instances\u003c/li\u003e\n\u003cli\u003eenableDnsSupport - enables DNS resolution in VPC - if not then the dns won't work\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"vpc-subnets\"\u003eVPC Subnets\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#vpc-subnets\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eSubnets in VPCs start of entirely private and you need to configure them to be public\u003c/li\u003e\n\u003cli\u003eA subnet is an AZ resilient feature of the VPC\u003c/li\u003e\n\u003cli\u003eIt's a subnetwork of a VPC within a particular AZ\u003c/li\u003e\n\u003cli\u003e1 subnet is created a specific AZ in that region. It can never be changed and can never ben in multiple AZs. ONE SUBNET =\u003e ONE AZ. Although one AZ can have 0 or more subnets\u003c/li\u003e\n\u003cli\u003eAllocated an IPv4 CIDR - it has to be within the range of the VPC\u003c/li\u003e\n\u003cli\u003eThe CIDR that a subnet uses can't overlap with other subnets in that VPC\u003c/li\u003e\n\u003cli\u003eCan optionally be allocated an IPv6 CIDR block. A /64 subset of the /56 is allocated (256)\u003c/li\u003e\n\u003cli\u003eSubnets can communicate with other subnets in the VPC\u003c/li\u003e\n\u003cli\u003eSizes of networks are based on the prefix\u003c/li\u003e\n\u003cli\u003eSome IPs in every VPC network are reserved\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eEvery VPC subnet has five addresses that cannot be used. Assuming the subnet we use is 10.16.16.0/20, the following can't be used:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003ethe network address (starting address) e.g. 10.16.16.0\u003c/li\u003e\n\u003cli\u003eNetwork + 1 (10.16.16.1) - used by the VPC router\u003c/li\u003e\n\u003cli\u003eNetwork + 2 (10.16.16.2) - Reserved by the DNS\u003c/li\u003e\n\u003cli\u003eNetwork + 3 (10.16.16.3) - For future use\u003c/li\u003e\n\u003cli\u003eBroadcast address 10.16.31.255 (Last IP in subnet)\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eA VPC has a configuration object applied to it called a DHCP option set - (dynamic host configuration protocol) - how computing devices receive IP addresses automatically.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eOn every subnet you can define two important allocation options:\n\u003col\u003e\n\u003cli\u003eAuto assign public IPv4 - allocated public addresses as well as their private automatically\u003c/li\u003e\n\u003cli\u003eAuto assign public IPv6\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"vpc-routing-internet-gateway--bastion-hosts\"\u003eVPC Routing, Internet Gateway \u0026#x26; Bastion Hosts\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#vpc-routing-internet-gateway--bastion-hosts\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eVPC Router:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEvery VPC has a VPC router - it's highly available\u003c/li\u003e\n\u003cli\u003eIn every subnet, the network+1 address is reserved for the vpc router\u003c/li\u003e\n\u003cli\u003eIt routes traffic between subnets\u003c/li\u003e\n\u003cli\u003eIt's controllable, you create route tables which influences what to do with traffic when it leaves the subnet\u003c/li\u003e\n\u003cli\u003eA VPC is created with a main route table - if you don't explicitly associate it, then it uses the main route table of the vpc. Otherwise if you create your own, the old one is dissociated. A subnet can only be associated with one route table at a time but a route table can be associated with many subnets\u003c/li\u003e\n\u003cli\u003eA route table is a list of routes - the vpc looks at the destination address, looks at the route table for the destination address and propagates the data to those destinations. It can be either to a single route or a range. The prefix is used as a priority - the higher the prefix the higher the priority\u003c/li\u003e\n\u003cli\u003eThe target field in a route table is either pointing to a gateway or to local\u003c/li\u003e\n\u003cli\u003eAll route tables have at least 1 route - the local route which matches the VPC CIDR range\u003c/li\u003e\n\u003cli\u003eIf it's also ipv6 enabled it will have another default local route for ipv6\u003c/li\u003e\n\u003cli\u003eThese local routes can never be updated, and those two will ALWAYS take priority\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eInternet Gateway:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRegional resilient gateway which can be attached to a VPC\u003c/li\u003e\n\u003cli\u003eyou do not need a gateway per availability zone\u003c/li\u003e\n\u003cli\u003ea vpc can have no internet gateways or just one\u003c/li\u003e\n\u003cli\u003ea gateway can have no attachments or 1 at a time\u003c/li\u003e\n\u003cli\u003eRuns from the border of the VPC and the aws public zone - allows services to be reached from the internet (AWS public zone)\u003c/li\u003e\n\u003cli\u003eit's a managed gateway, aws handles the performance\u003c/li\u003e\n\u003cli\u003ePublic ipv4 internet addresses never actually touch the services inside the VPC. A record is created which the internet gateway maintains. The instance itself is not configured with a public IP.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003ebaston Host / Jump boxes\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAn instance in a public subnet inside a vpc\u003c/li\u003e\n\u003cli\u003eused to manage incoming connections\u003c/li\u003e\n\u003cli\u003ethis allows you to access internal vpc resource - it's a management or entry point to private vpcs\u003c/li\u003e\n\u003cli\u003eIt used to be the only way in to a vpc\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"stateful-vs-stateless-firewalls\"\u003eStateful vs Stateless Firewalls\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#stateful-vs-stateless-firewalls\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eTCP and IP work together where TCP connection send IP packets\u003c/li\u003e\n\u003cli\u003eTCP runs on top of IP\u003c/li\u003e\n\u003cli\u003eA stateless firewall does not understand the state of connections. It needs two rules per inbound connection, an inbound and an outbound and 2 per outbound connection (inbound and outbound).\u003c/li\u003e\n\u003cli\u003eYou will have to allow the full range of ephemeral ports allowed in stateless firewall since responding to a request in a stateless server goes back to a random requester port. This can be a security concern.\u003c/li\u003e\n\u003cli\u003eA stateful firewall is intelligent enough to identify the request and response components of a connection\u003c/li\u003e\n\u003cli\u003eyou will only have to allow the request meaning the response is automatically allowed\u003c/li\u003e\n\u003cli\u003eYou don't need to allow the full ephemeral port range because a stateful firewall is smart enough to know which port to open up for a request/response\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"network-access-control-lists-nacls\"\u003eNetwork Access Control Lists (NACLs)\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#network-access-control-lists-nacls\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eCan be thought of as a traditional firewall available in AWS vps\u003c/li\u003e\n\u003cli\u003eConnections within a subnet are not affected by NACLs but inbound/outbound crossing the subnet boundary are filtered by NACLs\u003c/li\u003e\n\u003cli\u003eNACLs have inbound and outbound rules - data entering and leaving the subnet. Remember a request and a response can be both inbound and outbound.\u003c/li\u003e\n\u003cli\u003eA VPC is created with a default NACL. Inbound/outbound rules have the implicit deny (*) and an ALLOW ALL rule. The result is all traffic is allowed, the NACL has no effect\u003c/li\u003e\n\u003cli\u003eCustom NACLs are created for a specific VPC and are initially associated with no subnets. The default rule for inbound and outbound is an implicit deny (*). This means all traffic is denied by default\u003c/li\u003e\n\u003cli\u003eNACL crossing subnets needs the correct inbound/outbound rules\u003c/li\u003e\n\u003cli\u003eNACLs can only be assigned to subnets in AWS\u003c/li\u003e\n\u003cli\u003eThey can be used together with security groups to add explicit DENY\u003c/li\u003e\n\u003cli\u003eEach subnet can have one NACL associated to it (default or custom)\u003c/li\u003e\n\u003cli\u003eA single NACL can be associated with many subnets\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"security-groups-sg\"\u003eSecurity Groups (SG)\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#security-groups-sg\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA second type of security filtering feature used in AWS VPC\u003c/li\u003e\n\u003cli\u003eSG's are stateful - they detect response traffic automatically for a given request\u003c/li\u003e\n\u003cli\u003ethat means any IN or OUT request that is allowed will automatically allow a response - you don't have to worry about configuring ephemeral ports\u003c/li\u003e\n\u003cli\u003eThe major limitation of SG's are that there is no EXPLICIT deny. You cannot block specific bad actors e.g. a range of or a single IP\u003c/li\u003e\n\u003cli\u003eUsually SGs and NACLs are used in conjunction for this reason\u003c/li\u003e\n\u003cli\u003eSG support iP/CIDR AND logical resources\u003c/li\u003e\n\u003cli\u003eThis includes other security groups as well as itself\u003c/li\u003e\n\u003cli\u003eSGs are not attached to instances nor subnets, they are attached to specific elastic network interfaces known as ENIs\u003c/li\u003e\n\u003cli\u003eSG can use logical references - it can refer to other security groups so that you don't explicitly put IP ranges, any resource in that SG is allowed\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"network-address-translation-nat--nat-gateway\"\u003eNetwork Address Translation (NAT) \u0026#x26; NAT Gateway\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#network-address-translation-nat--nat-gateway\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA set of different processes by changing their source/destination IP addresses\u003c/li\u003e\n\u003cli\u003eIP Masquerading is a subset of NAT. IT can hide CIDR IP Blocks behind one IP i.e. many private IP to one public IP\u003c/li\u003e\n\u003cli\u003eSince IPv4 addresses are running out, giving many private CIDR range \u003cstrong\u003eoutgoing\u003c/strong\u003e internet access\u003c/li\u003e\n\u003cli\u003eA NAT gateway takes all the incoming packets from all the instances it's managing and it records all the information about the communication. It takes those packets, changes the source address from those instances to it's own IP address (external facing address).\u003c/li\u003e\n\u003cli\u003eNAT Gateways need to be run from a public subnet so that you can assign an external IPv4 for it\u003c/li\u003e\n\u003cli\u003eUses Elastic IPs (static ipv4 public)\u003c/li\u003e\n\u003cli\u003eAZ resilient service - to make it region resilient, you should but a nat gateway in each AZ and a routing table for each AZ in that NAT gateway as a target\u003c/li\u003e\n\u003cli\u003eCan get costly if you have a lot of AZs\u003c/li\u003e\n\u003cli\u003eThey are a managed service, you deploy and AWS takes care of them\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/KnowledgeGarden/./assets/images/natgw-resilience.png\" alt=\"NATGW Full resilience\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eA NAT instance is when you make an EC2 instance run as a NAT instance\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIt's much easier and scalable to use a NAT gateway except for when:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ecost is an issue\u003c/li\u003e\n\u003cli\u003efor test purposes\u003c/li\u003e\n\u003cli\u003eneed something free tier eligible\u003c/li\u003e\n\u003cli\u003eyou need to connect to them like normal ec2 instances - NAT Gateway cannot be used as a bastion host nor can they do port forwarding\u003c/li\u003e\n\u003cli\u003eNAT Gateways don't support security groups, they can only use NACLs\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eNAT is not required for IPv6\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIn AWS IPv6 addresses are all publicly routable\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eNat gateways DON'T work with IPV6\u003c/strong\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eif you add ::/0 route, that will give an internet gateway bidirectional connectivity for ipv6\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eYou can use Egress Only internet gateway if you want outbound only connection for IPv6\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"elastic-compute-cloud-ec2-basics\"\u003eElastic Compute Cloud (EC2) Basics\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#elastic-compute-cloud-ec2-basics\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003ch3 id=\"virtualization-101\"\u003eVirtualization 101\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#virtualization-101\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eEC2 provides virtualisation as a service (IaaS)\u003c/li\u003e\n\u003cli\u003eVirtualization is the process of running more than one operating system on a piece of physical hardware (a server)\u003c/li\u003e\n\u003cli\u003eBefore virtualization, Applications would run on top of an OS in user mode. They cannot directly access hardware resources. If apps try to do that it would cause a system wide error or crash the application\u003c/li\u003e\n\u003cli\u003eVirtualization fixes this by allowing a single piece of hardware to run multiple OS' where each is separate.\u003c/li\u003e\n\u003cli\u003eHistorically, virtualization was done in two ways:\u003c/li\u003e\n\u003c/ul\u003e\n\u003col\u003e\n\u003cli\u003eEmulated Virtualization (software) - the OS still ran on the hardware on top of a hypervisor. The software ran in privileged mode. Each OS ran inside in a virtual machines. They have emulated hardware provided by the hypervisor. The main issue was that this method was slow.\u003c/li\u003e\n\u003cli\u003ePara-virtualization - only works on a small subset of OS that can be modified.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eThe major improvement in virtualization came when the physical hardware became virtualization aware. This is known as hardware assisted virtualization. The CPU itself knowns virtualization exists. The hardware redirects privileged calls to the hypervisor.\nThe process of where the hardware devices themselves become virtualization aware is known as SR-IOV - single route I/O virtualization. Allows a network card or any other I/O card to present itself as not a single card but as several mini cards. These are presented to the guest operating system as real cards and hence the hypervisor doesn't need to be used - the OS can directly use it's card when it wants.\u003c/p\u003e\n\u003ch3 id=\"ec2-architecture-and-resilience\"\u003eEC2 Architecture and Resilience\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#ec2-architecture-and-resilience\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eEC2 instances are virtual machines (OS + Resources)\u003c/li\u003e\n\u003cli\u003eRun on EC2 Hosts which are either shared or dedicated\u003c/li\u003e\n\u003cli\u003eShared hosts are used by different AWS customers so you don't get ownership of hardware and you pay for usage and resource. There is still no visibility between customers when using shared hosts. Shared host is the default type of hosting\u003c/li\u003e\n\u003cli\u003eDedicated hosts is dedicated to your account and you pay for the whole thing. You don't share it with any AWS customers.\u003c/li\u003e\n\u003cli\u003eEC2 is an \u003cstrong\u003eAZ resilient service\u003c/strong\u003e - Hosts run in a single AZ. If that AZ fails then hosts will fail and any instances on those hosts will fail or be impacted\u003c/li\u003e\n\u003cli\u003eEC2 have some local hardware: cpu, memory and storage (instance store). The instance store will be lost if the instance moves to another host. They also have storage and data networking.\u003c/li\u003e\n\u003cli\u003eEC2 can connect to network storage known as Elastic Block Store (EBS). EBS also rus inside an AZ. You can't access it cross zone.\u003c/li\u003e\n\u003cli\u003eIf an availability zone in AWS has issues, it impacts ec2, subnets, storage and volumes.\u003c/li\u003e\n\u003cli\u003eAn instance runs in a specific host and it will stay on that host when you restart it. It stays there unless it fails or is taken down by AWS. Also if it is stopped and started which is different to restarting. In that instance it will be relocated to another host but it will still be in the same AZ\u003c/li\u003e\n\u003cli\u003eYou can never connect network interfaces or EBS storage in one AZ to an ec2 instance in another AZ\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eEC2 is good when:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eWhen you have a traditional OS and compute need\u003c/li\u003e\n\u003cli\u003eLong running compute needs as it's designed for persistent long running compute requirements\u003c/li\u003e\n\u003cli\u003eYou have server style applications\u003c/li\u003e\n\u003cli\u003eFor burst or steady state load\u003c/li\u003e\n\u003cli\u003eFor monolithic application stacks\u003c/li\u003e\n\u003cli\u003eFor migrating application workloads or disaster recovery\u003c/li\u003e\n\u003cli\u003eEC2 tends to be the default compute service in AWS unless you have niche requirements.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"ec2-instance-types\"\u003eEC2 Instance Types\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#ec2-instance-types\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eFactors in choosing instances:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCPU, memory, local storage capacity and type will influence which instance type you choose\u003c/li\u003e\n\u003cli\u003eResource ratios can give you different ratios of different o resource which will also affect your decision\u003c/li\u003e\n\u003cli\u003eThe amount of storage, data and network bandwidth\u003c/li\u003e\n\u003cli\u003eThe architecture and vendor the instance is run on - x86, ARM, intel, AMD\u003c/li\u003e\n\u003cli\u003eAdditional features and capabilities - GPUs, FPGAs\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eEC2 instances are grouped into 5 main categories:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eGeneral Purpose - default - should be first choice. even resource ratio, diverse workloads\u003c/li\u003e\n\u003cli\u003eCompute Optimized - Media Processing, High performance computing, scientific modelling, gaming, machine learning. Ratio is higher towards CPU\u003c/li\u003e\n\u003cli\u003eMemory Optimized - inverse of compute - ideal for applications for processing large in-memory datasets, database workloads\u003c/li\u003e\n\u003cli\u003eAccelerated computing - for additional capabilities e.g. hardware GPUs field programmable gate arrays (FPGAs)\u003c/li\u003e\n\u003cli\u003eStorage Optimized - fast local storage needs - sequential and random IO. Data warehouses, elastic search, data analytics\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eDecoding EC2 Types:\nExample: \"R5dn.8xlarge\"\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eLetter at the start is the instance family - specific type/types of computing\u003c/li\u003e\n\u003cli\u003eNext (5) is the generation e.g. 5th generation of the family. The latest generation should ideally always be used\u003c/li\u003e\n\u003cli\u003ethe part of the dot - the size \"8xlarge\" - the instance size\u003c/li\u003e\n\u003cli\u003ethe \"dn\" - additional capability e.g n could mean network optimized\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/KnowledgeGarden/./assets/images/ec2-instance-types.png\" alt=\"EC2 Instance Types\"\u003e\u003c/p\u003e\n\u003ch3 id=\"storage-refresher\"\u003eStorage Refresher\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#storage-refresher\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eStorage terms:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDirect (local) attached storage - Storage on the EC2 Host. Fast but prone to loss\u003c/li\u003e\n\u003cli\u003eNetwork attached storage - volumes delivered over the network (EBS). Resilient but slower\u003c/li\u003e\n\u003cli\u003eEphemeral Storage - temporary storage\u003c/li\u003e\n\u003cli\u003ePersistent Storage - Permanent storage - lives on past the lifetime of the instance\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThree main categories of storage available in AWS:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eBlock storage - Create a volume that has addressable blocks. No structure provided. The OS usually takes the block storage and creates a file storage on it. Can be HDD or SSD or a logical storage that's backed by physical storage. You can mount and boot off this volume.\u003c/li\u003e\n\u003cli\u003eFile storage - presented as a file server with a structure already there. Mountable but not bootable since the OS doesn't have low level access to it.\u003c/li\u003e\n\u003cli\u003eObject storage - Flat collection of objects. Not mountable or bootable.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eStorage Performance terms:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eI/O (block) size - the size of the blocks of data that you're writing to disk - KB/MB.\u003c/li\u003e\n\u003cli\u003eIOPS - input output operations per second - how many reads/writes a disk or storage system can accommodate in a second\u003c/li\u003e\n\u003cli\u003eThroughput - amount of data that can be transferred per second - MB/s. Relies on using the right block size and then maximising the number of IOPS\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIO X IOPS = THROUGHPUT\u003c/p\u003e\n\u003ch3 id=\"elastic-block-store-ebs-service-architecture\"\u003eElastic Block Store (EBS) Service Architecture\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#elastic-block-store-ebs-service-architecture\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eProvides block storage which can be addressed using block IDs. It takes raw physical discs, and presents a raw allocation of those disks known as volumes. These volumes can be written to or read from using a block number. They can be encrypted\u003c/li\u003e\n\u003cli\u003eWhen you attach a volume to an EC2 they see a block device and they can use it to create a file system on top of it (ext3/4, xfs). They appear just like any other storage design\u003c/li\u003e\n\u003cli\u003eStorage is provisioned in ONE AZ. It is separate and isolated within that AZ.\u003c/li\u003e\n\u003cli\u003eYou can attach to one EC2 instance (or other service) over a storage network. There is a multi attach feature which allows to attach to multiple at a time but it needs to be managed so that there aren't multi writes\u003c/li\u003e\n\u003cli\u003eYou can de-attach and reattach the EBS to another volume. EBS are persistent so if an instance moves or stops, restarts, the EBS is maintained\u003c/li\u003e\n\u003cli\u003eSnapshots can be taken of EBS volumes and they can be regionally resilient by migrating them between AZs and regions\u003c/li\u003e\n\u003cli\u003eEBS can provision different physical storage types, sizes and performance profiles\u003c/li\u003e\n\u003cli\u003eYou are billed based on GB-month (and sometimes performance)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eYou can't communicate across AZs for EBS\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/KnowledgeGarden/assets/images/ebs-sample-architecture.png\" alt=\"EBS sample architecture\"\u003e\u003c/p\u003e\n\u003ch3 id=\"ebs-volume-types---general-purpose\"\u003eEBS Volume Types - General Purpose\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#ebs-volume-types---general-purpose\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eGP2 - SSD:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eit's high performance storage for a low price.\u003c/li\u003e\n\u003cli\u003efrom 1GB - 16TB\u003c/li\u003e\n\u003cli\u003eAllocated with IO credit of 16KB. IOPS is 16kb. 1 IOPS is 1 IO in 1 second\u003c/li\u003e\n\u003cli\u003eIO Credit bucket has a capacity of 5.4 million IO credits\u003c/li\u003e\n\u003cli\u003eBucket fills with min 100 IO credits per second regardless of volume size\u003c/li\u003e\n\u003cli\u003eGP2 can burst up to 3000 IOPS by depleting the bucket\u003c/li\u003e\n\u003cli\u003eAll volumes start with an initial 5.4 million IO credits\u003c/li\u003e\n\u003cli\u003eMaximum IO per second is 16,000\u003c/li\u003e\n\u003cli\u003eGP2 is flexible storage for general usage. It can be a default if GP3 isn't there yet\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eGP3 - SSD:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRemoves the credit architecture of GP2\u003c/li\u003e\n\u003cli\u003eStarts at 3000 IOPS \u0026#x26; 125 MiB/s\u003c/li\u003e\n\u003cli\u003e20% cheaper than GP2\u003c/li\u003e\n\u003cli\u003eYou get benefits of GP2 with this\u003c/li\u003e\n\u003cli\u003eExtra cost for up to 16,000 IOPS or 1,000 MiBs\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"ebs-volume-types---provisioned-iops\"\u003eEBS Volume Types - Provisioned IOPS\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#ebs-volume-types---provisioned-iops\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eio1/2 - SSD:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIOPS is configured independently of the volume. Good for consistent low latency and jitter.\u003c/li\u003e\n\u003cli\u003e4x IOPS of gp2/3 (up to 64,000)\u003c/li\u003e\n\u003cli\u003eBlock express gets you more IOPS and MiBs\u003c/li\u003e\n\u003cli\u003eThere is a maximum performance that can be achieved - a per instance performance\u003c/li\u003e\n\u003cli\u003eProvisioned io can be good for low latency consistency with high levels of performance e.g. low volumes but high performance\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"ebs-volume-types---hdd-based\"\u003eEBS Volume Types - HDD-Based\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#ebs-volume-types---hdd-based\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eThese volume types are slower\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTwo types of storage in EBS:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003est1 - throughput optimised\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003echeap\u003c/li\u003e\n\u003cli\u003e125gb - 16tb\u003c/li\u003e\n\u003cli\u003emaximum of 500 IOPS - 1mb blocks - max of 500 MB/s\u003c/li\u003e\n\u003cli\u003eUseful for big data, data warehouses, log processing\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003esc1 - cold HDD\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003echeaper\u003c/li\u003e\n\u003cli\u003e125gb - 16tb\u003c/li\u003e\n\u003cli\u003edesigned for infrequent workloads - used for maximum economy where performance isn't as important\u003c/li\u003e\n\u003cli\u003emax 250 IOPS - max 250 MB/s\u003c/li\u003e\n\u003cli\u003elowest cost ebs storage type\u003c/li\u003e\n\u003cli\u003ecold data with few scans a day\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"instance-store-volumes---architecture\"\u003eInstance Store Volumes - Architecture\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#instance-store-volumes---architecture\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eBlock storage devices - raw volumes presented to an instance that present TEMPORARY storage\u003c/li\u003e\n\u003cli\u003eLike EBS except local\u003c/li\u003e\n\u003cli\u003ephysically connected to one EC2 host\u003c/li\u003e\n\u003cli\u003eInstances on that host can access those volumes\u003c/li\u003e\n\u003cli\u003eHigh storage performance\u003c/li\u003e\n\u003cli\u003eIncluded in the instance price\u003c/li\u003e\n\u003cli\u003eHave to be attached at launch time - CANNOT be attached after like EBS\u003c/li\u003e\n\u003cli\u003ethese are temporary volumes\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/KnowledgeGarden/./assets//images/instance-store-volumes.png\" alt=\"alt text\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eif you move an instance between hosts, that data is lost. They are given new ephemeral volumes.\u003c/li\u003e\n\u003cli\u003eif a physical volume fails, then the instance would lose that data\u003c/li\u003e\n\u003cli\u003ethese should only be used for temporary data\u003c/li\u003e\n\u003cli\u003esome instance types don't support these\u003c/li\u003e\n\u003cli\u003eperformance is a strength of instance store e.g. 4.6 GB/s - 16 GB/s throughput depending on HDD or SSD\u003c/li\u003e\n\u003cli\u003eMore IOPS and Throughput VS EBS\u003c/li\u003e\n\u003cli\u003eLocal to EC2 HOST\u003c/li\u003e\n\u003cli\u003eif the volume is resized the data is also lost\u003c/li\u003e\n\u003cli\u003eYou pay for it with the instance so there is no advantage to not using them\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"choosing-between-the-ec2-instance-store-and-ebs\"\u003eChoosing between the EC2 Instance Store and EBS\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#choosing-between-the-ec2-instance-store-and-ebs\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003ePersistence required - default to EBS (avoid Instance store)\u003c/li\u003e\n\u003cli\u003eResilience - as above\u003c/li\u003e\n\u003cli\u003eIf you need storage isolated from instance lifecycles then use EBS\u003c/li\u003e\n\u003cli\u003eIf your instance requires resilience but your app supports built-in replication, you could use lots of instances\u003c/li\u003e\n\u003cli\u003eIf you need high performance - both could be good although super high performance, instance store makes more sense\u003c/li\u003e\n\u003cli\u003eIf cost is a concern, instance store makes sense as it comes with the instance\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eREMEMBER these figures:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIf you need cheap storage but with EBS, use ST1 or SC1 because they are cheaper\u003c/li\u003e\n\u003cli\u003eThroughput or streaming should default to DT1\u003c/li\u003e\n\u003cli\u003eif you need a boot volume NEITHER ST1 OR SC1 are suitable\u003c/li\u003e\n\u003cli\u003eGP/2 - can deliver up to 16,000 IOPS\u003c/li\u003e\n\u003cli\u003eIO1/2 - up to 64,000 IOPS (*256,000 for block express for large instance types)\u003c/li\u003e\n\u003cli\u003eRAID0 + EBS can achieve 260,000 IOPS (io1/2-BE/GP2/3 combination)\u003c/li\u003e\n\u003cli\u003eIf you need more than 260,000 and you can deal with less resilience or no persistence, then use Instance Store\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThese figures are important to remember:\n\u003cimg src=\"/KnowledgeGarden/./assets/images/instance-store-ebs.png\" alt=\"ec2 instance store vs ebs\"\u003e\u003c/p\u003e\n\u003ch3 id=\"snapshots-restore--fast-snapshot-restore-fsr\"\u003eSnapshots, Restore \u0026#x26; Fast Snapshot Restore (FSR)\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#snapshots-restore--fast-snapshot-restore-fsr\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eBackup volumes to s3\u003c/li\u003e\n\u003cli\u003eProtect against AZ issues, migrate data between AZs\u003c/li\u003e\n\u003cli\u003eSnapshots become region resilient\u003c/li\u003e\n\u003cli\u003eIncremental in nature - the first is a full copy of the data on the volume\u003c/li\u003e\n\u003cli\u003eFuture snapshots only store the difference - consume less space and are quicker to perform\u003c/li\u003e\n\u003cli\u003eIf you accidentally delete a snapshot, future snapshots will fix any lost saves\u003c/li\u003e\n\u003cli\u003eEBS volumes can be blank or based on a restored snapshot\u003c/li\u003e\n\u003cli\u003eSnapshots can be copied between regions\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/KnowledgeGarden/./assets/images/EBS-snapshots.png\" alt=\"Ebs Snapshot architecture\"\u003e\u003c/p\u003e\n\u003cp\u003eNuances to Snapshot/volume performance:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSnaps restore lazily - fetched gradually\u003c/li\u003e\n\u003cli\u003eFast Snapshot Restore (FSR) is an option to immediately restore\u003c/li\u003e\n\u003cli\u003eUp to 50 FSR snaps per region can be restored. Set on the Snap and AZ.\u003c/li\u003e\n\u003cli\u003eFSR costs extra and can get expensive\u003c/li\u003e\n\u003cli\u003eYou can achieve the same end result by manually getting the OS to read all the data in s3 which forces the requested blocks to be pulled in\u003c/li\u003e\n\u003cli\u003eSnapshots are billed at Gigabyte per month\u003c/li\u003e\n\u003cli\u003eThe data stored is the USED not the allocated data e.g if you use 10 of 40gb only 10gb is stored and billed on\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"ebs-encryption\"\u003eEBS Encryption\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#ebs-encryption\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eEBS is not encrypted by default\u003c/li\u003e\n\u003cli\u003eEBS Encryption uses a KMS key using either a default KMS/EBS key or a customer managed key\u003c/li\u003e\n\u003cli\u003eThe key is used to create a data encrypted key (DEK)\u003c/li\u003e\n\u003cli\u003eWhat is stored in the EBS is encrypted and what is in the instance's memory is the decrypted version\u003c/li\u003e\n\u003cli\u003eAny snapshot of the EBS will also be encrypted with the same key\u003c/li\u003e\n\u003cli\u003eIt doesn't cost anything to use so you should use it by default\u003c/li\u003e\n\u003cli\u003eAccounts can be set up to encrypt EBS by default\u003c/li\u003e\n\u003cli\u003eEach volume uses a 1 unique DEK\u003c/li\u003e\n\u003cli\u003eIf you create any EBS volumes from a snapshot with an encryption key, it uses that same DEK\u003c/li\u003e\n\u003cli\u003eYou can't change a volume NOT to be encrypted\u003c/li\u003e\n\u003cli\u003eOS isn't aware of the encryption therefore there is no performance loss\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"network-interfaces-instance-ips-and-dns\"\u003eNetwork Interfaces, Instance IPs and DNS\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#network-interfaces-instance-ips-and-dns\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eInstances all start of with 1 network interface (a primary ENI - Elastic Network Interface)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eNetwork interfaces need to be in the same AZ as an instance\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eNetwork instances have a MAC address which is the hardware address\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eNetwork instances have a primary IPv4 Private IP\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e0 or more secondary private IPs - doesn't change for the lifetime of the instance\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e0 or 1 public IPv4 address - dynamic and will change e.g. when you stop and start an instance (not restarts)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e1 elastic IP per private IPv4 address - assigning this means the instance will remove the dynamic public IPv4\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e0 or more Ipv6 addresses (these are publicly routable)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eSecurity groups\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePer interface you can enable/disable source/destination check\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eSecondary interfaces can be moved to other instances\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eyou might use different network interfaces for different security groups\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eOS never sees the public IPv4 - this is performed by the internet gateway - You will NEVER configure an IPv4 public address\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePublic DNS will resolve to the primary private IP in the VPC. Instance to instance communication will not leave the VPC because of this. Everywhere else, it resolves to the public IP address.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"amazon-machine-images-ami\"\u003eAmazon Machine Images (AMI)\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#amazon-machine-images-ami\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eImages of EC2 - you can create a template of an instance configuration and use that template to create other instances\u003c/li\u003e\n\u003cli\u003eWhen you create an instance you're using AWS provided AMIs but you can create your own\u003c/li\u003e\n\u003cli\u003eAMIs can be AWS or Community provided as well e.g. Redhat, Centos, Ubuntu\u003c/li\u003e\n\u003cli\u003eMarketplace also provide AMIs which include commercial software\u003c/li\u003e\n\u003cli\u003eAMIs are regional and they have a unique ID (ami-[letters, numbers])\u003c/li\u003e\n\u003cli\u003eAMIs can control permissions (public, your account, specific accounts)\u003c/li\u003e\n\u003cli\u003eYou can create an AMI from an existing EC2 instance\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAMI Lifecycle:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eLaunch - create an instance from AMI\u003c/li\u003e\n\u003cli\u003eConfigure - Customising your instance\u003c/li\u003e\n\u003cli\u003eCreate image - Creating a new AMI from the instance - Snapshots are also taken of EBS volumes and they are references by the AMI as block device mapping\u003c/li\u003e\n\u003cli\u003eLaunch - when the AMI is used to create a new instance, it will have the same EBS volume as the original\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003eAMI's are in ONE region. Only works in that region but it can be used to deploy into all AZs in that region\u003c/li\u003e\n\u003cli\u003eAMI Baking - creating an AMI from configured instance\u003c/li\u003e\n\u003cli\u003eAMI \u003cstrong\u003ecan't be edited\u003c/strong\u003e - you need to launch an instance, update the config and make a new AMI\u003c/li\u003e\n\u003cli\u003eAMI can be copied between regions but they become SEPARATE AMIs\u003c/li\u003e\n\u003cli\u003ePermissions of AMI by default is your account - it can be private, public or given to specific accounts\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"ec2-purchase-options\"\u003eEC2 Purchase Options\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#ec2-purchase-options\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eSometimes known as launch types\nOn demand:\n\u003cul\u003e\n\u003cli\u003edefault\u003c/li\u003e\n\u003cli\u003eInstances of different sizes run on the same EC2 hosts with different AWS customers.\u003c/li\u003e\n\u003cli\u003eOn demand uses per second billing while instances are running. Associated storage e.g. storage will charge even when the instances are shut down\u003c/li\u003e\n\u003cli\u003eFor all projects, assume on demand and move only when needed\u003c/li\u003e\n\u003cli\u003eNo interruptions\u003c/li\u003e\n\u003cli\u003eWill not give you priority access if there are any failures\u003c/li\u003e\n\u003cli\u003ePredictable pricing, upfront costs but no discounts\u003c/li\u003e\n\u003cli\u003eGood for short term workloads or unknown workloads\u003c/li\u003e\n\u003cli\u003eFor apps that can't be interrupted\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSpot pricing:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCheapest\u003c/li\u003e\n\u003cli\u003eAWS sells spare capacity in an EC2 host at a discounted rate (up to 90% discount)\u003c/li\u003e\n\u003cli\u003eWill charge up to your maximum price before terminating any of your instances\u003c/li\u003e\n\u003cli\u003eNever use SPOT for workloads which can't tolerate interruptions\u003c/li\u003e\n\u003cli\u003eGood fits for SPOT workloads are things that are not time critical or can tolerate interruption/re-run e.g. media processing\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eReserved instances:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFor long term consistent usage of EC2\u003c/li\u003e\n\u003cli\u003eReduce the per-second cost or remove it entirely\u003c/li\u003e\n\u003cli\u003eIt's possible to reserve and not use and therefore still be built\u003c/li\u003e\n\u003cli\u003eYou can commit for 1 year of 3 years - the longer the more discounted but you need to be careful of wasted resource\u003c/li\u003e\n\u003cli\u003eYou can choose to pay no upfront - per second fee\u003c/li\u003e\n\u003cli\u003eYou can choose upfront means no per second fee so you get the greatest discount here\u003c/li\u003e\n\u003cli\u003ePartial upfront - pay a smaller lump sum in advance for a lower per-second cost\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eDedicated host:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAn EC2 host that is dedicated to you in it's entirety\u003c/li\u003e\n\u003cli\u003eYou pay for the host - the instances on the host you don't pay for so they can be any size up until the capacity\u003c/li\u003e\n\u003cli\u003eYou have a feature called host affinity - stopping and starting instances means that they can stay on the same host\u003c/li\u003e\n\u003cli\u003eA good use case for dedicated host is you are using software that has licensing based on socket and core\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eDedicated Instances:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA middle ground - instances run on ec2 hosts with other instances of yours and no other customers use the same hardware. You don't pay for the host nor share. You don't to manage the host itself\u003c/li\u003e\n\u003cli\u003eYou have to pay one off hourly fee for any regions where you use them\u003c/li\u003e\n\u003cli\u003eA fee for the dedicated industry itself\u003c/li\u003e\n\u003cli\u003eThis is where you may be an industry where you cannot use the same underlying hardware as other customers\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eFocus : On-demand, spot and reserved for the exam\u003c/p\u003e\n\u003ch3 id=\"reserved-instances---the-rest\"\u003eReserved Instances - the rest\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#reserved-instances---the-rest\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eIf you need access to the cheapest ec2 running all the time then you would pick standard reserved\u003c/li\u003e\n\u003cli\u003eScheduled reserved:\u003c/li\u003e\n\u003cli\u003eare great for when you have long term requirements but when it doesn't need to be run constantly e.g. batch processing\u003c/li\u003e\n\u003cli\u003eIf you reserve for that time window that's the only time you can use it\u003c/li\u003e\n\u003cli\u003eDoesn't support all instance types and regions. 1,200 hours per year and 1 year minimum terms\u003c/li\u003e\n\u003cli\u003eCapacity reservations\n\u003cul\u003e\n\u003cli\u003ehave a requirement for some compute that you can guarantee you can launch when you need\u003c/li\u003e\n\u003cli\u003eYou can purchase a reservation and make it a regional one, you get billing discounts on instances in the AZ. They don't reserve capacity within an AZ which is risky during major faults when capacity can be limited\u003c/li\u003e\n\u003cli\u003eYou can pick a zonal reservation - only apply to one AZ providing billing discounts and capacity reservation in that AZ\u003c/li\u003e\n\u003cli\u003eRegional/AZ are both 1 or 3 year commitment - you can choose on demand capacity reservation - can be booked to ensure you always have access to capacity in an AZ when you need it but at full on demand price. You will pay regardless of whether you consume it\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSavings plan:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ean hourly commit for 1-3 years and you get a reduction\u003c/li\u003e\n\u003cli\u003eYou can make a reservation for general compute amounts\u003c/li\u003e\n\u003cli\u003eOr a specific EC2 savings plan\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"instance-status-checks--auto-recovery\"\u003eInstance Status Checks \u0026#x26; Auto Recovery\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#instance-status-checks--auto-recovery\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eEvery instance has two high level per instance checks:\n\u003col\u003e\n\u003cli\u003eSystems status - failure could mean loss of system power, loss of network connectivity, host software issues, hardware issues\u003c/li\u003e\n\u003cli\u003eInstance status - corrupt file system, incorrect instance networking, OS kernel issues\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eYou can manually stop/restart an instance to fix status checks otherwise you can set up auto-recovery\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"horizontal--vertical-scaling\"\u003eHorizontal \u0026#x26; Vertical Scaling\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#horizontal--vertical-scaling\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eTwo different ways to handle increasing and decreasing load on the system\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eVertical scaling:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eUse a bigger server e.g. using a different ec2 instance i.e. go from t3.large to t3.xlarge\u003c/li\u003e\n\u003cli\u003eThere will be downtime when you do this - you should do it during an outage window\u003c/li\u003e\n\u003cli\u003eLarger instance carry a price premium\u003c/li\u003e\n\u003cli\u003ethere is an upper cap on the performance of an instance\u003c/li\u003e\n\u003cli\u003eNo application modification required\u003c/li\u003e\n\u003cli\u003eworks for all applications even monolithic\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eHorizontal scaling:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eInstead of increasing the size of an individual instance, you add more instances with load\u003c/li\u003e\n\u003cli\u003eInstead of one running copy of your application you will have multiple that need to work together\u003c/li\u003e\n\u003cli\u003eFor that reason you will need a load balancer usually so that the load is distributed across the instances\u003c/li\u003e\n\u003cli\u003eSessions handling is important - since you may be shifting between instances constantly - you would need application support or \u003cstrong\u003eoff-host sessions\u003c/strong\u003e which means that the session is stored somewhere else e.g. another db\u003c/li\u003e\n\u003cli\u003eUsing off-host sessions would mean the application is stateless - the application doesn't care which instance you connect to\u003c/li\u003e\n\u003cli\u003eYou have no disruption while you're scaling - customer connections remain unaffected and if the sessions are externally hosted it wouldn't matter if you scale down either\u003c/li\u003e\n\u003cli\u003eThere are no real limits to horizontal scaling\u003c/li\u003e\n\u003cli\u003eOften less expensive - no large instance premium\u003c/li\u003e\n\u003cli\u003emore granular in terms of resource management\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"instance-metadata\"\u003eInstance Metadata\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#instance-metadata\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA service EC2 provides to instances where you can access data about an instance\u003c/li\u003e\n\u003cli\u003eUsed to configure and manage an instance\u003c/li\u003e\n\u003cli\u003eAccessible inside all instances - you access it via the IP: \u003ca href=\"http://169.254.169.254\"\u003ehttp://169.254.169.254\u003c/a\u003e -\u003e \u003ca href=\"http://169.254.169.254/latest/meta-data/\"\u003ehttp://169.254.169.254/latest/meta-data/\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eData/information provided:\n\u003cul\u003e\n\u003cli\u003eenvironment\u003c/li\u003e\n\u003cli\u003enetworking\u003c/li\u003e\n\u003cli\u003eauthentication\u003c/li\u003e\n\u003cli\u003euser-data\u003c/li\u003e\n\u003cli\u003eNOT AUTHENTICATED or ENCRYPTED - if you connect to an ec2 you can access this. You can restrict it with a firewall for extra money\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"containers--ecs\"\u003eContainers \u0026#x26; ECS\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#containers--ecs\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003ch3 id=\"introduction-to-containers\"\u003eIntroduction to Containers\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#introduction-to-containers\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA container is similar to a VM in that in provides an isolated environment\u003c/li\u003e\n\u003cli\u003eWhere virtual machines run a whole isolated OS, a container runs as a process within the host operating system\u003c/li\u003e\n\u003cli\u003eThe processes are like isolated OS\u003c/li\u003e\n\u003cli\u003eContainers are much lighter than virtual machines since they don't need to run a full OS\u003c/li\u003e\n\u003cli\u003eA container is a running copy of a docker image\u003c/li\u003e\n\u003cli\u003eDocker images are a stack of layers created using a docker file\u003c/li\u003e\n\u003cli\u003eDocker images are how we create a docker container - a running copy of a docker image\u003c/li\u003e\n\u003cli\u003eA container registry is a hub of container images - it can be private or public e.g. docker hub\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eContainer key concepts:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDockerfiles are used to build images\u003c/li\u003e\n\u003cli\u003eContainers are portable, self contained and always run as expected\u003c/li\u003e\n\u003cli\u003eContainers and images are super lightweight\u003c/li\u003e\n\u003cli\u003eContainers only run the application and environment it needs\u003c/li\u003e\n\u003cli\u003eProvide much of the isolation VMs do\u003c/li\u003e\n\u003cli\u003ePorts are 'exposed' to the host and beyond\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"ecs---concepts\"\u003eECS - Concepts\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#ecs---concepts\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eECS is a product that allows you to run containers fully or partially managed by AWS - it takes away much of the admin overhead of managing containers\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eECS to containers is what ec2 is to virtual machines\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eECS uses clusters which runs in two modes: ec2 mode which uses ec2 instances as container hosts or fargate mode which is a serverless way of running docker containers\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eECS lets you create a cluster\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eAWS also have a container registry called ECR (elastic container registry)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eA task in ECS represents the container as a whole\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eA task role is the IAM role a task can assume to interact with AWS resources - a task role is the best way to give permission to containers\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eTasks and containers are separate things. A task can include one or more containers.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eA service definition is how we can define a task to scale and how we want it to run\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eA container definition - defines the image and ports that will be used for a container - points to a container image in a registry\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eA task definition applies to the application as a whole. It can be a single container definition or multiple containers and multiple container definitions. It's also where you define a task role and the resources that your task is going to consume\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eA task role is the IAM role which hte task assumes\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eService - how many copies of a task you want to run, High availability, restarts\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"ecs---cluster-mode\"\u003eECS - Cluster Mode\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#ecs---cluster-mode\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eEC2 cluster types defines a number of things but one of them is how much admin overhead surrounding running a set of container hosts that you manage vs how many AWS manage.\u003c/p\u003e\n\u003cp\u003eEC2 Mode:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eStart with an ECS management component (also exists in fargate) - handle high level tasks\u003c/li\u003e\n\u003cli\u003eAn ECS cluster is created within VPC in your AWS account - benefits from the multiple AZs\u003c/li\u003e\n\u003cli\u003eEC2s are used to run containers\u003c/li\u003e\n\u003cli\u003eAuto scaling groups are used\u003c/li\u003e\n\u003cli\u003eIf you want to use containers in your infrastructure but you want to also manage host capacity and availability then EC2 mode is the appropriate choice\u003c/li\u003e\n\u003cli\u003eWith EC2 mode, even if you're not running any tasks or services in your containers, you will still be paying for them while they're running\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eFargate mode:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eremoves more overhead\u003c/li\u003e\n\u003cli\u003eyou have no servers to manage - you won't have to pay for EC2 instances\u003c/li\u003e\n\u003cli\u003eAWS have a shared fargate infrastructure\u003c/li\u003e\n\u003cli\u003eFargate still operates in VPC and across AZ\u003c/li\u003e\n\u003cli\u003eTasks and services run on the shared infrastructure platform and are then injected into your VPC - they're given network interfaces inside the VPC\u003c/li\u003e\n\u003cli\u003eYou only pay for the containers you are using based on the resources they consume - you don't need to manage or provision hosts\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eEC2 vs ECS (EC2) vs Fargate:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eif you use containers, use ECS over EC2\u003c/li\u003e\n\u003cli\u003ePick EC2 mode when you have a large workload and price conscious organisation - you can use reserved pricing and try to optimise\u003c/li\u003e\n\u003cli\u003eLarge workload but overhead conscious - use fargate\u003c/li\u003e\n\u003cli\u003eSmall or burst style workloads - fargate makes sense as you only use for the resources the container uses\u003c/li\u003e\n\u003cli\u003ebatch/periodic workloads - fargate\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"elastic-container-registry-ecr\"\u003eElastic Container Registry (ECR)\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#elastic-container-registry-ecr\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eECR is a managed container image registry service - like docker hub but for AWS\u003c/li\u003e\n\u003cli\u003eWe have public and private registries - each aws is provided with one of each.\u003c/li\u003e\n\u003cli\u003eEach registry can have many repositories (think of github)\u003c/li\u003e\n\u003cli\u003eInside each repo you can have many container images and these can have several tags.\u003c/li\u003e\n\u003cli\u003eThe tags need to be unique within your repository\u003c/li\u003e\n\u003cli\u003epublic registry means that anyone can have read only access to anything within that repo (read write needs permission)\u003c/li\u003e\n\u003cli\u003eprivate registry means permission required for read only OR read write\u003c/li\u003e\n\u003cli\u003eECR is integrated with IAM for permission\u003c/li\u003e\n\u003cli\u003eImage scanning is either in basic or enhanced (using inspector product)\u003c/li\u003e\n\u003cli\u003eECR provides near real time metrics - delivered into cloud watch (auth, push, pull)\u003c/li\u003e\n\u003cli\u003eECR logs all api actions into cloud trail\u003c/li\u003e\n\u003cli\u003eGenerates events that are pushed to eventbridge\u003c/li\u003e\n\u003cli\u003eoffers replication cross region and cross-account\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"kubernetes-101\"\u003eKubernetes 101\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#kubernetes-101\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eOpen source container orchestration system - use it to automate the deployment, scaling and management of containerised applications\u003c/li\u003e\n\u003cli\u003eA cloud agnostic product so you can use it on many cloud platforms\u003c/li\u003e\n\u003cli\u003eA kubernetes cluster is a highly available cluster of compute resources which are organised to work as one unit\u003c/li\u003e\n\u003cli\u003eThe cluster starts with a cluster control plane - it manages the cluster, scheduling, applications, deploying\u003c/li\u003e\n\u003cli\u003eCluster nodes are VM or Physical servers which function as a worker in the cluster - they run the containerized applications\u003c/li\u003e\n\u003cli\u003econtainerd or docker is the software for handling container operations\u003c/li\u003e\n\u003cli\u003ekubelet is the agent to interact with the cluster control plane\u003c/li\u003e\n\u003cli\u003ekubelet interacts with the control plane using kubernetes API\u003c/li\u003e\n\u003cli\u003ePods are the smallest unit of computing in kubernetes. It's common to see one container one pod architecture\u003c/li\u003e\n\u003cli\u003eYou could run multiple containers in a pod but it's usually when they're tightly coupled and are in close proximity\u003c/li\u003e\n\u003cli\u003eYou will rarely manage pods directly - they are temporary\u003c/li\u003e\n\u003cli\u003ekube-api server is the front end for kubernetes control plane\u003c/li\u003e\n\u003cli\u003eetcd provides a highly available key-value store - main backing store\u003c/li\u003e\n\u003cli\u003ekube-scheduler - responsible for checking pods that don't have a node assigned - will assign based on constraints\u003c/li\u003e\n\u003cli\u003eoptional component - cloud-controlled-manager - provides cloud specific control logic i.e. AWS/azure/GCP\u003c/li\u003e\n\u003cli\u003ekube controller manager - cluster controller processing - node controller, job controller, endpoint controller, service account \u0026#x26; token controllers\u003c/li\u003e\n\u003cli\u003eon every node - kube proxy is a network proxy - it coordinates networking with the control plane\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003esummary terms:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ecluster\u003c/strong\u003e deployment of kubernetes\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003enode\u003c/strong\u003e - resources: pods are placed on nodes\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003epods\u003c/strong\u003e - smallest unit in kubernetes - often 1 container 1 pod\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eservices\u003c/strong\u003e - an abstraction from pods - service running on 1 or more pods\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ejob\u003c/strong\u003e - ad-hoc, creates one or more pods until completion\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eingress\u003c/strong\u003e - exposes a way into a service\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eingress controller\u003c/strong\u003e - used to provide ingress e.g. AWS LB controller\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePersistent storage (PV)\u003c/strong\u003e - provision long running storage to your applications\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"elastic-kubernetes-service-eks-101\"\u003eElastic Kubernetes Service (EKS) 101\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#elastic-kubernetes-service-eks-101\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA fully-managed kubernetes implementation that simplifies the process of building, securing, operating and maintaining kubernetes clusters\u003c/li\u003e\n\u003cli\u003eCan run on AWS, outposts, EKS anywhere, EKS distro - open source\u003c/li\u003e\n\u003cli\u003eControl plane is managed by AWS and scales based on load across multiple AZs\u003c/li\u003e\n\u003cli\u003eIntegrates with other AWS services - ECR, ELB, IAM, VPC\u003c/li\u003e\n\u003cli\u003eEKS Cluster = EKS Control Plane \u0026#x26; EKS Nodes\u003c/li\u003e\n\u003cli\u003eetcd is distributed across multiple AZs\u003c/li\u003e\n\u003cli\u003eNodes can be self managed, or managed groups or fargate pods - deciding between these is checking the node type and what it needs\u003c/li\u003e\n\u003cli\u003eFor persistent storage - can use EBS, EFS, FSx\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"advanced-ec2\"\u003eAdvanced EC2\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#advanced-ec2\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003ch3 id=\"bootstrapping-ec2-using-user-data\"\u003eBootstrapping EC2 using User Data\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#bootstrapping-ec2-using-user-data\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eBootstrapping is the process of bringing an instance with a certain pre-configured state\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eBootstrapping is a general term outside of AWS\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eWithin EC2 it can allow build automation\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eBootstrapping in EC2 is enabled using ec2 User Data - accessed via the meta-data IP (169.254.196.254/latest/user-data)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eAnything in the user data is executed by the instance OS\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eExecuted ONLY on the FIRST initial launch\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eEC2 doesn't interpret, the OS needs to understand the User Data\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eEC2 on launch checks User Data and executes it or errors on a bad config\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eUser data:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eis opaque to EC2 - it is just a block of data\u003c/li\u003e\n\u003cli\u003enot secure - don't use it for passwords or long term credentials\u003c/li\u003e\n\u003cli\u003elimited to 16kb in size\u003c/li\u003e\n\u003cli\u003ecan be modified but the contents are only executed ONCE on launch\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBoot time to service time - how quickly after you launch an instance is it ready to use\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFor an aws managed AMI it's usually in minutes\u003c/li\u003e\n\u003cli\u003eYou can do the work in advance by AMI baking\u003c/li\u003e\n\u003cli\u003ethe optimal way is to combine bootstrapping and baking - use AMI baking for any part of the process that is time intensive\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"enhanced-bootstrapping-with-cfn-init\"\u003eEnhanced Bootstrapping with CFN-INIT\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#enhanced-bootstrapping-with-cfn-init\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA way you can pass complex bootstrapping instructions to EC2 instances\u003c/li\u003e\n\u003cli\u003ecfn-init is a helper script which is installed on EC2 OS\u003c/li\u003e\n\u003cli\u003eUser data is procedural where as cfn-init is the desired state (declarative)\u003c/li\u003e\n\u003cli\u003ecan work with packages, groups, users, sources, files, commands and services\u003c/li\u003e\n\u003cli\u003eProvided with directives via Metadata and AWS::CLoudFormation:Init on a CFN resource\u003c/li\u003e\n\u003cli\u003eUnlike with user-data that only works on first launch, cfn-init can work with stack updates so that it can execute again and update the configuration of that instance\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eCloudformation creation policies and signals:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCreation policies is something that is added to a logical resource with a timeout value. It waits for a signal from the resource as either a success or error. The resource in cloud formation will show that there is an error if there is one\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"ec2-instance-roles--profile\"\u003eEC2 Instance Roles \u0026#x26; Profile\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#ec2-instance-roles--profile\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eEC2 instance roles are roles that an instance can assume and anything running in that instance has those permissions\u003c/li\u003e\n\u003cli\u003eAn instance profile is a wrapper around an IAM role, it's a way to put the credentials into an instance. This is what gets attached to an ec2 instance.\u003c/li\u003e\n\u003cli\u003eThe credentials are delivered by tbe instance meta-data. The credentials are always renewed before they expired. It will never be in a position where they expire. (automatically rotated)\u003c/li\u003e\n\u003cli\u003eCredentials are in /iam/security-credentials/role-name\u003c/li\u003e\n\u003cli\u003eAlways use roles where possible - they are always preferable to use as opposed to long term credentials\u003c/li\u003e\n\u003cli\u003eCLI tools use ROLE credentials automatically\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"ssm-parameter-store\"\u003eSSM Parameter Store\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#ssm-parameter-store\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eParameter store is a storage for configuration and secrets\u003c/li\u003e\n\u003cli\u003eMany AWS services integrate with Parameter store natively\u003c/li\u003e\n\u003cli\u003eAllows you to store 3 different types of parameters: String, StringList, SecureString\u003c/li\u003e\n\u003cli\u003eYou can store License codes, database strings, full configs and passwords\u003c/li\u003e\n\u003cli\u003eAllows you to store in hierarchies and use versioning\u003c/li\u003e\n\u003cli\u003eCan store plaintext and ciphertext (can integrate with KMS)\u003c/li\u003e\n\u003cli\u003ePublic parameters available e.g latest AMIs per region\u003c/li\u003e\n\u003cli\u003eanything using it needs to be an AWS service or have access to the public endpoints\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"system-and-application-logging-on-ec2\"\u003eSystem and Application Logging on EC2\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#system-and-application-logging-on-ec2\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eCloudwatch is for metrics and cloudwatch logs is for logging\u003c/li\u003e\n\u003cli\u003eNeither of those products natively capture data inside an instance\u003c/li\u003e\n\u003cli\u003eA cloudwatch agent is required - it runs in the ec2 instance and captures OS visible data and sends it to cloudwatch or cloudwatch logs\u003c/li\u003e\n\u003cli\u003eIt needs the configuration and permissions to be able to access and send that data\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"ec2-placement-groups\"\u003eEC2 Placement Groups\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#ec2-placement-groups\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eEC2 usually selects an AZ for you when you launch an instance\u003c/li\u003e\n\u003cli\u003ePlacement groups ensure that instances are physically close together or not\u003c/li\u003e\n\u003cli\u003eThere are three types of placement groups:\u003c/li\u003e\n\u003c/ul\u003e\n\u003col\u003e\n\u003cli\u003eCluster - any instances in a single cluster placement group are physically close together\u003c/li\u003e\n\u003cli\u003eSpread - the inverse where instances are kept separate\u003c/li\u003e\n\u003cli\u003ePartition - for distributed and replicated applications where each group is on different hardware\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eBest practice with cluster group is to launch all the instances at the same time.\nTypically instances in the same group are usually on the same rack, sometimes the same host. They have a direct connection to each other which ensures there is speedy communication between them. Lowest latency and max PPS possible in AWS.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eCluster placement groups\u003c/strong\u003e are used when you really need performance. The con is that there are little resilience because if the AZ goes down the whole cluster goes down.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eYou can't span cluster placement groups across AZs - they must be on ONE AZ only and this is locked when launching first instance\u003c/li\u003e\n\u003cli\u003eYou can span VPC peers but it will signifcantly impact performance\u003c/li\u003e\n\u003cli\u003eNot supported on every instance type\u003c/li\u003e\n\u003cli\u003eYou should use the same type of instance (although it's not mandatory)\u003c/li\u003e\n\u003cli\u003eYou should launch them at the same time (this is again not mandatory but \u003cstrong\u003every recommended\u003c/strong\u003e).\u003c/li\u003e\n\u003cli\u003eOffer 10gbps single stream performance\u003c/li\u003e\n\u003cli\u003eUse cases: Performance, fast speeds, low latency e.g. high compute\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSpread placement groups\u003c/strong\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003edesigned to ensure the maximum amount of availability and resilience\u003c/li\u003e\n\u003cli\u003eCan be across availability zones\u003c/li\u003e\n\u003cli\u003eInstances are on separate racks so if a rack fails, it won't affect the other instances\u003c/li\u003e\n\u003cli\u003eThere is a limit to 7 instances per AZ\u003c/li\u003e\n\u003cli\u003eProvides infrastructure isolation - every instance will be entirely separate from every other instance in that spread placement group\u003c/li\u003e\n\u003cli\u003eeach instance runs from a different rack with its own network and power source\u003c/li\u003e\n\u003cli\u003eYou can't use dedicated instances or hosts\u003c/li\u003e\n\u003cli\u003eUse case: small number of critical instances that need to be kept separate from each other\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003ePartition placement groups\u003c/strong\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSimilar to spread groups\u003c/li\u003e\n\u003cli\u003eDesigned for when you have infrastructure where you have more than 7 instances per AZ but you still have a requirement to separate them\u003c/li\u003e\n\u003cli\u003eCan be created across multiple AZs and you must specify the number of partitions per AZ with a maximum of 7 partitions per AZ.\u003c/li\u003e\n\u003cli\u003eEach partition has it's own rack and power\u003c/li\u003e\n\u003cli\u003eYou can launch as many instances as you need per partition and you can either select the partition explicitly or have AWS make that decision on your behalf\u003c/li\u003e\n\u003cli\u003eGreat for topology aware applications such as HDFS, HBase and Cassandra\u003c/li\u003e\n\u003cli\u003eCan help topology aware applications contain the impact of a failure to part of an application\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"dedicated-hosts\"\u003eDedicated Hosts\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#dedicated-hosts\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA dedicated host is an EC2 host that is dedicated to you in it's entirety\u003c/li\u003e\n\u003cli\u003ethe host is designed for a specific family of instances e.g. a1, c5, m5 etc\u003c/li\u003e\n\u003cli\u003eNo instance charges - you pay for the host\u003c/li\u003e\n\u003cli\u003eCan either pay on demand or reserve options\u003c/li\u003e\n\u003cli\u003eHost hardware comes with a certain number of physical sockets and cores - this dictates how many instances can be run and some software is licensed on the number of sockets and cores of the hardware\u003c/li\u003e\n\u003cli\u003eOlder hosts required all the instances to be the same size but newer ones allow you to mix sizes\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLimitations and features:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAMI Limits - you can't use RHEL, SUSE linux, Windows AMIs\u003c/li\u003e\n\u003cli\u003eCan't use Amazon RDS instances\u003c/li\u003e\n\u003cli\u003eCan't use placement groups\u003c/li\u003e\n\u003cli\u003eHosts can be shared with other accounts in the org using RAM (resource access manager) and those other accounts can create instances on that host. They can only see the instances they created only. You as the owner of the host cannot control the ones that are created by other accounts\u003c/li\u003e\n\u003cli\u003eDedicated hosts are generally used for software licensing / licensing issues. It's not typically the approach you would take just for running EC2 instances\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"enhanced-networking--ebs-optimized\"\u003eEnhanced Networking \u0026#x26; EBS Optimized\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#enhanced-networking--ebs-optimized\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eEnhanced network is a feature which is designed to improve the overall performance of EC2 networking\u003c/li\u003e\n\u003cli\u003eRequired for any high end performance features such as cluster placement groups\u003c/li\u003e\n\u003cli\u003eUses SR-IOV - Makes it so a physical network interface in an EC2 instance is aware of virtualization\u003c/li\u003e\n\u003cli\u003eOffers logical cards per physical card - gives each instance exclusive access to each logical card. Handles the process end to end without consuming the host process' CPU\u003c/li\u003e\n\u003cli\u003eHigher I/O and lower host CPU usage as a result\u003c/li\u003e\n\u003cli\u003emore bandwidth\u003c/li\u003e\n\u003cli\u003ehigher packets per second (PPS)\u003c/li\u003e\n\u003cli\u003eConsistent lower latency\u003c/li\u003e\n\u003cli\u003eAvailable at no charge for EC2 and available on most EC2 types but needs to be configured\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eEBS Optimized\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eHistorically, network used to be shared by data and EBS\u003c/li\u003e\n\u003cli\u003eEBS Optimisation means a dedicated capacity is provided for EBS usage\u003c/li\u003e\n\u003cli\u003eThis means faster speeds for EBS and it doesn't impact the data side\u003c/li\u003e\n\u003cli\u003eMost instances support and have enabled by default\u003c/li\u003e\n\u003cli\u003eSome older instances its supported but enabling costs extra\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"route-53---global-dns\"\u003eRoute 53 - Global DNS\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#route-53---global-dns\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003ch3 id=\"r53-public-hosted-zones\"\u003eR53 Public Hosted Zones\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#r53-public-hosted-zones\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eThere are two types of DNZ Zones in Route 53 - public and private.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eA hosted zone is a DNS database for a given section of the global DNS database e.g. animals4life.org\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eA globally resilient service\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHosted zones are created automatically via R53 - or separately and R53 will host it\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eA zone hosts DNS records e.g. A, AAAA, MX, NS, TXT\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eA hosted zone is what the dns system references and it's authoritative for that domain\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eA public hosted zone is a DNS database hosted by R53 on public name servers\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eAccessible from public internet and VPC\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHosted on 4 x r53 name servers (NS) specific for the zone\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eUse the ns records to point at those 4 x route\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eTo integrate it with the public DNS system, you change the NS records to point at the 4 name servers\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eInside a public hosted zone, you create resource records which DNS uses\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eYou can use route 53 to host zone files for externally registered domains\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"r53-private-hosted-zones\"\u003eR53 Private Hosted Zones\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#r53-private-hosted-zones\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eOperates the same way as a public zone except it's not public\u003c/li\u003e\n\u003cli\u003eIt's associated with VPCs within AWS and it's only accessible there\u003c/li\u003e\n\u003cli\u003eCan also associate it to different accounts\u003c/li\u003e\n\u003cli\u003eCan use a split-view technique where you can have overlapping public and private for public and internal use with the same zone name e.g. private intranet websites\u003c/li\u003e\n\u003cli\u003ePrivate zone is inaccessible from the internet - but it can be made accessible with VPCs.\u003c/li\u003e\n\u003cli\u003eVPC can access the private zone via route53 resolver\u003c/li\u003e\n\u003cli\u003eIf you create a public hosted zone with the same name that is how a split view could work. You have specific records in each.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"cname-vs-r53-alias\"\u003eCNAME vs R53 Alias\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#cname-vs-r53-alias\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eIf we only use CNAMES:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIn DNS an A record maps a name to an IP address i.e. catagram.io =\u003e 1.3.3.7\u003c/li\u003e\n\u003cli\u003eCNAME maps a NAME to another NAME e.g. \u003ca href=\"http://www.catagram.io\"\u003ewww.catagram.io\u003c/a\u003e =\u003e catagram.io\u003c/li\u003e\n\u003cli\u003eYou can't use CNAME for the APEX of the domain i.e. you can't have catagram.io pointing at something else\u003c/li\u003e\n\u003cli\u003eMany AWS services use a DNS Name (ELB)\u003c/li\u003e\n\u003cli\u003eTherefore if you only use CNAME - catagram.io =\u003e ELB would be invalid\u003c/li\u003e\n\u003cli\u003eAlias record fixes this\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAn ALIAS record:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMaps a NAME onto an AWS resource\u003c/li\u003e\n\u003cli\u003eCan be used for naked/apex and normal records\u003c/li\u003e\n\u003cli\u003eFor non apex/naked it functions like CNAME\u003c/li\u003e\n\u003cli\u003eThere is no charge for ALIAS requests pointing to AWS resources\u003c/li\u003e\n\u003cli\u003eFor AWS services e.g. cloudfront, gateway, s3 buckets - you should default to picking ALIAS\u003c/li\u003e\n\u003cli\u003eAn ALIAS is a subtype - you need to manage the record type with the type youre pointing to e.g. elastic balancer is A record therefore you need to create an A record ALIAS\u003c/li\u003e\n\u003cli\u003eCan only use ALIAS if you're using route 53\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"simple-routing\"\u003eSimple Routing\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#simple-routing\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eSimple routing supports 1 record per name\u003c/li\u003e\n\u003cli\u003eEach record can have multiple values\u003c/li\u003e\n\u003cli\u003eSimple routing should be used when you want to route request to one single service e.g a web server\u003c/li\u003e\n\u003cli\u003eIt doesn't support health checks\u003c/li\u003e\n\u003cli\u003esimple to implement and manage\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"r53-health-checks\"\u003eR53 Health Checks\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#r53-health-checks\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eSeparate from but are used by records in route 53\u003c/li\u003e\n\u003cli\u003ePerformed by a fleet of health checkers distributed globally\u003c/li\u003e\n\u003cli\u003eNot limited to just AWS targets - can check anything that is accessible by IP\u003c/li\u003e\n\u003cli\u003eCheck every 30s but can be every 10s (cost extra)\u003c/li\u003e\n\u003cli\u003eTest TCP, HTTP/HTTPS, HTTP/HTTPS with string matching\u003c/li\u003e\n\u003cli\u003eAn endpoint is either healthy or unhealthy\u003c/li\u003e\n\u003cli\u003eTypes of checks: Endpoint, Cloudwatch Alarm, checks of checks\u003c/li\u003e\n\u003cli\u003eif 18%+ of distributed checkers report a healthy then the health check is healthy\u003c/li\u003e\n\u003cli\u003eCommonly uses s3 as a back up\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"failover-routing\"\u003eFailover Routing\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#failover-routing\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eYou can add a backup/failure resource with the inclusion of a health check on the primary record\u003c/li\u003e\n\u003cli\u003eUse this when you want to configure active-passive failover\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"multi-value-routing\"\u003eMulti value routing\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#multi-value-routing\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA mix of simple and failover\u003c/li\u003e\n\u003cli\u003eCan create many records with the same name\u003c/li\u003e\n\u003cli\u003eEach record can have an associated health check\u003c/li\u003e\n\u003cli\u003eUp to 8 healthy records are randomly selected\u003c/li\u003e\n\u003cli\u003eClient chooses and uses 1 value\u003c/li\u003e\n\u003cli\u003eAny failed health check records won't be returned\u003c/li\u003e\n\u003cli\u003eMore of an active-active method\u003c/li\u003e\n\u003cli\u003eNot a replacement for a load balancer\u003c/li\u003e\n\u003cli\u003eImproves availability of an application\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"weighted-routing\"\u003eWeighted Routing\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#weighted-routing\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA simple form of load balancing\u003c/li\u003e\n\u003cli\u003eYou're able to specify a weight for each record\u003c/li\u003e\n\u003cli\u003eThe total weight is calculated for a given name\u003c/li\u003e\n\u003cli\u003eA record with the weight of 0 never gets returned\u003c/li\u003e\n\u003cli\u003eEach record is returned based on it's record weight vs total weight\u003c/li\u003e\n\u003cli\u003eIf a record returned is unhealthy, it repeats until a healthy record is chosen\u003c/li\u003e\n\u003cli\u003eUseful for when you have records with the same name and want to test the distribution\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"latency-routing\"\u003eLatency Routing\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#latency-routing\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eWhen you want to optimise for performance and user experience\u003c/li\u003e\n\u003cli\u003eFor each of the records with the same name, you can use different regions\u003c/li\u003e\n\u003cli\u003eIn the background, aws maintains a latency between different regions\u003c/li\u003e\n\u003cli\u003eA record that has the lowest latency based on region is chosen for a user\u003c/li\u003e\n\u003cli\u003eIf a record is unhealthy then the second lowest latency is returned\u003c/li\u003e\n\u003cli\u003eThe database AWS maintains is not real time\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"geolocation-routing\"\u003eGeolocation Routing\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#geolocation-routing\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eSimilar to latency except the location of customers and resources is the influencing factor\u003c/li\u003e\n\u003cli\u003eWith geolocation routing, records are tagged with a location e.g. country, continent or default\u003c/li\u003e\n\u003cli\u003eWhen a user is making a request, the IP check verifies the location of the user. Then the relevant record is returned (not the closest) - it checks the state first, the country next and then the continent. Optionally it returns the default you defined. If there is no default then a NO ANSWER is returned.\u003c/li\u003e\n\u003cli\u003eThis is ideal for restricting content e.g. to the usa only\u003c/li\u003e\n\u003cli\u003eFor language specific content or balancing across regional locations\u003c/li\u003e\n\u003cli\u003eThis is about location not proximity. E.G. if you're not based in a specific state the record is defined for in the state, then you wont get that record\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"geoproximity\"\u003eGeoproximity\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#geoproximity\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eAims to return records as close to your users as possible\u003c/li\u003e\n\u003cli\u003eRecords can be tagged by AWS region or lat and long coordinates\u003c/li\u003e\n\u003cli\u003eAllows us to define a bias - how route 53 handles a calculation .e.g + - bias where \"+\" increases the region size and \"-\" decreases neighbouring regions\u003c/li\u003e\n\u003cli\u003eBias expands/shrinks the region to direct traffic to\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"r53-interoperability\"\u003eR53 Interoperability\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#r53-interoperability\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eUsing route 53 to register domain or host domain files when the other part of that is not with route 53\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eUsually these things are done together with Route 53 but it can do one or the other\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eWhen you register a domain with route 53 it does two jobs: \u003cem\u003edomain registrar\u003c/em\u003e and \u003cem\u003edomain hosting\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIt can do BOTH or either\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIf you register a domain using route 53\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eit accepts your money (domain registration fee)\u003c/li\u003e\n\u003cli\u003eallocates 4 x Name Servers (domain hosting)\u003c/li\u003e\n\u003cli\u003eCreates a zone file (domain hosting) on the NS servers\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eDomain registration:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eR53 communicates with the registry of TLD (domain registrar)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003etypically r53 doesn't isn't just used as a domain registar but sometimes used purely for hosting where the domain is registered via a 3rd party\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"implementing-dnssec-using-route53\"\u003eImplementing DNSSEC using Route53\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#implementing-dnssec-using-route53\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eDNSSEC strengthens authentication in DNS using digital signatures based on public key cryptography.\u003c/li\u003e\n\u003cli\u003eAsymmetric keys are created in the us-east-1 region (Using KMS)\u003c/li\u003e\n\u003cli\u003eRoute53 creates the zone signing keys internally (KMS isn't involved)\u003c/li\u003e\n\u003cli\u003eAdds the key signing key and zone signing key public parts within a DNS record\u003c/li\u003e\n\u003cli\u003eCloudwatch alarms should be enabled for DNSECInternalFailure or KeySigningKeysNeedingAttention\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"relational-database-service-rds\"\u003eRelational Database Service (RDS)\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#relational-database-service-rds\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003ch3 id=\"database-refresher--models---part1\"\u003eDatabase Refresher \u0026#x26; MODELS - PART1\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#database-refresher--models---part1\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eRelational (SQL) vs Non-Relational (NoSQL)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSQL - Structured Query Language\u003c/li\u003e\n\u003cli\u003eRelational - structure in and between tables of data - Rigid Schema\u003c/li\u003e\n\u003cli\u003eFixed relationship between tables and defined in advance\u003c/li\u003e\n\u003cli\u003eNoSQL - is not one single thing - it covers alternative database models\u003c/li\u003e\n\u003cli\u003eThey have a more relaxed schema and relationships between tables is handled differently\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"database-refresher--models---part2\"\u003eDatabase Refresher \u0026#x26; MODELS - PART2\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#database-refresher--models---part2\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eExamples of nosql/non-relational DB models:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eKey Value databases consist of sets of keys and values.\u003c/li\u003e\n\u003cli\u003eunstructured and are key/value pairs\u003c/li\u003e\n\u003cli\u003egood for simple data, no structure, name/value pairs\u003c/li\u003e\n\u003cli\u003eGood for in-memory caching\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWide Column Store\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA variation on key value\u003c/li\u003e\n\u003cli\u003eyou can have additional keys as well as a partition key\u003c/li\u003e\n\u003cli\u003eDynamoDB uses this\u003c/li\u003e\n\u003cli\u003eHas tables which are groupings of data\u003c/li\u003e\n\u003cli\u003etables containing attributes but they don't have to be the same. It can have all of the same attributes or a mixture or none\u003c/li\u003e\n\u003cli\u003eNo fixed structure on the attribute side\u003c/li\u003e\n\u003cli\u003eEvery item has to use the same key structure and needs to include a key that is unique\u003c/li\u003e\n\u003cli\u003eDynamoDB is a wide column store\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eDocument\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eStore and query data as documents\u003c/li\u003e\n\u003cli\u003eFormatted using json or XML and can have different structure within the same DB\u003c/li\u003e\n\u003cli\u003eInteracted with via it's ID\u003c/li\u003e\n\u003cli\u003eWork best for order or collections or contact style DB\u003c/li\u003e\n\u003cli\u003eGood for deep attributes within a nested structure i.e. orders or contacts\u003c/li\u003e\n\u003cli\u003eHave flexible indexing for deep nested data\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eColumn\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRow based DBs are when you interact with data based on rows\u003c/li\u003e\n\u003cli\u003eRows are ideal when you operate on rows\u003c/li\u003e\n\u003cli\u003eColumn stores data in columns i.e. a grouping column for orderID, Product, Color Size\u003c/li\u003e\n\u003cli\u003eGood for reporting where you need a particular column\u003c/li\u003e\n\u003cli\u003eAn AWS column db is RedShift\u003c/li\u003e\n\u003cli\u003eColumn db is great for reporting and analytics\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eGraph\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eGood for social media or HR systems\u003c/li\u003e\n\u003cli\u003eCan store complex relationships between data\u003c/li\u003e\n\u003cli\u003eQuicker for running queries on relationships\u003c/li\u003e\n\u003cli\u003eRelationships are fluid and dynamic and are stored along the data\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"acid-vs-base\"\u003eACID vs BASE\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#acid-vs-base\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eDatabase transaction models\u003c/li\u003e\n\u003cli\u003eCAP Theorem - consistency, availability and partition tolerance - choose 2\n\u003cul\u003e\n\u003cli\u003eConsistency means it will receive the most recent write otherwise an error\u003c/li\u003e\n\u003cli\u003eAvailability - every request will receive a response but it may not be the most recent write\u003c/li\u003e\n\u003cli\u003ePartition tolerance - can be made of multiple network partitions and continues to operates even if there is a drop of packets\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eACID\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAtomic - all of the transaction parts must be successful otherwise none are\u003c/li\u003e\n\u003cli\u003eConsistent - transactions move the db from one valid state to another - no in between state is allowed\u003c/li\u003e\n\u003cli\u003eIsolated - concurrent executions leave the db in the same state as if they were executed sequentially\u003c/li\u003e\n\u003cli\u003eDurable - once a transaction has been committed, it will remain so even in the event of a system failure\u003c/li\u003e\n\u003cli\u003eGenerally refers to RDS DB and it limits a database to scale\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBASE\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eBasically available - R/W operations are available as much as possible but without any consistency guarantees\u003c/li\u003e\n\u003cli\u003eSoft state - the DB doesn't enforce consistency, it's offloaded to the developer\u003c/li\u003e\n\u003cli\u003eEventually consistent - if we wait long enough, reads from a system will be consistent\u003c/li\u003e\n\u003cli\u003ehighly scalable and performant\u003c/li\u003e\n\u003cli\u003eDynamo DB usually works in a BASE like way but does offer consistent reads and other ACID functionality\u003c/li\u003e\n\u003cli\u003etypically no-sql and acid mentioned together would be referring to a dynamo db database\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"databases-on-ec2\"\u003eDatabases on EC2\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#databases-on-ec2\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eRunning databases directly on EC2 is considered bad practice\u003c/li\u003e\n\u003cli\u003eThere may be some small scenarios where it may benefit\u003c/li\u003e\n\u003cli\u003eThere needs to be reliable communication between your app and DB\nWhy you might do it:\u003c/li\u003e\n\u003cli\u003eAccess to the DB Instance OS\u003c/li\u003e\n\u003cli\u003eAdvanced DB Option tuning - you don't have these with managed DBs but AWS does allow you to control them without root access in managed DBs\u003c/li\u003e\n\u003cli\u003eThe app vendor might require it\u003c/li\u003e\n\u003cli\u003eDB or DB version which AWS doesn't provide\u003c/li\u003e\n\u003cli\u003especific OS/DB combination that AWS doesn't provide\u003c/li\u003e\n\u003cli\u003eArchitecture AWS don't provide\u003c/li\u003e\n\u003cli\u003eDecision makers just want it\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWhy you shouldn't:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eadmin overhead - managing EC2 and DBHost/server\u003c/li\u003e\n\u003cli\u003eBackup / DR management adds additional complexity\u003c/li\u003e\n\u003cli\u003eEC2 is single AZ - access to DB can fail\u003c/li\u003e\n\u003cli\u003eFeatures - AWS DB products have a extensive features which achieve more than what can be done in an ec2 instance\u003c/li\u003e\n\u003cli\u003eEC2 is on or off - no serverless so you can't scale up or down easily\u003c/li\u003e\n\u003cli\u003eReplication - admin overhead\u003c/li\u003e\n\u003cli\u003eperformance - aws has advanced performance features for managed DBs\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"relational-database-service-rds-architecture\"\u003eRelational Database Service (RDS) Architecture\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#relational-database-service-rds-architecture\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eRDS is a 'Database server as a service' product\u003c/li\u003e\n\u003cli\u003eOn this database server/instance you can have multiple databases\u003c/li\u003e\n\u003cli\u003eYou don't have to run installation or maintenance\u003c/li\u003e\n\u003cli\u003eChoice of mysql, mariaDB, postgresSQL, oracle, Microsoft SQL server\u003c/li\u003e\n\u003cli\u003eAmazon aurora is a different product\u003c/li\u003e\n\u003cli\u003eManaged service - you do not have access to OS or SSH access - there is an RDS custom where you could do this\u003c/li\u003e\n\u003cli\u003eRuns within a VPC - it's not a global service\u003c/li\u003e\n\u003cli\u003eEvery RDS instance has it's own dedicated storage (EBS)\u003c/li\u003e\n\u003cli\u003eData is replicated to the standby DB instances in different AZs\u003c/li\u003e\n\u003cli\u003eBackups occur to S3 but you don't see it within your account\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eCosts:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ebilled based on instance size and type\u003c/li\u003e\n\u003cli\u003eMulti az or not\u003c/li\u003e\n\u003cli\u003eper gig monthly fee for storage - storage type and amount\u003c/li\u003e\n\u003cli\u003edata transferred I/O\u003c/li\u003e\n\u003cli\u003ebackups \u0026#x26; snapshots - the same amount as storage is free but any more comes with a cost\u003c/li\u003e\n\u003cli\u003eany extra costs based on licensing if applicable\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"relational-database-service-rds-multiaz---instance-and-cluster\"\u003eRelational Database Service (RDS) MultiAZ - Instance and Cluster\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#relational-database-service-rds-multiaz---instance-and-cluster\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eHistorically, the only way to provide high availability to RDS is via multi az. This meant the primary rds instance replicates across AZs:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eall access to DB is via the CNAME - with multi az you still only access the primary instance\u003c/li\u003e\n\u003cli\u003edata is written to primary and immediately replicated to standby\u003c/li\u003e\n\u003cli\u003enot included in free tier\u003c/li\u003e\n\u003cli\u003eyou get one standby replica only - it cannot be used for reads or writes, it's used for failover\u003c/li\u003e\n\u003cli\u003e60-120 seconds for failover\u003c/li\u003e\n\u003cli\u003ecan only be within the same region\u003c/li\u003e\n\u003cli\u003ebackups can be taken from standby replica to improve performance\u003c/li\u003e\n\u003cli\u003efailures can occur for various different reasons - AZ outage, primary failure, manual failover, instance type change and software patching\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eMulti az cluster architecture:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eone writer can replicate to two reader instances (different AZs) - in RDS you can only have 2 and in aurora you can have more\u003c/li\u003e\n\u003cli\u003ethe primary instance can be used for reads and writes and the replicas can be used for reads\u003c/li\u003e\n\u003cli\u003eruns on much faster hardware\u003c/li\u003e\n\u003cli\u003efast writes to local storage and flushed to EBS\u003c/li\u003e\n\u003cli\u003ereaders can be used to scale reading\u003c/li\u003e\n\u003cli\u003ereplication is done via transaction logs which is more efficient\u003c/li\u003e\n\u003cli\u003efailover is fast = ~35 seconds + transaction log apply\u003c/li\u003e\n\u003cli\u003ewrites are viewed as committed when 1 reader has confirmed that it's written\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"rds-automatic-backup-rds-snapshots-and-restore\"\u003eRDS Automatic Backup, RDS Snapshots and Restore\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#rds-automatic-backup-rds-snapshots-and-restore\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eTwo types of backup functionality:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eAutomated backups\u003c/li\u003e\n\u003cli\u003esnapshots\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003eboth stored in AWS managed s3 buckets - you won't be able to see them in s3\u003c/li\u003e\n\u003cli\u003ebecause it's in s3, it's regionally resilient\u003c/li\u003e\n\u003cli\u003eRDS can replicate backups to another region\u003c/li\u003e\n\u003cli\u003echarges apply for cross-region data copy and storage in the destination region - this is not the default you have to explicitly enable it\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSnapshots:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003esnapshots must be run explicitly, they're not automatic\u003c/li\u003e\n\u003cli\u003etaken of the instance so all the DBs within it\u003c/li\u003e\n\u003cli\u003esnapshots are incremental i.e. they only store the difference between previous\u003c/li\u003e\n\u003cli\u003esnapshots don't expire and live beyond the instance\u003c/li\u003e\n\u003cli\u003eif you use a single AZ there will be an IO pause, with multiple it will happen with the standby\u003c/li\u003e\n\u003cli\u003etransaction logs will also be stored in the s3 every 5 minutes\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eautomated backup\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eautomatically cleaned up - min 0 days to 35 days\u003c/li\u003e\n\u003cli\u003eyou can choose to retain automated backups - but they still expire based on retention period\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eRestores:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCreates a new RDS instance - it will use a new endpoint address\u003c/li\u003e\n\u003cli\u003erestoring snapshots aren't fast\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"rds-read-replicas\"\u003eRDS Read-Replicas\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#rds-read-replicas\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eRead only replicas of an RDS instance. They can be in the same or cross-region\u003c/li\u003e\n\u003cli\u003eRead replicas are not part of the main database instance in any way - applications need to be adjusted to use them - Without app support, they don't do anything\u003c/li\u003e\n\u003cli\u003eKept in sync using asynchronous synchronisation\u003c/li\u003e\n\u003cli\u003ecan create 5x direct read replicas per DB instance\u003c/li\u003e\n\u003cli\u003eeach providing an additional instance of read performance\u003c/li\u003e\n\u003cli\u003eread replicas can have read replicas but lag starts to be a problem\u003c/li\u003e\n\u003cli\u003ecan help with global performance improvements\u003c/li\u003e\n\u003cli\u003ebenefit in recover point objectives (RPOS) with frequent snapshot and backups - limits the amount of data lost\u003c/li\u003e\n\u003cli\u003ertos are a problem as it takes a long time\u003c/li\u003e\n\u003cli\u003eRR offer a near 0 RPO - very little potential for data loss\u003c/li\u003e\n\u003cli\u003eCan be promoted quickly - low RTO\u003c/li\u003e\n\u003cli\u003eread replicas should only be used on failure only - not for data corruption\u003c/li\u003e\n\u003cli\u003eread only until they're promoted\u003c/li\u003e\n\u003cli\u003egreat for global availability improvements due to global resilience\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"rds-data-security\"\u003eRDS Data Security\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#rds-data-security\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eSSL/TLS (in transit) is available for RDS and can be mandatory\u003c/li\u003e\n\u003cli\u003eRDS supports EBS volume encryption - KMS encryption\u003c/li\u003e\n\u003cli\u003eThis is handled by Host or DBS\u003c/li\u003e\n\u003cli\u003eAWS or customer managed CMK generates data encryption keys (DEKs) used for encryption operations\u003c/li\u003e\n\u003cli\u003estorage, logs, snapshots \u0026#x26; replicas are all encrypted by the same master key\u003c/li\u003e\n\u003cli\u003eencryption cannot be removed once it's added\u003c/li\u003e\n\u003cli\u003eRDS MSSQL and RDS Oracle support TDE - transparent data encryption - it's handled by the DB engine\u003c/li\u003e\n\u003cli\u003eRDS oracle supports integration with cloud HSM - managed by you with no key exposure with AWS\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIAM Authentication:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRDS can be configured to use IAM user authentication to a DB\u003c/li\u003e\n\u003cli\u003eYou have IAM users and roles with attached policies - tokens are generated with a 15 minute validity - you won't need a password\u003c/li\u003e\n\u003cli\u003ethis is only authentication NOT authorization - authorization is controlled by the DB engine\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"rds-custom\"\u003eRDS Custom\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#rds-custom\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eFills the gap between RDS and EC2 running a DB engine\u003c/li\u003e\n\u003cli\u003eWorks for MSSQL and oracle\u003c/li\u003e\n\u003cli\u003ecan connect using SSH, RDP, Session Manager\u003c/li\u003e\n\u003cli\u003eRDS Custom gives you the benefits of using the RDS product combined with the ability to customise instances\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"aurora-architecture\"\u003eAurora Architecture\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#aurora-architecture\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eAurora is very different from RDS\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eUses a cluster\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eMade up of a single primary instance and 0 or more replicas\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eReplicas are used for reads for normal operations - you don;t have to choose between read scaling and availability\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eDoes not use local storage, uses shared cluster volume\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThis provides faster provisioning, improved availability and better performance\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHas a max cluster volume of 128 TiB\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eReplication happens at the storage level so no extra resources are consumed from the instances\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eBecause storage is across 3 AZs, availability of storage is much higher\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eAurora avoids data lost and reduces any point in time restores - more resilient than RDS\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eAUrora can have up to 15 replicas and any of them can be failover\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eFailover is quicker because there are no storage modifications\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eCluster shared volume is SSD by default - high IOPS/low latency\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eBilling - based on what storage you consume\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ehigh water mark billing - e.g. billed for the most used storage in a cluster - this is being changed by AWS but for now this is the architecture\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ereplicas can be added and removed without requiring storage provisioning\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eAurora has a cluster endpoint (points at primary) and reader endpoint (at any replica or primary) - you can also create custom endpoints and there are unique end points per replica\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eCost - there is no free tier option - it doesn't support micro instances\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eAnything beyond RDS Single AZ (micro) aurora offers a better value\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ecompute is charged hourly and you're billed per second at a 10 minute minimum\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003estorage is GB month consumed at a high watermark. Theres also an IO cost per request\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e100% DB Size in backups are included in your cost\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eBackups in aurora work the same way as RDS\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eRestores create a brand new cluster\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eBacktrack can be used to rollback DB to a previous point in time - as opposed to a full restore\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eYou can create a fast clone to create a new database - it references the original storage and stores differences between the two\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"aurora-serverless\"\u003eAurora Serverless\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#aurora-serverless\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eProvides a version of the aurora product where you don't have to worry about provisioning a server or DB instances\u003c/li\u003e\n\u003cli\u003eThe non-serverless version of aurora is often known as 'aurora provisioned'\u003c/li\u003e\n\u003cli\u003eYou don't need to provision resources the same way as auroro provisioned\u003c/li\u003e\n\u003cli\u003eUses ACU - aurora capacity units\u003c/li\u003e\n\u003cli\u003eHave a min and max ACU\u003c/li\u003e\n\u003cli\u003eCluster adjusts based on load\u003c/li\u003e\n\u003cli\u003eCan go to 0 and be paused\u003c/li\u003e\n\u003cli\u003eBilled on consumption per-second\u003c/li\u003e\n\u003cli\u003esame resilience as aurora (6 copies across azs)\u003c/li\u003e\n\u003cli\u003eMuch simpler, removes complexity, easy to scale\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eDifferences:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSame cluster volume architecture\u003c/li\u003e\n\u003cli\u003eInstead of provisioned servers - ACUs - provided from a warm pool of capacity units\u003c/li\u003e\n\u003cli\u003eThey have no local storage\u003c/li\u003e\n\u003cli\u003eOnce allocated, they have access to the cluster storage\u003c/li\u003e\n\u003cli\u003einteracting with the aurora cluster happens through a 'proxy fleet' - it doesn't connect directly to the units\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eUse cases:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eInfrequently used - eg low volume blog site.\u003c/li\u003e\n\u003cli\u003eNew applications - where you're unsure of the levels of load\u003c/li\u003e\n\u003cli\u003eVariable workloads - an application that has peaks and troughs\u003c/li\u003e\n\u003cli\u003eUnpredictable workloads\u003c/li\u003e\n\u003cli\u003eDevelopment and test databases\u003c/li\u003e\n\u003cli\u003emulti-tenant applications\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"aurora-global-database\"\u003eAurora Global Database\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#aurora-global-database\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA feature of aurora provisioned clusters which allow data to be replicated globally\u003c/li\u003e\n\u003cli\u003eIntroduce the concept of secondary regions which can have up to 16 replicas. They are all read only.\u003c/li\u003e\n\u003cli\u003eReplica occurs at the storage layer and its typically a 1s replication between regions - it's one way between primary and secondary\u003c/li\u003e\n\u003cli\u003eYou would use these for:\n\u003cul\u003e\n\u003cli\u003ecross region disaster recovery and business continuity\u003c/li\u003e\n\u003cli\u003eGlobal read scaling - low latency\u003c/li\u003e\n\u003cli\u003ereplication has no impact on DB performance\u003c/li\u003e\n\u003cli\u003eSecondary can be promoted to read write\u003c/li\u003e\n\u003cli\u003ecurrently max 5 secondary regions\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"multi-master-writes\"\u003eMulti-master writes\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#multi-master-writes\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA write mode of aurora provisioned clusters which allows multiple instances to perform reads and writes at the same time rather than only one primary instance having write capability\u003c/li\u003e\n\u003cli\u003eDefault aurora mode is a Single-Master - one R/W and 0+ read only replicas\u003c/li\u003e\n\u003cli\u003eFailover takes time to replicate to promote\u003c/li\u003e\n\u003cli\u003eIn multi-master all clusters are R/W\u003c/li\u003e\n\u003cli\u003eThere is no load-balancing cluster endpoint to use, the app is responsible to connecting to instances\u003c/li\u003e\n\u003cli\u003eWhen a r/w node receives data, it commits to all storage in cluster. It either rejects or accepts the change depending on the in-flight data - it must agree with the other nodes\u003c/li\u003e\n\u003cli\u003eWith multi-master cluster - the change is also replicated to other nodes in the cluster (replication in in-memory caches)\u003c/li\u003e\n\u003cli\u003eThe application logic needs to manually load balance across the cluster instances\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"relational-database-service-rds---rds-proxy\"\u003eRelational Database Service (RDS) - RDS Proxy\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#relational-database-service-rds---rds-proxy\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eWhy use:\n\u003cul\u003e\n\u003cli\u003eOpening/closing connections to DB takes time\u003c/li\u003e\n\u003cli\u003ehandling failure of DB instances is hard\u003c/li\u003e\n\u003cli\u003eDB proxies change your architecture, you connect to the proxy and it maintains open connections for you in the long term\u003c/li\u003e\n\u003cli\u003eApplications =\u003e Proxy (connection pooling) =\u003e Database\u003c/li\u003e\n\u003cli\u003eReduces too many connection errors\u003c/li\u003e\n\u003cli\u003eSmaller/burst instances\u003c/li\u003e\n\u003cli\u003eAWS Lambda - time saved connecting\u003c/li\u003e\n\u003cli\u003eLong running connections (SAAS Apps)\u003c/li\u003e\n\u003cli\u003eResilience to DB failure is a priority - can reduce the time for failover and make it transparent to the application as it's going through the proxy\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eKey facts:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFully managed DB Proxy for RDS/Aurora\u003c/li\u003e\n\u003cli\u003eAuto scaling, highly available by default\u003c/li\u003e\n\u003cli\u003eprovides connection pooling reducing DB load\u003c/li\u003e\n\u003cli\u003eonly accessible within a VPC\u003c/li\u003e\n\u003cli\u003eaccessed via a proxy endpoint - no app changes\u003c/li\u003e\n\u003cli\u003ecan enforce SSL/TLS\u003c/li\u003e\n\u003cli\u003ereduce failover time by over 60% for aurora\u003c/li\u003e\n\u003cli\u003eabstracts failure of DB away from the application\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"database-migration-service-dms\"\u003eDatabase Migration Service (DMS)\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#database-migration-service-dms\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA managed service which allows for 0 data loss, low or 0 downtime migration between 2 database endpoints\u003c/li\u003e\n\u003cli\u003eRuns a replication instance\u003c/li\u003e\n\u003cli\u003eSource and destination endpoints where one must be on AWS\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSCT (Schema Conversion Tool):\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA standalone tool when converting one database engine to another including DB -\u003e S3\u003c/li\u003e\n\u003cli\u003eNot used for movements of data between compatible engines\u003c/li\u003e\n\u003cli\u003edifferent engines e.g. on premiss MSQL - RDS MYSQL\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eDMS + Snowball:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eLarger migrations (multi TB)\u003c/li\u003e\n\u003cli\u003eDMS Can use snowball products (Uses schema conversion tool). You move data to a snowball device and ship it back to AWS to perform the migration\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"network-storage--data-lifecycle\"\u003eNetwork Storage \u0026#x26; Data Lifecycle\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#network-storage--data-lifecycle\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003ch3 id=\"efs-architecture\"\u003eEFS Architecture\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#efs-architecture\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eElastic File System (EFS)\u003c/li\u003e\n\u003cli\u003eProvides network based file systems which can be mounted and used by multiple instances at once\u003c/li\u003e\n\u003cli\u003eImplementation of NFSv4\u003c/li\u003e\n\u003cli\u003eCan be mounted on Linux instances (Linux only)\u003c/li\u003e\n\u003cli\u003eShared between many EC2 instances\u003c/li\u003e\n\u003cli\u003eExists separately from the EC2 instance\u003c/li\u003e\n\u003cli\u003ePrivate service and accessed via mount targets inside a VPC\u003c/li\u003e\n\u003cli\u003eCan be accessed on premiss via VPN or DX\u003c/li\u003e\n\u003cli\u003eOffers general purpose and Max I/O performance mode\u003c/li\u003e\n\u003cli\u003eGeneral purpose is default and good for 99.9% of uses\u003c/li\u003e\n\u003cli\u003eBursting and provisioned throughput modes (pick bursting generally)\u003c/li\u003e\n\u003cli\u003eStandard (default) and Infrequent Access (IA) classes\u003c/li\u003e\n\u003cli\u003eLifecycle policies can be used with classes\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"aws-backup\"\u003eAWS Backup\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#aws-backup\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003efully managed data protection service (backup/restore)\u003c/li\u003e\n\u003cli\u003eConsolidate management of data into one place - across accounts and across regions\u003c/li\u003e\n\u003cli\u003eSupports a wide range of AWS products - Compute, block storage, file storage, databases, object storage\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eKey concepts:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eBackup plans - frequency, window, lifecycle, vault, region copy\u003c/li\u003e\n\u003cli\u003eBackup resources - what resources are backed up\u003c/li\u003e\n\u003cli\u003eVaults - destination (container) - assign a KMS key for encryption\u003c/li\u003e\n\u003cli\u003eVault lock - write once read many (WORM) - No one, including AWS can delete anything from the vault after 72 hour cool off\u003c/li\u003e\n\u003cli\u003eOn demand - manual backups created as needed\u003c/li\u003e\n\u003cli\u003ePITR - point in time recovery\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"ha--scaling\"\u003eHA \u0026#x26; SCALING\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#ha--scaling\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003ch3 id=\"regional-and-global-aws-architecture\"\u003eRegional and Global AWS Architecture\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#regional-and-global-aws-architecture\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eArchitectural components to consider:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eGlobal service location and discovery\u003c/li\u003e\n\u003cli\u003eContent delivery (CDN) and optimisation\u003c/li\u003e\n\u003cli\u003eGlobal health checks and failover\u003c/li\u003e\n\u003cli\u003eRegional entry point\u003c/li\u003e\n\u003cli\u003eRegional scaling and resilience\u003c/li\u003e\n\u003cli\u003eApplication services and components\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eNetflix can be thought of as a global application also made up of blocks of regional services:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eUses a global DNS for service/discovery (R53)\u003c/li\u003e\n\u003cli\u003eCDN layer at a global level (cloudfront)\u003c/li\u003e\n\u003cli\u003eOnce a region is entered, user enters via web tier at the regional level\u003c/li\u003e\n\u003cli\u003eWeb tier talks to compute tier eg ec2, lambda\u003c/li\u003e\n\u003cli\u003ecompute tier consumes storage services e.g. EFS, S3\u003c/li\u003e\n\u003cli\u003etalks to DB tier\u003c/li\u003e\n\u003cli\u003eSometimes gets data via caching layer\u003c/li\u003e\n\u003cli\u003eApp services are used like SNS, Queues\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"evolution-of-the-elastic-load-balancer\"\u003eEvolution of the Elastic Load Balancer\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#evolution-of-the-elastic-load-balancer\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eThree different types of ELBS split between v1 (avoid this) and v2 (prefer)\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eClassic load Balancer (CLB) - v1 - not really layer 7 devices and lack advanced functionality - can only use 1 SSL cert per load balancer. Default to NOT using this\u003c/li\u003e\n\u003cli\u003eApplication Load Balancer (ALB) - v2 - layer 7 devices that support HTTP/S/Websocket\u003c/li\u003e\n\u003cli\u003eNetwork Load Balancer (NLB) - v2 - TCP, TLS \u0026#x26; UDP - good for any load balancing of anything that's not using HTTP(s)\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003ev2 = faster, cheaper and support target groups and rules\nIn exam you should be able to choose between ALB and NLB\u003c/p\u003e\n\u003ch3 id=\"elastic-load-balancer-architecture\"\u003eElastic Load Balancer Architecture\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#elastic-load-balancer-architecture\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eAccepts connections from customers and distributes them\u003c/li\u003e\n\u003cli\u003eWhen you provision a load balancer, you need to select which AZs it goes into and you do this by selecting ONE subnet in each AZ\u003c/li\u003e\n\u003cli\u003eEach ALB is configured with an A record DNS name which resolves to the ELB nodes\u003c/li\u003e\n\u003cli\u003eYou must decide whether the ELB is internet facing or internal - if it's public facing then the ELB nodes have public and private IPs where as internal will only have private\u003c/li\u003e\n\u003cli\u003eLBs need at least 8+ free IPs per subnet - you should use a /27 or larger subnet to allow for scale\u003c/li\u003e\n\u003cli\u003eInternal LBs are usually used to separate application tiers\u003c/li\u003e\n\u003cli\u003ewithout LBs, the tiers need to have awareness of each other and they need to connect to specific instances. Tiers can then scale independently on each other\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eCross zone load balancing - allows each load balancer node to distribute connections evenly between all instances across availability zones. This is enabled as standard in load balancers. Without this, if you have two load balancer nodes and one zone has more instances than the other, the nodes in that instance will get a smaller distribution of traffic as opposed to the other zone.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eWhen you provision as an ELB, you see a DNS A record pointing at 1+ Nodes per AZ\u003c/li\u003e\n\u003cli\u003eNodes in one subnet per AZ can scale\u003c/li\u003e\n\u003cli\u003eEC2 doesn't need to be public to work with an internet facing load balancer\u003c/li\u003e\n\u003cli\u003eLoad balancers are configured by listener configuration which controls what it should listen to\u003c/li\u003e\n\u003cli\u003e8+ free IPs per subnet /28 is enough but AWS docs recommend /27 for scaling\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"application-load-balancing-alb-vs-network-load-balancing-nlb\"\u003eApplication Load balancing (ALB) vs Network Load Balancing (NLB)\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#application-load-balancing-alb-vs-network-load-balancing-nlb\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eConsolidation of LBs:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eClassic load balancers don't scale because each unique https name requires an individual CLB (1 SSL per CLB)\u003c/li\u003e\n\u003cli\u003ev2 load balancers support rules and target groups\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eApplication load balancer (ALB):\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eLayer 7 which listens on HTTP/S\u003c/li\u003e\n\u003cli\u003eCan't understand any other layer 7 protocols e.g. SMTP, SSH, Gaming, TCP, UDP, TLS\u003c/li\u003e\n\u003cli\u003eCan understand l7 content e.g. cookies, custom headers, user location and app behaviour (protocol info)\u003c/li\u003e\n\u003cli\u003eAny incoming connections are always terminated on the ALB - you can't have an unbroken SSL connection\u003c/li\u003e\n\u003cli\u003eA new connection is made to the application\u003c/li\u003e\n\u003cli\u003eALBs MUST have SSL certs if HTTPs is used\u003c/li\u003e\n\u003cli\u003eSlower than NLB as they are more levels of network stack to process\u003c/li\u003e\n\u003cli\u003eThey can evaluate application health\u003c/li\u003e\n\u003cli\u003eHave the concept of rules\u003c/li\u003e\n\u003cli\u003eprocessed in priority order\u003c/li\u003e\n\u003cli\u003eDefault rule is catch-all\u003c/li\u003e\n\u003cli\u003eRule conditions - host-header, http-header, request method, path pattern, query string and source IP\u003c/li\u003e\n\u003cli\u003eActions - forward, redirect, fixed-response, authenticate-oidc and incognito\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eNetwork load balancer (NLB):\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFunction at layer 4 - TCP, TLS, UDP, TCP_UDP\u003c/li\u003e\n\u003cli\u003eThey have no visibility or understanding of HTTP or HTTPs\u003c/li\u003e\n\u003cli\u003eThey can't interpet headers, cookies, session sticiness\u003c/li\u003e\n\u003cli\u003eThey're very fast (millions of rps, 25% of ALB latency)\u003c/li\u003e\n\u003cli\u003eIdeal to deal with anything thats not http(s) e.g. game servers, smtp, ssh, financial apps\u003c/li\u003e\n\u003cli\u003eHealth checks only check ICMP/TCP handshake - they're not app aware\u003c/li\u003e\n\u003cli\u003eThey can be allocated with static IPs which is useful for whitelisting\u003c/li\u003e\n\u003cli\u003eThey can forward TCP through to instances - unbroken end to end encryption - it can accept tcp only traffic so any layers above will not be terminated\u003c/li\u003e\n\u003cli\u003eUsed with private link to provide services to other VPCs\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eALB vs NLB:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eUnbroken encryption- NLB\u003c/li\u003e\n\u003cli\u003estatic IP for whitelisting - NLB\u003c/li\u003e\n\u003cli\u003eFastest performing - NLB\u003c/li\u003e\n\u003cli\u003eprotocols that arent http(s) - NLB\u003c/li\u003e\n\u003cli\u003ePrivatelink requirement - NLB\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eotherwise - ALB\u003c/p\u003e\n\u003ch3 id=\"launch-configuration-and-templates\"\u003eLaunch Configuration and Templates\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#launch-configuration-and-templates\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eLC and LT at a high level perform the same task - they allow you to define the configuration of EC2 instances in advance e.g AMI, instance type, storage and keypair, networking and security groups, userdata and IAM role\u003c/li\u003e\n\u003cli\u003eBoth are not editable\u003c/li\u003e\n\u003cli\u003eLT provides newer features - T2/T3 unlimited, placement groups, capacity reservations and elastic graphics\u003c/li\u003e\n\u003cli\u003eLC provide configuration to be used by auto scaling groups - they are not editable nor do they have any versioning\u003c/li\u003e\n\u003cli\u003eLT can be used for the same thing but they can also be used to launch EC2 instances directly\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"auto-scaling-groups\"\u003eAuto-Scaling Groups\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#auto-scaling-groups\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eProvide auto scaling for ec2 and can be used for a self healing architecture\u003c/li\u003e\n\u003cli\u003eThey use launch templates or configurations - always one at a time (one config definition)\u003c/li\u003e\n\u003cli\u003eHas 3 values - minimum, desired and maximum size e.g. (1:2:4)\u003c/li\u003e\n\u003cli\u003eKeeps number of running ec2 instances the same as desired capacity by provisioning and terminating instances\u003c/li\u003e\n\u003cli\u003eScaling policies normally together with auto scaling groups to automate based on metrics\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eScaling policies are rules on ASG:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003emanual scaling - manually adjust the desired capacity\u003c/li\u003e\n\u003cli\u003eschedule scaling - time based adjustment e.g. sales\u003c/li\u003e\n\u003cli\u003edynamic scaling:\n\u003cul\u003e\n\u003cli\u003esimple - e.g. either provision or terminate based on a metric (CPU, memory, disk I/O, length of SQS queue)\u003c/li\u003e\n\u003cli\u003estepped scaling - more +/- which allows you to react quicker\u003c/li\u003e\n\u003cli\u003etarget tracking - desired aggregate e.g.CPU = 40% and ASG handles it\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eCool down period - waits a certain amount of seconds before doing another action\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eASG + Load Balancers:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eASG can use the load balancer health checks rather than EC2 status checks\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eScaling processes:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eLaunch and terminate- SUSPEND and RESUME\u003c/li\u003e\n\u003cli\u003eAddToLoadBalancer - add to LB on launch\u003c/li\u003e\n\u003cli\u003eAlarmNotification -accept notification from CW\u003c/li\u003e\n\u003cli\u003eAZRebalance - Balances instances evenly across AZs\u003c/li\u003e\n\u003cli\u003eHealthcheck - instance health checks on/off\u003c/li\u003e\n\u003cli\u003eReplaceUnhealthy - Terminate unhealthy and replace\u003c/li\u003e\n\u003cli\u003eStandby - use this for instances InService vs Standby - can be used for maintenance\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eFInal points\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eASG are free\u003c/li\u003e\n\u003cli\u003eOnly the resource created are billed, use cool down to avoid rapid scaling\u003c/li\u003e\n\u003cli\u003eThink about more, smaller instances - smaller instances mean more granularity\u003c/li\u003e\n\u003cli\u003eUse ALB for elasticity - abstraction\u003c/li\u003e\n\u003cli\u003eASG defines when and where, LT defines what\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"asg-scaling-policies\"\u003eASG Scaling Policies\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#asg-scaling-policies\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eASGs don't NEED scaling policies - they can have none\u003c/li\u003e\n\u003cli\u003eWIthout policies they have static values\u003c/li\u003e\n\u003cli\u003eManual scaling means manually adjusting min, max desired\u003c/li\u003e\n\u003cli\u003eDynamic scaling:\u003c/li\u003e\n\u003cli\u003eSimple scaling - define actions which occur when alarm moves into alarm state and adds/removes a static amount\u003c/li\u003e\n\u003cli\u003estep scaling - adds and removes based on steps with upper and lower bounds\u003c/li\u003e\n\u003cli\u003eTarget tracking - predefined set of metrics and you define an ideal value, the ASG calculates the scaling for you based on this\u003c/li\u003e\n\u003cli\u003eIt's possible to scale based on SQS - ApproximateNumberOfMessagesVisible - scales up and down based on messages\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"asg-lifecycle-hooks\"\u003eASG Lifecycle hooks\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#asg-lifecycle-hooks\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eAllow you to configure custom actions on instances during ASG actions\u003c/li\u003e\n\u003cli\u003ee.g. during instance launch or instance terminate transitions\u003c/li\u003e\n\u003cli\u003eWhen you create lifecycle hooks, instances are paused and they wait until a timeout and either continue or abandon, alternatively you resume the ASG process\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"asg-healthcheck-comparison---ec2-vs-elb\"\u003eASG HealthCheck Comparison - EC2 vs ELB\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#asg-healthcheck-comparison---ec2-vs-elb\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eThree different types of health checks on ASG:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eEC2 (default), ELB (can be enabled) \u0026#x26; custom\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eEC2 - if anything other than status running then it's viewed as unhealthy\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eELB - instance must be both running and passing ELB health check - this way it can be more application aware\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eCustom - instances marked as healthy and unhealthy by an external system\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eA health check grace period is the amount of time to delay before starting checks (default 300s) - allows system launch and bootstrap. You need to make sure this is a sufficient amount so that instances don't keep terminating and restarting over and over again\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"ssl-offload--session-stickiness\"\u003eSSL Offload \u0026#x26; Session Stickiness\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#ssl-offload--session-stickiness\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eSSL Offload - there are three ways a load balancer can handle secure connections:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003ebridging\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003edefault mode of ELB\u003c/li\u003e\n\u003cli\u003esecure connection between the client and the load balancer - the LB needs an SSL certificate and a domain name that the application uses\u003c/li\u003e\n\u003cli\u003eAWS technically have access to that security certificate\u003c/li\u003e\n\u003cli\u003eIt also creates new encrypted with the backend instances. This means that all the EC2 instances also need an SSL certificate which matches the domain name\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003epositives:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eELB gets to see unecrypted HTTP\nNegatives:\u003c/li\u003e\n\u003cli\u003eCert has to be stored on the ELB itself which is a security risk\u003c/li\u003e\n\u003cli\u003eSSL certs need to be installed on the instances themselves which is an overhead since they need to perform the cryptographic operations\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003epass-through\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003eClient connects but the LB passes it to the backend instance. The LB doesn't need an SSL cert but the backend instances do\u003c/li\u003e\n\u003cli\u003eThis LB must be a network load balancer\u003c/li\u003e\n\u003cli\u003eThe LB is configured to use TCP. AWS never need to see the cert that you use\u003c/li\u003e\n\u003cli\u003eNegative is that you don't get to use load balancing based on the http part.\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003eoffload\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003eClients connect to ELB using HTTPS\u003c/li\u003e\n\u003cli\u003eLB connects to backend instances via HTTP (unencrypted)\u003c/li\u003e\n\u003cli\u003eLB requires SSL but backend instances don't\u003c/li\u003e\n\u003cli\u003edownside is data is in plaintext in backend network\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eConnection stickiness\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIf state is stored on a specific server rather than being stateless, you need session stickiness\u003c/li\u003e\n\u003cli\u003eELBs can pass a cookie to clients which ensures that users are always being passed to a specific server until there is a server failure (in which case the user is sent to a different server) or the cookie expires\u003c/li\u003e\n\u003cli\u003eIt can cause uneven load on the backend servers - apps should be designed to use stateless by moving the session external to the ec2 instance e.g. dynamo DB\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"gateway-load-balancer\"\u003eGateway Load Balancer\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#gateway-load-balancer\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA product which AWS provides to help you run and scale 3rd party security appliances e.g. firewalls, intrusion detection and prevention systems\u003c/li\u003e\n\u003cli\u003eYou can use these for inbound and outbound traffic\u003c/li\u003e\n\u003cli\u003eHas endpoints where traffic enters/leaves - similar to VPC endpoints\u003c/li\u003e\n\u003cli\u003eGWLB balances across multiple backend applications\u003c/li\u003e\n\u003cli\u003eTraffic and metadata is tunnelled using GENEVE protocol\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"serverless-and-application-services\"\u003eSERVERLESS AND APPLICATION SERVICES\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#serverless-and-application-services\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003ch3 id=\"architecture-deep-dive\"\u003eArchitecture Deep Dive\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#architecture-deep-dive\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eMonolithic architecture\u003c/strong\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eis one entity that fails together since they are all contained together\u003c/li\u003e\n\u003cli\u003escales together as they're highly coupled - you need to vertically scale the system\u003c/li\u003e\n\u003cli\u003eBill together and use resources even if they're not running - tends to be the least effective architecture\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eTiered architecture\u003c/strong\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA way to evolve a monolithic architecture - you break it apart and each tier can be on the same server or different\u003c/li\u003e\n\u003cli\u003eStill tightly coupled\u003c/li\u003e\n\u003cli\u003ecan vertically scale each tier independently\u003c/li\u003e\n\u003cli\u003eCan use load balancers between each tier so that there isn't a direct comm between a specific instance\u003c/li\u003e\n\u003cli\u003eCan horizontally scale if load balancer is used between each tier\u003c/li\u003e\n\u003cli\u003ebecause each tier relies on the other, you cannot scale any tier down to 0\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eQueues\u003c/strong\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA tiered architecture can be evolved with a queue\u003c/li\u003e\n\u003cli\u003eA queue based architecture is decoupled - each tier pushes messages onto a queue\u003c/li\u003e\n\u003cli\u003eEach tier doesn't care about other tiers, it uses async comms to wait for messages from the queue\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eMicroservice architecture\u003c/strong\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA way to further break down a monolithic architecture\u003c/li\u003e\n\u003cli\u003emicroservices do individual things e.g. upload, process, store, manage\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eEvent-driven architecture\u003c/strong\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEvents are produced and consumed\u003c/li\u003e\n\u003cli\u003eOnly consume resources as and when required - nothing is constantly running or waiting\u003c/li\u003e\n\u003cli\u003eProducers generate events when something happens e.g. clicks, errors, criteria met, uploads, actions\u003c/li\u003e\n\u003cli\u003eEvents are delivered to consumers (usually using an event router)\u003c/li\u003e\n\u003cli\u003eActions are taken\u003c/li\u003e\n\u003cli\u003eMature event-driven architecture only consumes resources when handling events (key component of serverless architecture)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"aws-lambda\"\u003eAWS Lambda\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#aws-lambda\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eLambda is a Function-as-a-service (FaaS) product - it's a short-running and focussed service\u003c/li\u003e\n\u003cli\u003eA lambda function - a piece of code that lambda runs\u003c/li\u003e\n\u003cli\u003eFunctions use a runtime e.g. python 3.8\u003c/li\u003e\n\u003cli\u003eFunctions are loaded and run in a runtime environment\u003c/li\u003e\n\u003cli\u003eenvironment has direct memory (and virtual CPU e.g. indirect CPU) allocation\u003c/li\u003e\n\u003cli\u003eYou're only billed for the duration the function runs\u003c/li\u003e\n\u003cli\u003eA key part of serverless architectures\u003c/li\u003e\n\u003cli\u003eDocker is an anti-pattern for lambda - this will generally refer to ecs\u003c/li\u003e\n\u003cli\u003eCode loads, executes then terminates\u003c/li\u003e\n\u003cli\u003eLambda functions are stateless so no data is left over from previous invocations - you need to make sure your code works in a new environment\u003c/li\u003e\n\u003cli\u003eThis is the default but there are cases where it's not\u003c/li\u003e\n\u003cli\u003ememory is 128mb to 10240mb - you don't control the CPU, it's according to the memory you get\u003c/li\u003e\n\u003cli\u003e900s (15m) function timeout for each lambda function\u003c/li\u003e\n\u003cli\u003eTypically used in conjunction with other serverless applications e.g. s3, api gateway\u003c/li\u003e\n\u003cli\u003eOften used for things like file processing\u003c/li\u003e\n\u003cli\u003eFor database triggers - dynamo db, streams\u003c/li\u003e\n\u003cli\u003eserverless cron - eventbridge/cwEvents\u003c/li\u003e\n\u003cli\u003ereal time stream data processing - kinesis\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eNetworking\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePublic and VPC networking\u003c/li\u003e\n\u003cli\u003edefault is public networking - can access public space aws services and the internet\u003c/li\u003e\n\u003cli\u003epublic networking offers the best performance because no customer specific vpc networking is required - however they won't have access to vpc based services unless public ips are allocated and security rules allow external access\u003c/li\u003e\n\u003cli\u003elambda functions running in vpc can freely access other vpc resources but nothing outside unless it's specifically configured\u003c/li\u003e\n\u003cli\u003eYou could use a natgateway and internet gateway or a vpc endpoint to be able to talk to anything outside the vpc\u003c/li\u003e\n\u003cli\u003etreat lambdas running in a vpc like anything running in a vpc\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSecurity\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePermissions\n\u003cul\u003e\n\u003cli\u003eexecution role (similar to an ec2 instance role)\u003c/li\u003e\n\u003cli\u003eresource policies - like a bucket policy on s3 to allow external accounts or services to interface with lambda - can only be manipulated with cli or api\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eLambda uses cloudwatch, cloudwatch logs and x-ray\u003c/li\u003e\n\u003cli\u003eCan be integrated with x-ray for distributed tracing\u003c/li\u003e\n\u003cli\u003erequires permissions via execution role in order to log to cloudwatch\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eInvocation\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSynchronous\n\u003cul\u003e\n\u003cli\u003eResult is returned during the request (success/failure). Errors and retries must be handled within the client.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003easynchronous\n\u003cul\u003e\n\u003cli\u003eTypically used when AWS services invoke lambda functions on your behalf\u003c/li\u003e\n\u003cli\u003eFor example, s3 won't wait for a response from lambda and the lambda is responsible for any re-processing\u003c/li\u003e\n\u003cli\u003eThe function code needs to be idempotent\u003c/li\u003e\n\u003cli\u003eAny retries could potentially be sent to a dead letter queue which repeat failed processing\u003c/li\u003e\n\u003cli\u003eLambda supports destinations where successful or failed events can be sent\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eevent source mappings\n\u003cul\u003e\n\u003cli\u003etypically used on streams/queues which don't support events and polling is required\u003c/li\u003e\n\u003cli\u003eevent source mapping reads from a source and sends an event batch to lambda\u003c/li\u003e\n\u003cli\u003ebatches that fail can be sent to sqs or sns topics\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eVersions\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eYou can have different versions of lambda functions\u003c/li\u003e\n\u003cli\u003eeach version is immutable\u003c/li\u003e\n\u003cli\u003e$latest points to the latest version\u003c/li\u003e\n\u003cli\u003eCan use Aliases to point to specific versions eg dev, stage, prod which can be changed\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003estartup times\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eexecution context needs to be created\u003c/li\u003e\n\u003cli\u003edeployment package is downloaded\u003c/li\u003e\n\u003cli\u003ethis process is known as a cold start\u003c/li\u003e\n\u003cli\u003eif a future invocation is done in a short time span it could possibly use the same execution context - this is known as a warm start\u003c/li\u003e\n\u003cli\u003eif too long between invocations then a new function will need to be executed causing a cold start\u003c/li\u003e\n\u003cli\u003eone function invocation runs at a time per context\u003c/li\u003e\n\u003cli\u003eprovisioned concurrency can be used where aws will keep a certain amount of contexts warm to improve start up speeds\u003c/li\u003e\n\u003cli\u003ethe /tmp storage can also hold the data between warm functions\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"cloudwatchevents-and-eventbridge\"\u003eCloudWatchEvents and EventBridge\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#cloudwatchevents-and-eventbridge\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eCloudwatch events delivers a near real time stream of system events which describe changes in aws products and services e.g. terminate, start\u003c/li\u003e\n\u003cli\u003eEventsBridge is the service which will replace CloudWatch Events\u003c/li\u003e\n\u003cli\u003eCan observe if X happens or at Y times ... do Z\u003c/li\u003e\n\u003cli\u003eEventBridge is basically Cloudwatch Events v2 - you should use it by default\u003c/li\u003e\n\u003cli\u003eBoth of these use an event bus and there is a default one for the account\u003c/li\u003e\n\u003cli\u003ecloudwatch only has 1 bus and its implicit (not exposed)\u003c/li\u003e\n\u003cli\u003eEventBridge allows you to create additional busses and you can interact with them\u003c/li\u003e\n\u003cli\u003eYou create rules for incoming events or schedule based rules\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"serverless-architecture\"\u003eServerless Architecture\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#serverless-architecture\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eServerless is a software architecture which's aim is to manage few servers as possible\u003c/li\u003e\n\u003cli\u003eApplications are a collection of small and specialised functions\u003c/li\u003e\n\u003cli\u003eThe functions are run in stateless and ephemeral environments - they are billed via duration\u003c/li\u003e\n\u003cli\u003eEverything is event driven - things are only run when required\u003c/li\u003e\n\u003cli\u003eFaaS is used where possible for compute functionality\u003c/li\u003e\n\u003cli\u003eNo persistent usage of compute\u003c/li\u003e\n\u003cli\u003eManaged services should be used where possible e.g. s3, dynamo, SSO\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"simple-notification-service-sns\"\u003eSimple Notification Service (SNS)\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#simple-notification-service-sns\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA highly available, durable, secure pub sub service\u003c/li\u003e\n\u003cli\u003eIt's on the Public AWS Service so you will need network connectivity with the public endpoint\u003c/li\u003e\n\u003cli\u003eCoordinates the sending and delivery of message\u003c/li\u003e\n\u003cli\u003eMessages are \u0026#x3C;= 256kb (it's made for small files)\u003c/li\u003e\n\u003cli\u003eSNS Topics are the base of entity of SNS - permission and configuration\u003c/li\u003e\n\u003cli\u003ePublishers sends things to a topic\u003c/li\u003e\n\u003cli\u003eSubscribers receive messages from a topic e.g. http(s), emails, sqs, mobile push, sms messages, lambda\u003c/li\u003e\n\u003cli\u003eUsed across AWS services e.g. cloudwatch and cloudformation\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eFunctionality it offers:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDelivery status\u003c/li\u003e\n\u003cli\u003eDelivery retries - reliable delivery\u003c/li\u003e\n\u003cli\u003eHA and Scalable (Region)\u003c/li\u003e\n\u003cli\u003eSSE (server side encryption)\u003c/li\u003e\n\u003cli\u003eCross-account via TOPIC policy\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"step-functions\"\u003eStep Functions\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#step-functions\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eAddress some of the limitations/design decisions of Lambda\u003c/li\u003e\n\u003cli\u003eLambda is FaaS - you should not be putting a full application in a function\u003c/li\u003e\n\u003cli\u003e15 minute max execution time\u003c/li\u003e\n\u003cli\u003eThey can be chained together\u003c/li\u003e\n\u003cli\u003eChaining together can get messy at scale\u003c/li\u003e\n\u003cli\u003eRuntime environments are stateless\u003c/li\u003e\n\u003cli\u003eStep functions let you create state machines\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eState Machines\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eState machines are like a workflow with start/end point and in between has states\u003c/li\u003e\n\u003cli\u003eStates modify and output data\u003c/li\u003e\n\u003cli\u003eMaximum duration for state machine execution is 1 year\u003c/li\u003e\n\u003cli\u003eStandard workflow or express workflow available - standard is default, express is for high volume and they are for up to 5 minutes\u003c/li\u003e\n\u003cli\u003eThey can be started via API gateway, IOT rules, Event bridge, lambda\u003c/li\u003e\n\u003cli\u003eCan be created via ASL (amazon states language) - JSON template\u003c/li\u003e\n\u003cli\u003eInteract with other services via IAM roles (permissions)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eStates:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSUCCEED \u0026#x26; FAIL - where it arrives\u003c/li\u003e\n\u003cli\u003eWAIT - period of time or until - pauses the workflow\u003c/li\u003e\n\u003cli\u003eCHOICE - takes a path depending on an input\u003c/li\u003e\n\u003cli\u003ePARALLEL - allows you to create parallel branches in a state machine - perform multiple sets of thing at the same time\u003c/li\u003e\n\u003cli\u003eMAP - accepts a list of things, performs action(s) on each item\u003c/li\u003e\n\u003cli\u003eTASK - a single unit of work which allows you to perform action - integrates with many things e.g. lambda, batch, dynamodb, ecs, sns, sqs etc\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"api-gateway-101\"\u003eAPI Gateway 101\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#api-gateway-101\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA service which lets you create and manage APIs\u003c/li\u003e\n\u003cli\u003eAct as an endpoint/entry point for applications\u003c/li\u003e\n\u003cli\u003eSit between application and integration (services)\u003c/li\u003e\n\u003cli\u003eHighly available, scalable, handles authorisation, throttling, caching, CORS, transformations, openAPI spec, direct integration and much more\u003c/li\u003e\n\u003cli\u003eCan connect to services/endpoints in AWS or on-premises\u003c/li\u003e\n\u003cli\u003eWorks with HTTP, REST and websockets\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAuthentication:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSupports a range of methods and can also be open access\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eEndpoint types:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEdge optimised - routed to the nearest cloudfront POP\u003c/li\u003e\n\u003cli\u003eRegional - clients in the same region\u003c/li\u003e\n\u003cli\u003ePrivate - only accessible within a vpc via interface endpoint\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eStages:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAPIs are deployed to stages each stage has one deployment e.g dev, prod\u003c/li\u003e\n\u003cli\u003eCan be rolled back\u003c/li\u003e\n\u003cli\u003eAllows canary deployments on stages and eventually be promoted\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eErrors:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e4xxx - client error - invalid requests on the client side\u003c/li\u003e\n\u003cli\u003e5xxx - server errors - valid request, backend issue\u003c/li\u003e\n\u003cli\u003e400 - Bad Request - Generic\u003c/li\u003e\n\u003cli\u003e403 - Access Denied - authorizer denied or its been filtered\u003c/li\u003e\n\u003cli\u003e429 - API Gateway can throttle - its been exceeded\u003c/li\u003e\n\u003cli\u003e502 - Bad gateway exception - bad output returned by lambda\u003c/li\u003e\n\u003cli\u003e503 - service unavailable - endpoint offline or major service issues\u003c/li\u003e\n\u003cli\u003e504 - integration failure/timeout - 29s limit on lambda\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eCaching:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eConfigured per stage\u003c/li\u003e\n\u003cli\u003eWithout a cache, applications make requests to the stage and the backend integrations will be used on each and every request\u003c/li\u003e\n\u003cli\u003eWith cache, you can specify a size between 500mb-237GB - caching for 300s by default (otherwise 0-3600s). Can be encrypted. Calls are only made to backend if request is a cache miss\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"simple-queue-service-sqs\"\u003eSimple Queue Service (SQS)\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#simple-queue-service-sqs\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eProvides managed message queues\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePublic service\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eFully managed\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eHighly available and highly performant - you don't need to worry about replication or resiliency\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eEither standard or FIFO - fifo guarantee an order. Standard is best effort but could be out of order\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eMsgs can be up to 256kb in size - you want to keep them small\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eClients can send and other clients can poll the queue\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eReceived messages are hidden (VisibilityTimeout) - if a client doesn't delete the message then it can reappear int he queue\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eDead letter queues can be used for problem messages which means that different sets of processing can occur on problematic messages\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eAuto scaling groups can scale based on the queue lengths\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eStandard - at least once delivery , FIFO - exactly once delivery\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eFIFO performance is limited - 3000 messages per second with batching or up to 300 messages per second without\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eBilled based on requests\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e1 request = 1-10 messages up to 64kb total\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eShort (immediate) vs long (waitTimeSeconds) polling - waitTimeSeconds can be up to 20 second. Long polling is how you SHOULD poll SQS\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eEncryption at rest (KMS) \u0026#x26; in transit. Data is encrypted by default in transit but not at rest\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eQueue policy can be used\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"sqs-standard-vs-fifo-queues\"\u003eSQS Standard vs FIFO Queues\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#sqs-standard-vs-fifo-queues\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eFIFO are single lane highways and standard are multi lane\u003c/li\u003e\n\u003cli\u003eStandard is scalable as wide as required near unlimited TPS\u003c/li\u003e\n\u003cli\u003eFIFO queues have to have a FIFO suffix to be a fifo queue\u003c/li\u003e\n\u003cli\u003eGreat for workflow ordering, command ordering, price adjustments\u003c/li\u003e\n\u003cli\u003eStandard queues are faster however there is no rigid order of messaging.\u003c/li\u003e\n\u003cli\u003eGood for decoupling, worker pools, batch for future processing\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"sqs-delay-queues\"\u003eSQS Delay Queues\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#sqs-delay-queues\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eAllow you to postpone the delivery of messages to consumers\u003c/li\u003e\n\u003cli\u003eA delay queue has a DelaySeconds where messages are conceptually parked - they are not available on the queue. Maximum value is 15 minutes. \u003c/li\u003e\n\u003cli\u003eYou cannot use it on FIFO queues\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"sqs-dead-letter-queues\"\u003eSQS Dead-Letter Queues\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#sqs-dead-letter-queues\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eDead letter queues are designed to allow you to handle problematic messages \u003c/li\u003e\n\u003cli\u003eYou can use a dead letter queue whereby when the recievecount of a message is more than maxRecieveCount it moves to a dead letter queue\u003c/li\u003e\n\u003cli\u003eIt's a separate area to analyse/diagnose the messaging issues \u003c/li\u003e\n\u003cli\u003eAll sqs have retention periods for messages which starts at the enqueue timestamp of the original queue.\u003c/li\u003e\n\u003cli\u003eA DLQ can be used for multiple source queues\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"kinesis-data-streams\"\u003eKinesis Data Streams\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#kinesis-data-streams\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eOften confused with SQS\u003c/li\u003e\n\u003cli\u003eA scalable streaming service\u003c/li\u003e\n\u003cli\u003eDesigned to ingest data from lots of devices and applications\u003c/li\u003e\n\u003cli\u003estreams can scale from low to near infinite data rates\u003c/li\u003e\n\u003cli\u003epublic service \u0026#x26; highly available by design \u003c/li\u003e\n\u003cli\u003eProvide a level of persistence - 24 hour moving window of data\u003c/li\u003e\n\u003cli\u003eCan be increased to 365 days for an additional cost\u003c/li\u003e\n\u003cli\u003emultiple consumers can access the data from that moving window \u003c/li\u003e\n\u003cli\u003egreat for analytics and dashboards\u003c/li\u003e\n\u003cli\u003eUses a shard architecture with each shard taking on more data \u003c/li\u003e\n\u003cli\u003eKineses data records are max of 1mb\u003c/li\u003e\n\u003cli\u003eQuestions about ingesting data is about kineses otherwise it could be sqs\u003c/li\u003e\n\u003cli\u003eSQS has 1 production group, 1 consumption group\u003c/li\u003e\n\u003cli\u003eSQS usually are used for decoupling and asynchronous communications\u003c/li\u003e\n\u003cli\u003eSQS doesn't really use any persistence or windows\u003c/li\u003e\n\u003cli\u003eKinesis is designed for huge scale ingestion for multiple consumers over a rolling window\u003c/li\u003e\n\u003cli\u003eKinesis is good for data ingestion, analytics, monitoring or app clicks \u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"kinesis-data-firehose\"\u003eKinesis Data Firehose\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#kinesis-data-firehose\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eKinesis does not provide a default way to store data\u003c/li\u003e\n\u003cli\u003eFirehose is a fully managed service used to load data for data lakes, data stores and analytics services\u003c/li\u003e\n\u003cli\u003eScales automatically - fully serverless, resilient\u003c/li\u003e\n\u003cli\u003eNear real time delivery (~60 seconds delay)\u003c/li\u003e\n\u003cli\u003eSupports transformation of data on the fly using lambda - can add latency\u003c/li\u003e\n\u003cli\u003eBilling - volume through firehose\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eValid destinations for firehose:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eHTTP endpoints\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eSplunk\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eRedshift\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eElasticSearch\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eDestination Bucket s3\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eKinesis data stream integrates with firehose to delegate the data\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eFirehose can also recieve data directly from sources \u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eEven though it receives things in real time, firehose does not deliver in real time unlike kinesis data stream (~200ms vs ~60s)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eLambda can be used to transform data coming from firehose and back\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe only exception to kineses firehose data store is redshift where s3 is used as an intermediary storage before it's saved onto redshift\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eFirehose is good for permanent storage of data, for transforming data (using lambda) to store, or if you want to put it into one of the supported products\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eremember it is not REAL TIME\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"kinesis-data-analytics\"\u003eKinesis Data Analytics\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#kinesis-data-analytics\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eReal time data processing product\u003c/li\u003e\n\u003cli\u003eUses SQL\u003c/li\u003e\n\u003cli\u003eIngests from kineses data streams or firehose\u003c/li\u003e\n\u003cli\u003eCan be sent on in real time to destinations - firehose, s3, redshift, elasticsearch \u0026#x26; splunk\u003c/li\u003e\n\u003cli\u003eAWS Lambda\u003c/li\u003e\n\u003cli\u003eKineses data streams\u003c/li\u003e\n\u003cli\u003eIt's realtime unless you use firehose\u003c/li\u003e\n\u003cli\u003eAllows you to use sql in real time on source streams\u003c/li\u003e\n\u003cli\u003eKineses analaytics app can also take data from static resources e.g. s3 bucket \u003c/li\u003e\n\u003cli\u003eStatic data can be used to enrich the real time streaming input\u003c/li\u003e\n\u003cli\u003eIt processes input, performs application code on the data and outputs streams and puts them to kineses streams or kinesis firehose\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003escenarios where you may use kineses data analytics:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003estreaming data that needs reeal time sql processing\u003c/li\u003e\n\u003cli\u003etime series analytics - elections/e-sports\u003c/li\u003e\n\u003cli\u003ereal time dashboards - leaderboards for games\u003c/li\u003e\n\u003cli\u003ereal time metrics - security and response \u003c/li\u003e\n\u003cli\u003eLambda is limited to simple manipulations, kineses data analytics is good for complex real time data manipulation \u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"kinesis-video-streams\"\u003eKinesis Video Streams\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#kinesis-video-streams\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eKineses video streams ingests live video from producers\u003c/li\u003e\n\u003cli\u003eThese can be security cameras, smartphones, cars, drones, time-serialised audio, thermal, depth and RADAR data\u003c/li\u003e\n\u003cli\u003eConsumers can access data frame-by-frame or as needed \u003c/li\u003e\n\u003cli\u003eCan persist and encrypt data in transit and at rest\u003c/li\u003e\n\u003cli\u003eYou can't access the video data directly via storage you can only do it via apis\u003c/li\u003e\n\u003cli\u003eIntegrates with AWS products - rekognition and Connect\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"amazon-cognito---user-and-identity-pools\"\u003eAmazon Cognito - User and Identity Pools\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#amazon-cognito---user-and-identity-pools\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eCognito provides authentication, authorization and user management for web and mobile apps\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThere are two parts of cognito:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eUser pools - sign in and get a JWT (json web token) - most aws services CANNOT use jwts.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003eused for sign up, sign in, MFA and other security features\u003c/li\u003e\n\u003cli\u003eAllow SSO \u003c/li\u003e\n\u003cli\u003eCan't be used to access AWS resources\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003eIdentity Pool - allows you to offer access to temporary AWS credentials\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003eUnauthenticated identities for guest users \u003c/li\u003e\n\u003cli\u003eSwap temporary identity for short term AWS credentials \u003c/li\u003e\n\u003cli\u003eAssume an IAM role on behalf of an identity\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"aws-glue-101\"\u003eAWS Glue 101\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#aws-glue-101\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eServerless ETL (extract, transform and load) \u003c/li\u003e\n\u003cli\u003eDatapipeline can do ETl but it uses servers\u003c/li\u003e\n\u003cli\u003eMoves and transforms data between source and destination \u003c/li\u003e\n\u003cli\u003eCrawls data sources and generates the AWS glue data catalog\u003c/li\u003e\n\u003cli\u003eData sources can be any store e.g. s3, rds, jdbc compatible \u0026#x26; dynamo db \u003c/li\u003e\n\u003cli\u003eData sources can also be streams e.g. kinesis data streams \u0026#x26; apache kafka\u003c/li\u003e\n\u003cli\u003eData targets can be s3, rds, jdbc databases\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eData Catalog\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA collection of metadata combined with search tools\u003c/li\u003e\n\u003cli\u003eOne catalog per region per account \u003c/li\u003e\n\u003cli\u003eHelps avoid data silos\u003c/li\u003e\n\u003cli\u003eAWS can use glue for etl and catalogue related services e.g. athena, redshift spectrum, aws lake formation\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"amazon-mq-101\"\u003eAmazon MQ 101\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#amazon-mq-101\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eA merge between SQS and SNS but using open standards\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eSNS/SQS utilise aws apis\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eSNS provides topics and sqs provides queues\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eSNS/SQS are both public services and can be accessed from anywhere\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eBoth highly scalable and AWS integrated\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eMany orgs already use topics and queues (an on premise messaging system)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIf they want to migrate to AWS, sns and sqs won't work out of the box\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eAmazon MQ is an open-source message broker\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eBased on managed apache activeMQ\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eProvides both queues and topics (1-1 and 1-many)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eProvided with message broker service - either a single instance for test/dev/cheap or Highly available Pair (active/standbye)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eNot a public service - runs in a VPC - requires private networking\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eno AWS native integration\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eYour default implementation should be SNS or SQS (new implementations)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eSNS or SQS if AWS integration is required e.g. logging, permissions, encryption, service integration\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eUse Amazon MQ if you neeed to migrate from an existing system with little to no change\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIf you need to use open APIs\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eRemember you need to have private networking configured to use amazon MQ \u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"amazon-appflow\"\u003eAmazon AppFlow\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#amazon-appflow\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eFully managed integration service\u003c/li\u003e\n\u003cli\u003eExchange data between applications (connectors) using flow\u003c/li\u003e\n\u003cli\u003eSource/destination connector\u003c/li\u003e\n\u003cli\u003eSync data across applications\u003c/li\u003e\n\u003cli\u003eAggregate data from different sources\u003c/li\u003e\n\u003cli\u003eUses public endpoints but works with PrivateLink (privacy)\u003c/li\u003e\n\u003cli\u003eCan use a custom connector SDK (build your own)\u003c/li\u003e\n\u003cli\u003ee.g. of usage - sync contact records from salesforce to redshift or support tickets from zendesk to s3\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"global-content-delivery-and-optimization\"\u003eGLOBAL CONTENT DELIVERY AND OPTIMIZATION\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#global-content-delivery-and-optimization\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003ch3 id=\"cloudfront-architecture\"\u003eCloudfront Architecture\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#cloudfront-architecture\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eContent Delivery Network - improve the delivery - uses caching and an efficient global network\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eCloudfront terms:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eOrigin - the original location of content - S3 or Custom origin - S3 bucket or anywhere else\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eDistribution - The configuration unit of cloudfront - everything is configured in distribution (directly or indirectly)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eEdge location - pieces of global infrastructure where content is cached\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eRegional Edge Cache - bigger than edge locations but designed to hold data that is accessed less frequently\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eEdge location is checked first, if there is a cache miss, the regional cache is checked, then finally its fetched from the origin if its not there. If its fetched from the origin then it's cached at regional and edge \u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eCloudfront performs no write caching - only read caching\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eA behaviour is configuration or \"subconfiguration\" of distribution\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eBehaviours sit architecturally between origins and distributions - Cloudfronts have at least 1 behaviour\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eDefault behaviour is * which matches everything\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"cloudfront---ttl-and-invalidations\"\u003eCloudFront - TTL and Invalidations\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#cloudfront---ttl-and-invalidations\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eAn edge location views an object as not expired if it's within it's TTL period\u003c/li\u003e\n\u003cli\u003eMore frequent cache HITS = lower origin load\u003c/li\u003e\n\u003cli\u003eTTL default behaviour = 24 hours validity period\u003c/li\u003e\n\u003cli\u003eYou can set Minimum TTL and Maximum TTL \u003c/li\u003e\n\u003cli\u003eThere are different headers that can be used to direct cloudfront to use different TTL values:\n\u003cul\u003e\n\u003cli\u003eCache-Control max-age (seconds)\u003c/li\u003e\n\u003cli\u003eCache-Control s-maxage (seconds)\u003c/li\u003e\n\u003cli\u003eExpires (Date \u0026#x26; Time)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eFor all of these, the TTL minimum and maximum will be used instead of the per-object setting if these don't fall in the range \u003c/li\u003e\n\u003cli\u003eCache invalidations can be performed on a distribution - applies to all edge locations - takes time \u003c/li\u003e\n\u003cli\u003eTakes a path with wildcards to invalidate everything in that path e.g. /images/\u003cem\u003e or /images/whiskers\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003eInvalidation should only be thought of as a way to correct errors - versioned file names are a good alternative to invalidation \u003c/li\u003e\n\u003cli\u003eversioned file names is not the same as s3 object versioning\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"acm---aws-certificate-manager\"\u003eACM - AWS Certificate Manager\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#acm---aws-certificate-manager\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eHTTP was created as simple and secure\u003c/li\u003e\n\u003cli\u003eOnce HTTP evolved, security vulnerabilities became an issue\u003c/li\u003e\n\u003cli\u003eHTTPS - SSL/TLS Layer of Encryption was added to HTTP\u003c/li\u003e\n\u003cli\u003eData is encrypted in transit\u003c/li\u003e\n\u003cli\u003eCertificates prove identity \u003c/li\u003e\n\u003cli\u003eChain of trust - signed by a trusted authority \u003c/li\u003e\n\u003cli\u003eACM can function as a public or private certificate authority (CA) e.g. private can be used in an organisation\u003c/li\u003e\n\u003cli\u003ePrivate CA - applications need to trust your private CA\u003c/li\u003e\n\u003cli\u003ePublic CA - browsers trust a list of providers \u003c/li\u003e\n\u003cli\u003eACM can generate or import certificates\u003c/li\u003e\n\u003cli\u003eIf generated, ACM can auto renew on your behalf\u003c/li\u003e\n\u003cli\u003eIf imported, you will have to renew them yourself\u003c/li\u003e\n\u003cli\u003eACM can be deployed out to supported services\u003c/li\u003e\n\u003cli\u003eSupported AWS services ONLY e.g. cloudfront and ALB but not EC2\u003c/li\u003e\n\u003cli\u003eACM is a regional service \u003c/li\u003e\n\u003cli\u003eCerts cannot leave the region they are generated or imported in \u003c/li\u003e\n\u003cli\u003eIf you want to use a certificate in a service, it MUST be in the same region in ACM\u003c/li\u003e\n\u003cli\u003ethere is one exception - cloudfront operates as though within us-east-1 - you need to use this region in ACM\u003c/li\u003e\n\u003cli\u003eS3 does not use ACM for any certificates\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"securing-cf-and-s3-using-oai\"\u003eSecuring CF and S3 using OAI\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#securing-cf-and-s3-using-oai\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eOrigin Access Identity - OAI is a type of identity\u003c/li\u003e\n\u003cli\u003eAssociated with cloudfront distribution \u003c/li\u003e\n\u003cli\u003ecloudfront \"becomes\" that OAI\u003c/li\u003e\n\u003cli\u003eOAI can be used in S3 Bucket Policies\u003c/li\u003e\n\u003cli\u003eUses DENY all BUT one or more OAIs\u003c/li\u003e\n\u003cli\u003eWe can deny any access directly to s3 by using an OAI policy - explicit allow for the OAI \u003c/li\u003e\n\u003cli\u003ewhen we have custom origns we can't use OAI\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWith custom origins you can:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003euse custom headers \u003c/li\u003e\n\u003cli\u003eand/or we have the IP ranges used by cloudfront so we can use a custom firewall\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"cloudfront---private-distribution--behaviours\"\u003eCloudFront - Private Distribution \u0026#x26; Behaviours\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#cloudfront---private-distribution--behaviours\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003ecloudfront can be run in public mode or private mode\u003c/li\u003e\n\u003cli\u003eif its private it needs to be access via cookie or signed url\u003c/li\u003e\n\u003cli\u003eyou can have a mixed of multiple behaviours e.g. public or private\u003c/li\u003e\n\u003cli\u003eyou need a signer to sign cookies and urls\u003c/li\u003e\n\u003cli\u003eOld way was via a cloudfront key via the account root user - you need to remember the term TRUSTED SIGNER\u003c/li\u003e\n\u003cli\u003enew method is TRUSTED KEY GROUP(s) - you don't need to use the root user.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003esigned urls vs signed cookies:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eurls - provide access to ONE object only\u003c/li\u003e\n\u003cli\u003euse signed urls if your client doesn't support cookies\u003c/li\u003e\n\u003cli\u003eCookies provides access to groups of objects\u003c/li\u003e\n\u003cli\u003euse cookies for groups of files/all files of a type\u003c/li\u003e\n\u003cli\u003eor if you want to maintain the application url \u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"lambdaedge\"\u003eLambda@Edge\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#lambdaedge\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eAllows you to run lightweight lambda functions at edge locations\u003c/li\u003e\n\u003cli\u003ecan adjust traffic between the viewer and origin\u003c/li\u003e\n\u003cli\u003eCurrently only support node js and python\u003c/li\u003e\n\u003cli\u003eyou cannot access any VPC services since its in the public space\u003c/li\u003e\n\u003cli\u003eYou can use it for A/B testing to change the viewer request and the url \u003c/li\u003e\n\u003cli\u003eCan use it to migrate between S3 origins e.g. by a weighted value\u003c/li\u003e\n\u003cli\u003eCan use it to customise behaviour based on the type of device the customer is using\u003c/li\u003e\n\u003cli\u003eVary content by country \u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"global-accelerator\"\u003eGlobal Accelerator\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#global-accelerator\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eused to optimise flow of data\u003c/li\u003e\n\u003cli\u003ethis is an alternative to cloudfront\u003c/li\u003e\n\u003cli\u003eglobal accelerators use anycast IP addresses - they allow single IPs to be used in multiple locations\u003c/li\u003e\n\u003cli\u003ewhen we create a global accelerator, its allocated an anycast IP address\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eKey Concepts:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003emoves AWS network closer to customers\u003c/li\u003e\n\u003cli\u003eAims to get users onto the global aws network as quickly and as close to their location as possible\u003c/li\u003e\n\u003cli\u003eits transited over AWS backbone to 1+ location \u003c/li\u003e\n\u003cli\u003eglobal accelerator is a network product and can be used for non http(s) e.g. TCP/UDP - if you need TCP/UDP you will need global accelerator. \u003c/li\u003e\n\u003cli\u003ecloudfront only caches HTTP, HTTP(S) content \u003c/li\u003e\n\u003cli\u003eGA does not cache anything , its just transmitting network data quickly\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"advanced-vpc-networking\"\u003eADVANCED VPC Networking\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#advanced-vpc-networking\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003ch3 id=\"vpc-flow-logs\"\u003eVPC Flow Logs\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#vpc-flow-logs\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eCapture metadata (Not contents) e.g. source ip, destination ip, anything to do with flow of data to vpc\u003c/li\u003e\n\u003cli\u003eCan attach a VPC - all ENIs in that VPC\u003c/li\u003e\n\u003cli\u003eSubnet - All ENIs in that subnet\u003c/li\u003e\n\u003cli\u003eENIs directly\u003c/li\u003e\n\u003cli\u003ethey're NOT real time \u003c/li\u003e\n\u003cli\u003ecan go to multiple destination - s3 or cloudwatch logs\u003c/li\u003e\n\u003cli\u003ecan use athena for querying - ad hoc querying engine\u003c/li\u003e\n\u003cli\u003eA VPC flow logs has different fields e.g. srcaddr, dstaddr, srcport, dstport, protocol,action\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"egress-only-internet-gateway\"\u003eEgress-Only Internet gateway\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#egress-only-internet-gateway\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eIPV4 addresses are private or public\u003c/li\u003e\n\u003cli\u003eNAT allows private IPs to access public networks \u003c/li\u003e\n\u003cli\u003eWithout allowing externally initiated connections (IN)\u003c/li\u003e\n\u003cli\u003eWith IPv6, all IPS are public meaning internet gateways allows all IPs IN and OUT\u003c/li\u003e\n\u003cli\u003eEgress-only is outbound-only for IPV6 since NAT does not support this\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"vpc-endpoints-gateway\"\u003eVPC Endpoints (Gateway)\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#vpc-endpoints-gateway\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eProvide provide private access to public endpoints. At this point for S3 and DynamoDB\u003c/li\u003e\n\u003cli\u003eThey allow a private only resource inside a VPC to access S3 and DynamoDB\u003c/li\u003e\n\u003cli\u003eNormally you would need an internet gateway to the VPC \u003c/li\u003e\n\u003cli\u003eGateway endpoints allow you to access these services without creating a public infrastructure\u003c/li\u003e\n\u003cli\u003eA prefix list is added to route table for these subnets\u003c/li\u003e\n\u003cli\u003ethat means any traffic leaving the subnet goes through the gateway endpoint rather than the internet gateway\u003c/li\u003e\n\u003cli\u003eIt's HA across all AZs in a region by default \u003c/li\u003e\n\u003cli\u003eEndpoint policy is used to control what it can access e.g. particular s3 buckets\u003c/li\u003e\n\u003cli\u003eCan only access in same region - can't access cross-region services\u003c/li\u003e\n\u003cli\u003eThese prevent leaky buckets - s3 can be set to private only by allowing access ONLY from a gateway endpoint. \u003c/li\u003e\n\u003cli\u003egateway endpoints are NOT accessible outside the vpc \u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"vpc-endpoints-inteface\"\u003eVPC Endpoints (Inteface)\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#vpc-endpoints-inteface\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eSimilar to gateway but the way its done is different\u003c/li\u003e\n\u003cli\u003eLike gateway endpoints, they provide private access to AWS services\u003c/li\u003e\n\u003cli\u003edynamoDB is still only available using gateway but interface can use s3\u003c/li\u003e\n\u003cli\u003eAllow private IP addressing to access public AWS services\u003c/li\u003e\n\u003cli\u003einterface endpoints are not highly available by default - they are added to specific subnets - ENI\u003c/li\u003e\n\u003cli\u003eOne Interface Endpoint should be added to one subnet per AZ for high availability\u003c/li\u003e\n\u003cli\u003eNetwork access controlled via Security Groups - can't do this with gateway endpoints\u003c/li\u003e\n\u003cli\u003eEndpoint policies can be used to restrict what can be done with the endpoint\u003c/li\u003e\n\u003cli\u003eTCP and IPV4 ONLY\u003c/li\u003e\n\u003cli\u003eUses PrivateLink\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"vpc-peering\"\u003eVPC Peering\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#vpc-peering\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA service that lets you create a private encrypted network link between two VPCs\u003c/li\u003e\n\u003cli\u003eOne peering connection links two and ONLY two vpcs \u003c/li\u003e\n\u003cli\u003eWorks same/cross region and same/cross-account\u003c/li\u003e\n\u003cli\u003eSame region peers can reference peer Security Groups\u003c/li\u003e\n\u003cli\u003eVPC Peering does not support transitive peering e.g. A -\u003e B and B -\u003e C does NOT mean A -\u003e C\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"hybrid-environments-and-migration\"\u003eHYBRID ENVIRONMENTS AND MIGRATION\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#hybrid-environments-and-migration\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003ch3 id=\"border-gateway-protocol-101\"\u003eBorder Gateway Protocol 101\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#border-gateway-protocol-101\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eMade up of Autonomous Systems (AS) - Routers controlled by one entity \u003c/li\u003e\n\u003cli\u003eASN (Autonomous system numbers) are unique and allocated by IANA\u003c/li\u003e\n\u003cli\u003eReliable and distributed - operates over tcp/179\u003c/li\u003e\n\u003cli\u003eNot automatic - peering is manually configured \u003c/li\u003e\n\u003cli\u003ePath-vector protocol - exchanges the best path to a destination between peers. This path is known as the ASPATH\u003c/li\u003e\n\u003cli\u003eiBGP - Internal BGP - routing within AS\u003c/li\u003e\n\u003cli\u003eeBGP - External BGP - routing between AS\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"ipsec-vpn-fundamentals\"\u003eIPSec VPN Fundamentals\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#ipsec-vpn-fundamentals\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA group of protocols that aim to set up secure tunnels across insecure networks\u003c/li\u003e\n\u003cli\u003e...between two peers (local and remote)\u003c/li\u003e\n\u003cli\u003eProvides authentication and is encrypted\u003c/li\u003e\n\u003cli\u003eIPSEC has two main phases:\n\u003col\u003e\n\u003cli\u003eIKE Phase 1 - Internet Key Exchange (slow and heavy)\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003eAuthenticate \u003c/li\u003e\n\u003cli\u003eUsing asymmetric encryption to agree on \u003c/li\u003e\n\u003cli\u003eIKE SA created - phase 1 tunnel\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003eIKE Phase 2 - (fast and agile)\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003eUses keys agreed in phase 1\u003c/li\u003e\n\u003cli\u003eAgreed encryption method used\u003c/li\u003e\n\u003cli\u003eCreated IPSEC SA - phase 2 tunnel \u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003ePolicy vs route based VPNs:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePolicy - rule sets match traffic - a pair of SAs\u003c/li\u003e\n\u003cli\u003eroute based - target matching (prefix) - matches a single pair of SAs\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"aws-site-to-site-vpn\"\u003eAWS Site-to-Site VPN\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#aws-site-to-site-vpn\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eLogical connection between a VPC and an on-premiss network - encrypted using IPSEC, running over public internet\u003c/li\u003e\n\u003cli\u003eFully HA - if you design and implement correctly\u003c/li\u003e\n\u003cli\u003eQuick to provision - less than an hour\u003c/li\u003e\n\u003cli\u003eVirtual Private Gateway (VGW) - a logical gateway object that can be associated with a single VPC and one or more route tables\u003c/li\u003e\n\u003cli\u003eCustomer Gateway (CGW) - logical config in AWS or physical device which it represents\u003c/li\u003e\n\u003cli\u003eVPN connection between VGW and CGW\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eVPN Consideration:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSpeed limitation 1.25Gbps\u003c/li\u003e\n\u003cli\u003eLatency - inconsistent\u003c/li\u003e\n\u003cli\u003eCost - AWS hourly cost, GB out cost, data cap (on premises)\u003c/li\u003e\n\u003cli\u003eSpeed of setup is quick and usually quicker than other private connection technologies- hours, all software configuration \u003c/li\u003e\n\u003cli\u003eCan be used as a backup for direct connect (DX) \u003c/li\u003e\n\u003cli\u003eCan be used with Direct Connect (DX)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"start-direct-connect-dx-concepts\"\u003eStart Direct Connect (DX) Concepts\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#start-direct-connect-dx-concepts\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA physical connection into an AWS region - 1,10 or 100 Gbps\u003c/li\u003e\n\u003cli\u003eBusiness premises =\u003e DX location =\u003e AWS Region\u003c/li\u003e\n\u003cli\u003eYou're given a port allocation at DX location \u003c/li\u003e\n\u003cli\u003eCost is hourly and outbound data transfer\u003c/li\u003e\n\u003cli\u003eProvisioning time - requires physical cables and there is no resilience as its physical. This could take weeks\u003c/li\u003e\n\u003cli\u003eLow \u0026#x26; consistent latency + high speeds\u003c/li\u003e\n\u003cli\u003eCan be used to access AWS Private services - can't be used to access public internet without additional configuration\u003c/li\u003e\n\u003cli\u003eDX location is not owned by AWS but is rented out by it \u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"direct-connect-dx-resilience\"\u003eDirect Connect (DX) Resilience\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#direct-connect-dx-resilience\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eDirect connect is not resilient, it's a physical connectivity that needs to be architected to be resilient\u003c/li\u003e\n\u003cli\u003eWhat could go wrong:\n\u003cul\u003e\n\u003cli\u003eDX location could fail e.g. power failure\u003c/li\u003e\n\u003cli\u003eDX Router \u003c/li\u003e\n\u003cli\u003eCross Connect - it'sa cable\u003c/li\u003e\n\u003cli\u003eCustomer DX router, \u003c/li\u003e\n\u003cli\u003eExtension\u003c/li\u003e\n\u003cli\u003eCustomer premises\u003c/li\u003e\n\u003cli\u003eCustomer router\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWe can add resilience by:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSeparate customer premises buildings - with separate routers\u003c/li\u003e\n\u003cli\u003eSeveral DX locations\u003c/li\u003e\n\u003cli\u003eAdding separate ports in each DX locations as well as premisses locations \u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"direct-connect-dx---public-vif--vpn-encryption\"\u003eDirect Connect (DX) - Public VIF + VPN (Encryption)\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#direct-connect-dx---public-vif--vpn-encryption\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eUsing a VPN gives you an encrypted and authenticated tunnel\u003c/li\u003e\n\u003cli\u003eOVer DX you will get low latency \u0026#x26; consistency latency\u003c/li\u003e\n\u003cli\u003eThis uses a public VIF\u003c/li\u003e\n\u003cli\u003eVPJ is transit agnostic - DX/Public internet\u003c/li\u003e\n\u003cli\u003ePublic VIFs+IPSec VPN is a way to provide access to private VPC resources, using an encrypted IPSEC tunnel for transit.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"transit-gateway\"\u003eTransit Gateway\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#transit-gateway\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA network transit hub which connects VPCs to each other and to on premises networks using site to site VPNs and direct connect\u003c/li\u003e\n\u003cli\u003eIt's designed to reduce network complexity\u003c/li\u003e\n\u003cli\u003eIt's a single network object - HA \u0026#x26; Scalable\u003c/li\u003e\n\u003cli\u003eYou create attachments to other network types\u003c/li\u003e\n\u003cli\u003eattachments - VPC, Site to site VPN and DX gateway\u003c/li\u003e\n\u003cli\u003eSupports transitive routing \u003c/li\u003e\n\u003cli\u003eCan be used to create global networks\u003c/li\u003e\n\u003cli\u003eShare transit gateways between accounts using AWS RAM\u003c/li\u003e\n\u003cli\u003eyou can peer different regions on same or cross accounts\u003c/li\u003e\n\u003cli\u003eIt offers much less complexity than without TGW\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"storage-gateway---volume\"\u003eStorage Gateway - Volume\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#storage-gateway---volume\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eRuns as a virtual machine on premises (although can be ordered as hardware appliance)\u003c/li\u003e\n\u003cli\u003epresents storage using iSCSI, NFS or SMB\u003c/li\u003e\n\u003cli\u003eIntegrates with EBS, s3 and glacier\u003c/li\u003e\n\u003cli\u003eused for migrations, extensions, storage tier-ing, DR and replacement of backup systems \u003c/li\u003e\n\u003cli\u003eWhen you're using volume storage in volume stored mode everything is stored locally\u003c/li\u003e\n\u003cli\u003eIt asynchronously syncs to storage gateway endpoint which stores EBS snapshots in an s3 bucket\u003c/li\u003e\n\u003cli\u003eif you need full disk backups and DR, this is not the right solution\u003c/li\u003e\n\u003cli\u003eVolume cached mode - instead of local storage, it has a local cache but it stores all data in s3. The AWS bucket is an aws managed area so its not available to just look at \u003c/li\u003e\n\u003cli\u003ethe main difference between Volume stored vs volume cached is the location of the data\u003c/li\u003e\n\u003cli\u003evolume cache uses aws as the primary location \u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"storage-gateway---tape-vtl\"\u003eStorage Gateway - Tape (VTL)\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#storage-gateway---tape-vtl\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003etapes - LTO - storing to tapes\u003c/li\u003e\n\u003cli\u003ethis really only allows write as a whole or read as a whole as editing tapes is not really possible\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"storage-gateway---file\"\u003eStorage Gateway - File\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#storage-gateway---file\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eFile bridges on premises file storage and s3\u003c/li\u003e\n\u003cli\u003eyou create mount points (shares) available via NFS or SMB \u003c/li\u003e\n\u003cli\u003ethey map directly onto an S3 bucket\u003c/li\u003e\n\u003cli\u003efiles stored into a mount point are visible as objects in an s3 bucket\u003c/li\u003e\n\u003cli\u003edoes read/write caching and ensures LAN-like performance\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"snowball--edge--snowmobile\"\u003eSnowball / Edge / Snowmobile\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#snowball--edge--snowmobile\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eDesigned to move large amounts of data in and out of AWS\u003c/li\u003e\n\u003cli\u003eThe devices in this series are big physical storage\u003c/li\u003e\n\u003cli\u003eYou can either order them empty, load and return \u003c/li\u003e\n\u003cli\u003eor order with data, empty and return \u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSnowball:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eordered from AWS \u003c/li\u003e\n\u003cli\u003edata encrypted using KMS\u003c/li\u003e\n\u003cli\u003e50tb or 80tb capacity\u003c/li\u003e\n\u003cli\u003e1GBPS or 10GBPS network\u003c/li\u003e\n\u003cli\u003e10TB to 10PB of data transfer most economical - you can order multiple devices\u003c/li\u003e\n\u003cli\u003eYou can move the devices to multiple premises\u003c/li\u003e\n\u003cli\u003eonly storage is included in the device\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSnowball edge:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eComes with storage and compute \u003c/li\u003e\n\u003cli\u003eLarger capacity\u003c/li\u003e\n\u003cli\u003e10gbs, 10/25, 45/50/100 - faster network\u003c/li\u003e\n\u003cli\u003estorage optimized with EC2 \u003c/li\u003e\n\u003cli\u003eCompute optimized variant - for aggressive compute requirements\u003c/li\u003e\n\u003cli\u003eCompute with GPU \u003c/li\u003e\n\u003cli\u003eSnowball is older, snowball edge is ideal for remote sites where data processing on ingestion is needed \u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSnowmobile:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePortable data center within a shipping container on a truck\u003c/li\u003e\n\u003cli\u003eideal for single location when 10+ PB is required\u003c/li\u003e\n\u003cli\u003eup to 100PB per snowmobile\u003c/li\u003e\n\u003cli\u003eIt's a single truck - not economical for multi site (unless huge) or sub 10pb\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"directory-service\"\u003eDirectory Service\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#directory-service\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003edirectories:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003estore objects within a structure (domain/tree)\u003c/li\u003e\n\u003cli\u003emultiple trees can be grouped into a forest\u003c/li\u003e\n\u003cli\u003eMicrosoft active directory domain service (AD DS) is a common implementation\u003c/li\u003e\n\u003cli\u003eDirectory Service is AWS managed implementation\u003c/li\u003e\n\u003cli\u003eRuns within a VPC\u003c/li\u003e\n\u003cli\u003eProvides HA - deploys within multiple AZs\u003c/li\u003e\n\u003cli\u003esome aws services need a directory e.g. amazon workplaces \u003c/li\u003e\n\u003cli\u003ecan be isolated directory or integrated with existing on-premises \u003c/li\u003e\n\u003cli\u003eor act as a proxy back to on premises\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIt can function in 3 modes:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSimple AD - an implementation of Samba 4\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eAWS Managed Microsoft AD - an actual microsoft AD DS implementation\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eAD Connector which proxies requests back to an on premises directory \u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eStart off with simple AD\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eMove to Microsoft AD if applications in AWS need MS DS or you need a trust relationship with AD DS\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIf you need a directory without storing any directory info in the cloud - use AD Connector \u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"datasync\"\u003eDataSync\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#datasync\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA data transfer service to transfer data into and out of AWS\u003c/li\u003e\n\u003cli\u003eDesigned to work at huge scale\u003c/li\u003e\n\u003cli\u003eKeeps metadata (e.g. permissions and timestamps)\u003c/li\u003e\n\u003cli\u003eBuilt in data validation\u003c/li\u003e\n\u003cli\u003eScalable - 10gbps per agent (~ 100TB per day)\u003c/li\u003e\n\u003cli\u003ecan use bandwith limiters\u003c/li\u003e\n\u003cli\u003eincremental and scheduled transfer options\u003c/li\u003e\n\u003cli\u003esupports compression and encryption\u003c/li\u003e\n\u003cli\u003eautomatic recovery\u003c/li\u003e\n\u003cli\u003eservice integration - S3, EFS, FSx\u003c/li\u003e\n\u003cli\u003ePay as you use\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"fsx-for-windows-servers\"\u003eFSx for Windows Servers\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#fsx-for-windows-servers\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003efully managed native windows file servers/shares\u003c/li\u003e\n\u003cli\u003edesigned for integration with windows environments\u003c/li\u003e\n\u003cli\u003ecan integrate with directory service or self managed AD\u003c/li\u003e\n\u003cli\u003eResilient and HA - single or multi AZ within a VPC\u003c/li\u003e\n\u003cli\u003eon demand and scheduled backups\u003c/li\u003e\n\u003cli\u003eAccessible over VPC, peering, DX\u003c/li\u003e\n\u003cli\u003eHighly performant\u003c/li\u003e\n\u003cli\u003eVSS - User driven restores - unique to Fsx - can do this without a sys admin\u003c/li\u003e\n\u003cli\u003eNative file system accessible over SMB \u003c/li\u003e\n\u003cli\u003eUses windows permission model\u003c/li\u003e\n\u003cli\u003eSupports DFS\u003c/li\u003e\n\u003cli\u003eManaged - no file server admin\u003c/li\u003e\n\u003cli\u003ecan be integrated with DS and your own directory\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"fsx-for-lustre\"\u003eFSx For Lustre\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#fsx-for-lustre\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eManaged implementation of Lustre - designed for HPC - Linux clients (POSIX)\u003c/li\u003e\n\u003cli\u003eFor machine learning, big data, financial model\u003c/li\u003e\n\u003cli\u003ecan scale to 100s GBs throughput and sub millisecond latency\u003c/li\u003e\n\u003cli\u003eDeployment types:\n\u003cul\u003e\n\u003cli\u003escratch - highly optimised for short term, fast\u003c/li\u003e\n\u003cli\u003epersistent - longer term, HA in one AZ and self healing\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eAvailable over a VPN or DX\u003c/li\u003e\n\u003cli\u003eMetadata is stored on metadata targets\u003c/li\u003e\n\u003cli\u003eobjects are stored on object storage targets\u003c/li\u003e\n\u003cli\u003ebaseline performance based on size \u003c/li\u003e\n\u003cli\u003eUse scratch for short term or temp workloads - NO HA, NO REPLICATION\u003c/li\u003e\n\u003cli\u003epersistent has replication but within ONE AZ only\u003c/li\u003e\n\u003cli\u003eAuto heals when hardware failure occurs\u003c/li\u003e\n\u003cli\u003eYou can backup to S3 with both\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"aws-transfer-family\"\u003eAWS Transfer Family\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#aws-transfer-family\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eProvides managed file transfer service - supports transfers to and from s3 and efs\u003c/li\u003e\n\u003cli\u003eprovides managed \"servers\"\nProtocols used:\n\u003cul\u003e\n\u003cli\u003eFTP\u003c/li\u003e\n\u003cli\u003eFTPS \u003c/li\u003e\n\u003cli\u003eSSH (SFTP)\u003c/li\u003e\n\u003cli\u003eAS2 - B2B data\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eCreate servers / endpoints:\n\u003cul\u003e\n\u003cli\u003epublic - via aws  - SFTP\u003c/li\u003e\n\u003cli\u003eVPC - internet - SFTP, FTPS, AS2\u003c/li\u003e\n\u003cli\u003eVPC - internal - SFTP, FTP, FTPS, AS2 \u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eMulti az \u003c/li\u003e\n\u003cli\u003eprovisioned server per hour + data transfered\u003c/li\u003e\n\u003cli\u003eFTP and FTPS - directory service or custom IDP only\u003c/li\u003e\n\u003cli\u003eFTP - VPC only (cannot be public)\u003c/li\u003e\n\u003cli\u003eAS2 - VPC internal/internet only\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"security-deployment--operations\"\u003eSECURITY, DEPLOYMENT \u0026#x26; OPERATIONS\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#security-deployment--operations\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003ch3 id=\"aws-secrets-manager\"\u003eAWS Secrets Manager\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#aws-secrets-manager\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eShares functionality with parameter store\u003c/li\u003e\n\u003cli\u003edesigned specifically for secrets e.g. passwords, api keys\u003c/li\u003e\n\u003cli\u003eUsable via console, cli, api or sdks\u003c/li\u003e\n\u003cli\u003esupports automatic rotation \u003c/li\u003e\n\u003cli\u003edirectly integrates with some aws products e.g. rds\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"application-layer-l7-firewall\"\u003eApplication Layer (L7) Firewall\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#application-layer-l7-firewall\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eNormal Firewalls (layer 3/4/5):\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003elayer 3-4 requests to/from are seen as different streams of data\u003c/li\u003e\n\u003cli\u003ewith layer 5, using a session, the two requests can be seen as one\u003c/li\u003e\n\u003cli\u003eeach of these don't understand anything above the layer they operate at e.g. they cannot see HTTP, they just see general packet data\u003c/li\u003e\n\u003cli\u003elayer 7 fix many of these limitations\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLayer 7:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eLayer 7 firewalls are aware of layer 7 protocl e.g. HTTP\u003c/li\u003e\n\u003cli\u003ecan identify normal or abnormal requests and attacks\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"web-application-firewall-waf-webacls-rule-groups-and-rules\"\u003eWeb Application Firewall (WAF), WEBACLs, Rule Groups and Rules\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#web-application-firewall-waf-webacls-rule-groups-and-rules\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA web application firewall that helps protect your web applications or APIs against common web exploits and bots\u003c/li\u003e\n\u003cli\u003eOutputs logs\u003c/li\u003e\n\u003cli\u003eA protection pack (web ACL) gives you fine-grained control over all of the HTTP(S) web requests that your protected resource responds to\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWeb ACL:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eControls what traffic is allowed or blocked - (ALLOW or BLOCK)\u003c/li\u003e\n\u003cli\u003eResource type - cloudfront or regional service \u003c/li\u003e\n\u003cli\u003eHave to add rule groups or rules processed in order\u003c/li\u003e\n\u003cli\u003eWCU - acl capacity units - default is 1500 but can be increased via support tickets\u003c/li\u003e\n\u003cli\u003eWebACLS are associated with resources , this can take some time\u003c/li\u003e\n\u003cli\u003eAdjusting an existing WEBACL can take less time than creating a new one\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eRule groups:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003erule groups contain rules\u003c/li\u003e\n\u003cli\u003eNo default actions - thats defined when added to webacls\u003c/li\u003e\n\u003cli\u003emanaged by aws, you, services owned\u003c/li\u003e\n\u003cli\u003eCan be reused by multiple webACLS\u003c/li\u003e\n\u003cli\u003eYou have to define the WCU capacity upfront (max 1500*)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWAF Rules:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eType, Statement, Action\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eRegular or Rate-based (e.g. x100 in a 5 minute period)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eStatement: WHAT to match or COUNT\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eAction: Allow, block, count, captcha and custom responses\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eWebACL - monthly $5/month\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eRule - $1 / month\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eRequests - monthly $0.6/million\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIntelligent threat mitigation: bot control ($10/month) \u0026#x26; $1/1 mil requests\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eCaptcha, fraud control, marketplace groups extra costs\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"aws-shield\"\u003eAWS Shield\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#aws-shield\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eStandard and Advance - DDOS Protection\u003c/li\u003e\n\u003cli\u003eShield is free and advanced has a cost\u003c/li\u003e\n\u003cli\u003eNetwork volumetric attacks (L3) - Saturate Capacity\u003c/li\u003e\n\u003cli\u003eNetwork Protocol Attacks (L4) - TCP SYN FLood\u003c/li\u003e\n\u003cli\u003e...Leave connections open, prevent new ones\u003c/li\u003e\n\u003cli\u003eApplication Layer Attacks (L7) e.g. web request floods\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eStandard:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFree\u003c/li\u003e\n\u003cli\u003eProtection at the perimeter at region/vpc or at AWS edge\u003c/li\u003e\n\u003cli\u003eCommon network (L3) or Transport (L4)\u003c/li\u003e\n\u003cli\u003eBest protection using r53, cloudfront, aws global accelerator \u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAdvanced:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e$3000 per month per org - 1 year lock in\u003c/li\u003e\n\u003cli\u003eProtects CF, R53, Accelerator, anything associated with EIPS (ec2), ALBS, CLBs, NLBs\u003c/li\u003e\n\u003cli\u003enot automatic - must be explicitly enabled \u003c/li\u003e\n\u003cli\u003eCost protection for unmitigated attacks e.g. ec2 scaling\u003c/li\u003e\n\u003cli\u003eProactive engagement \u0026#x26; aws shield response team will contact you when attacks are detected\u003c/li\u003e\n\u003cli\u003eIntegrates with WAF\u003c/li\u003e\n\u003cli\u003eApplication Layer 7 ddos protection\u003c/li\u003e\n\u003cli\u003ereal time visibility of DDOS events and attacks\u003c/li\u003e\n\u003cli\u003eHealth based detection \u003c/li\u003e\n\u003cli\u003eProtection groups\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"cloudhsm\"\u003eCloudHSM\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#cloudhsm\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003ewith KMS its AWS managed. It's a shared service which means other AWS accounts use it \u003c/li\u003e\n\u003cli\u003eCloudHSM - a true Single Tenant hardware security module (HSM)\u003c/li\u003e\n\u003cli\u003eAWS Provision but its fully customer managed\u003c/li\u003e\n\u003cli\u003eFully FIPS 140-2 Level 3 compliant (KMS is l3 overall some l3)\u003c/li\u003e\n\u003cli\u003eCloudHSM has to be accessed via industry standard APIs - pks#11, java cryptography extensions JCE, microsoft cryptoNG (CNG) libraries\u003c/li\u003e\n\u003cli\u003eKMS can use cloudhsm as a custom key store and cloudhsm integration with KMS\u003c/li\u003e\n\u003cli\u003eDeployed on a cloud VPC you have no visibility of\u003c/li\u003e\n\u003cli\u003eAWS CloudHSM client needs to be installed on the VPC devices to be accessed\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eUse cases:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eNo native integration e.g. no s3, SSE\u003c/li\u003e\n\u003cli\u003eOffload the SSL/TLS processing for web servers - more economical and efficient than doing on a general purpose ec2 instance\u003c/li\u003e\n\u003cli\u003eenable transparent data encryption (TDE) for oracle databases\u003c/li\u003e\n\u003cli\u003eprotect the private keys for an issuing certificate authority (CA)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eFor anything that requires aws integration then cloudHSM is not suitable \u003c/p\u003e\n\u003ch3 id=\"aws-config\"\u003eAWS Config\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#aws-config\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA service which records config changes over time on resources\u003c/li\u003e\n\u003cli\u003eFor auditing of changes, compliance with standards\u003c/li\u003e\n\u003cli\u003edoes not prevent changes happening - no protection\u003c/li\u003e\n\u003cli\u003eRegional service - supports cross region and account aggregation\u003c/li\u003e\n\u003cli\u003eCan generate SNS notifications and near real time events via event bridge and lambda\u003c/li\u003e\n\u003cli\u003eConfig rules can be used to evaluate resources and determining whether their non-compliant\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"amazon-macie\"\u003eAmazon Macie\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#amazon-macie\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003edata security and data privacy service\u003c/li\u003e\n\u003cli\u003eDiscover, monitor and protect data stored in S3 buckets\u003c/li\u003e\n\u003cli\u003eAutomated discovery of data i.e. PII, PHI, Finance\u003c/li\u003e\n\u003cli\u003eManaged data identifiers - build-in using ML/Patterns\u003c/li\u003e\n\u003cli\u003eCustom data identifiers - proprietary - regex based\u003c/li\u003e\n\u003cli\u003eIntegrates - with security hub \u0026#x26; finding events to event bridge\u003c/li\u003e\n\u003cli\u003eUses a multi account architecture - centrally managed ether via aws ORG or one macie account inviting\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIdentifiers:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eManaged via AWS:\n\u003cul\u003e\n\u003cli\u003evia a growing list of common sensitive data types e.g. credentials, finance, health, personal identifiers\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eCustom - created by you\n\u003cul\u003e\n\u003cli\u003eregex\u003c/li\u003e\n\u003cli\u003eKeywords - optional sequences \u003c/li\u003e\n\u003cli\u003eMaximum match distance\u003c/li\u003e\n\u003cli\u003eignore words\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eFindings:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePolicy or sensitive data findings\u003c/li\u003e\n\u003cli\u003ePolicy e.g. S3BlockPublicAccessDisabled/EncryptionDIsabled/BucketSharedExternally etc...\u003c/li\u003e\n\u003cli\u003eSensitive data - S3Object/Credentials, S3Object/CustomIdentifiers, S3Object/Financial etc...\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"amazon-inspector\"\u003eAmazon Inspector\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#amazon-inspector\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eDesigned to check EC2 instances and the instances OS\u003c/li\u003e\n\u003cli\u003eProvides report ordered by severity\u003c/li\u003e\n\u003cli\u003eNetwork assessment (agentless)\u003c/li\u003e\n\u003cli\u003eNetwork and Host assessment (agent)\u003c/li\u003e\n\u003cli\u003eRules package - network reachability (no agent required)\u003c/li\u003e\n\u003cli\u003eAgent can provide additional OS visibility\u003c/li\u003e\n\u003cli\u003eCheck reachability end to end\u003c/li\u003e\n\u003cli\u003ePackages - Host assessments, agent required:\n\u003cul\u003e\n\u003cli\u003ecommon vulnerabilities and exposures (CVE)\u003c/li\u003e\n\u003cli\u003eCenter for internet security (CIS) benchmarks\u003c/li\u003e\n\u003cli\u003eSecurity best practices for amazon inspector e.g. password complexity checks\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e","noteIndex":{"id":"wn8PE1RhG0znK1alrGFYv","title":"Knowledge Garden","desc":"","updated":1725627729985,"created":1631901573363,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"vault"},"contentHash":"8d5496c75d3dbc62da1263726aa08b42","links":[],"anchors":{"my-second-brain":{"type":"header","text":"My Second Brain","value":"my-second-brain","line":8,"column":0,"depth":4}},"children":["bwlvrHRccHBUBhHu7Mh1G","7w0mtdy9yip2z8dm44sazxg","8h567033xcainsquqy92vos","514eyidh124uj7yywy9os9z","zbqz5oql3yy88t9yf8q9mtz","XZTCg1c8mZeR9jEyM2HOy","6FtP5bCaxDDd47jEuSH5y","5c0e9ifp2lh9imgp1zahq33","aig5i0xuh2jq0ibzfq8sz22","8HZ1TTh4HUtNFePL29cg7"],"parent":null,"data":{},"body":"\n#### My Second Brain\n\n---\n\nA collection of my notes around all things software development.\n\n\u003e This website is generated by a Dendron template. For more information, see the [template README file](https://github.com/dendronhq/template.publish.github/).\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2,"vaultSelectionModeOnCreate":"smart"}},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"randomNote":{},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":true,"maxPreviewsCached":10,"maxNoteLength":204800,"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"enableUserTags":true,"enableHashTags":true,"dendronVersion":"0.83.0","enableEditorDecorations":true,"enableFullHierarchyNoteTitle":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Dendron","description":"Personal knowledge space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"lookup","assetsPrefix":"/KnowledgeGarden","siteUrl":"https://danadabb.github.io/","duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"jeybygpftmwnk69ylywov78"},"buildId":"hwGfdcDrSx4cXywVsCQrh","assetPrefix":"/KnowledgeGarden","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>